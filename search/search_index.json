{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Runnable","text":"<pre><code>                                                   ,////,\n                                                  /// 6|\n                                                  //  _|\n                                                _/_,-'\n                                            _.-/'/   \\   ,/;,\n                                        ,-' /'  \\_   \\ / _/\n                                         `\\ /     _/\\  ` /\n                                           |     /,  `\\_/\n                                           |     \\'\n                                /\\_        /`      /\\\n                              /' /_``--.__/\\  `,. /  \\\n                              |_/`  `-._     `\\/  `\\   `.\n                                        `-.__/'     `\\   |\n                                                     `\\  \\\n                                                      `\\ \\\n                                                        \\_\\__\n                                                          \\___)\n</code></pre>"},{"location":"#what_does_it_do","title":"What does it do?","text":""},{"location":"#example","title":"Example","text":""},{"location":"#functions","title":"functions","text":"<p>The below content is assumed to be <code>examples/functions.py</code></p> <p>pydantic models</p> <p>The functions should use pydantic models as their outputs.</p> <p>Pydantic models offer better representations of the input and output, inspired by FastAPI's implementation.</p> <pre><code>from pydantic import BaseModel\n\n\nclass InnerModel(BaseModel):\n    \"\"\"\n    A pydantic model representing a group of related parameters.\n    \"\"\"\n\n    foo: int\n    bar: str\n\n\nclass NestedModel(BaseModel):\n    \"\"\"\n    A pydantic model representing the parameters of the whole pipeline.\n    \"\"\"\n\n    x: int\n    y: InnerModel\n\n\ndef return_parameter() -&gt; NestedModel:\n    \"\"\"\n    A example python task that does something interesting and returns\n    a parameter to be used in downstream steps.\n\n    The annotation of the return type of the function is not mandatory\n    but it is a good practice.\n\n    Returns:\n        NestedModel: The parameters that should be used in downstream steps.\n    \"\"\"\n    # Return type of a function should be a pydantic model\n    return 1, InnerModel(foo=10, bar=\"hello world\")\n\n\ndef display_parameter(x: int, y: InnerModel):\n    \"\"\"\n    An example python task that does something interesting with\n    input parameters.\n\n    Annotating the arguments of the function is important for\n    runnable to understand the type of parameters you want.\n\n    Without annotations, runnable would inject a python dictionary.\n\n    Input args can be a pydantic model or the individual attributes\n    of the non-nested model\n    \"\"\"\n    print(x)\n    # &gt;&gt;&gt; prints 1\n    print(y)\n    # &gt;&gt;&gt; prints InnerModel(foo=10, bar=\"hello world\")\n\n\n\"\"\"\nWithout any framework, the \"driver\" code would be the\nmain function.\n\"\"\"\n\n\ndef main():\n    my_param = return_parameter()\n    display_parameter(my_param.x, my_param.y)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>There is nothing special about the functions, they are plain old python functions.</p> <p>Notebooks and Shell scripts</p> <p>You can execute notebooks and shell scripts too!!</p> <p>They can be written just as you would want them, plain old notebooks and scripts.</p>"},{"location":"#local","title":"local","text":"<p>Replace the \"driver\" function with a runnable definition in either <code>python sdk</code> or <code>yaml</code>.</p> yamlpythonmetadata <p>pipeline and steps</p> <p>The pipeline is essentially a representation of the \"driver\" function.</p> <p>The gains by this definition for local executions are clearer by the metadata gathered during the exeuction.</p> <pre><code>dag:\n  description: |\n    This is a simple pipeline that does 3 steps\n    in sequence.\n\n    In this example:\n      1. First step: returns a \"parameter\" x\n      as a Pydantic model\n      2. Second step: Consumes that parameter\n      and prints it\n\n    You can run this pipeline by:\n    runnable execute -f examples/python-tasks.yaml\n  start_at: step 1 # (1)\n  steps:\n    step 1: # (2)\n      type: task\n      command: examples.functions.return_parameter # (3)\n      returns:\n        - name: x\n          kind: json\n        - name: y\n          kind: json\n      next: step 2 # (4)\n    step 2:\n      type: task\n      command_type: python\n      command: examples.functions.display_parameter\n      next: success # (5)\n    success:\n      type: success # (6)\n    fail:\n      type: fail\n</code></pre> <ol> <li>Start the pipeline execution at step1</li> <li>The name of the step.</li> <li>The path to the python function</li> <li>Go to step2, if successful</li> <li>Go to success node, if successful</li> <li>Mark the execution as success</li> </ol> <p>pipeline and steps</p> <p>The pipeline is essentially a representation of the \"driver\" function.</p> <p>The gains by this definition for local executions are clearer by the metadata gathered during the exeuction.</p> <pre><code>\n</code></pre> <ol> <li>The name of the step.</li> <li>The path to the python function</li> <li><code>terminate_with_success</code> indicates that the pipeline is completed successfully. You can also use <code>terminate_with_failure</code> to indicate the pipeline fail.</li> <li>There are many ways to define dependencies within nodes, step1 &gt;&gt; step2, step1 &lt;&lt; step2 or using depends_on.</li> <li>Start the pipeline execution at step1</li> <li>The list of steps to be executed, the order does not matter.</li> <li>Add <code>success</code> and <code>fail</code> nodes to the pipeline.</li> <li>Returns the metadata captured during the execution.</li> </ol> <p> Thats it!! </p> <p>By adding one file you created a pipeline. Your application code did not change at all.</p> <p>There is no boilerplate code, no adherence to structure, no intrusion into the application code.</p>"},{"location":"#todo_change_this","title":"TODO: Change this","text":"<p>Captures information to understand the execution plan for debugging or lineage purposes.</p> <pre><code>{\n  \"run_id\": \"piquant-pasteur-0613\", // Unique run identifier\n  \"dag_hash\": \"\",\n  \"use_cached\": false,\n  \"tag\": \"\",\n  \"original_run_id\": \"\",\n  \"status\": \"SUCCESS\",\n  \"steps\": {\n      \"step1\": {\n          \"name\": \"step1\", // name of the step\n          \"internal_name\": \"step1\",\n          \"status\": \"SUCCESS\",\n          \"step_type\": \"task\",\n          \"message\": \"\",\n          \"mock\": false,\n          \"code_identities\": [ // The code status at the time of execution of step1\n              {\n                  \"code_identifier\": \"f68561360eed64e2715929d2ddd0736fd277d706\",\n                  \"code_identifier_type\": \"git\",\n                  \"code_identifier_dependable\": true,\n                  \"code_identifier_url\": \"https://github.com/vijayvammi/runnable.git\",\n                  \"code_identifier_message\": \"\"\n              }\n          ],\n          \"attempts\": [\n              {\n                  \"attempt_number\": 1,\n                  \"start_time\": \"2024-02-25 06:13:53.295595\",\n                  \"end_time\": \"2024-02-25 06:13:53.306082\",\n                  \"duration\": \"0:00:00.010487\",\n                  \"status\": \"SUCCESS\",\n                  \"message\": \"\",\n                  \"parameters\": {}\n              }\n          ],\n          \"user_defined_metrics\": {},\n          \"branches\": {},\n          \"data_catalog\": [\n              {\n                  \"name\": \"step1.execution.log\", // THe stdout and stderr of execution\n                  \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                  \"catalog_relative_path\": \"piquant-pasteur-0613/step1.execution.log\",\n                  \"catalog_handler_location\": \".catalog\",\n                  \"stage\": \"put\"\n              }\n          ]\n      },\n      \"step2\": {\n          \"name\": \"step2\",\n          \"internal_name\": \"step2\",\n          \"status\": \"SUCCESS\",\n          \"step_type\": \"task\",\n          \"message\": \"\",\n          \"mock\": false,\n          \"code_identities\": [\n              {\n                  \"code_identifier\": \"f68561360eed64e2715929d2ddd0736fd277d706\",\n                  \"code_identifier_type\": \"git\",\n                  \"code_identifier_dependable\": true,\n                  \"code_identifier_url\": \"https://github.com/vijayvammi/runnable.git\",\n                  \"code_identifier_message\": \"\"\n              }\n          ],\n          \"attempts\": [\n              {\n                  \"attempt_number\": 1,\n                  \"start_time\": \"2024-02-25 06:13:53.372941\",\n                  \"end_time\": \"2024-02-25 06:13:53.378192\",\n                  \"duration\": \"0:00:00.005251\",\n                  \"status\": \"SUCCESS\",\n                  \"message\": \"\",\n                  \"parameters\": { // The parameters at the time of execution\n                      \"x\": 1,\n                      \"y\": {\n                          \"foo\": 10,\n                          \"bar\": \"hello world\"\n                      }\n                  }\n              }\n          ],\n          \"user_defined_metrics\": {},\n          \"branches\": {},\n          \"data_catalog\": [\n              {\n                  \"name\": \"step2.execution.log\",\n                  \"data_hash\": \"612160fd5e1d7d1f3d8b4db1a6e73de63f97ff4c5db616525f856d774a2837b4\",\n                  \"catalog_relative_path\": \"piquant-pasteur-0613/step2.execution.log\",\n                  \"catalog_handler_location\": \".catalog\",\n                  \"stage\": \"put\"\n              }\n          ]\n      },\n      \"success\": {\n          \"name\": \"success\",\n          \"internal_name\": \"success\",\n          \"status\": \"SUCCESS\",\n          \"step_type\": \"success\",\n          \"message\": \"\",\n          \"mock\": false,\n          \"code_identities\": [\n              {\n                  \"code_identifier\": \"f68561360eed64e2715929d2ddd0736fd277d706\",\n                  \"code_identifier_type\": \"git\",\n                  \"code_identifier_dependable\": true,\n                  \"code_identifier_url\": \"https://github.com/vijayvammi/runnable.git\",\n                  \"code_identifier_message\": \"\"\n              }\n          ],\n          \"attempts\": [\n              {\n                  \"attempt_number\": 1,\n                  \"start_time\": \"2024-02-25 06:13:53.441232\",\n                  \"end_time\": \"2024-02-25 06:13:53.441295\",\n                  \"duration\": \"0:00:00.000063\",\n                  \"status\": \"SUCCESS\",\n                  \"message\": \"\",\n                  \"parameters\": {\n                      \"x\": 1,\n                      \"y\": {\n                          \"foo\": 10,\n                          \"bar\": \"hello world\"\n                      }\n                  }\n              }\n          ],\n          \"user_defined_metrics\": {},\n          \"branches\": {},\n          \"data_catalog\": []\n      }\n  },\n  \"parameters\": { // THe final state of the parameters\n      \"x\": 1,\n      \"y\": {\n          \"foo\": 10,\n          \"bar\": \"hello world\"\n      }\n  },\n  \"run_config\": { // The configuration of the execution\n      \"executor\": {\n          \"service_name\": \"local\",\n          \"service_type\": \"executor\",\n          \"enable_parallel\": false,\n          \"overrides\": {}\n      },\n      \"run_log_store\": {\n          \"service_name\": \"buffered\",\n          \"service_type\": \"run_log_store\"\n      },\n      \"secrets_handler\": {\n          \"service_name\": \"do-nothing\",\n          \"service_type\": \"secrets\"\n      },\n      \"catalog_handler\": {\n          \"service_name\": \"file-system\",\n          \"service_type\": \"catalog\",\n          \"catalog_location\": \".catalog\"\n      },\n      \"experiment_tracker\": {\n          \"service_name\": \"do-nothing\",\n          \"service_type\": \"experiment_tracker\"\n      },\n      \"pipeline_file\": \"\",\n      \"parameters_file\": \"\",\n      \"configuration_file\": \"\",\n      \"tag\": \"\",\n      \"run_id\": \"piquant-pasteur-0613\",\n      \"variables\": {},\n      \"use_cached\": false,\n      \"original_run_id\": \"\",\n      \"dag\": { // THe pipeline representation\n          \"start_at\": \"step1\",\n          \"name\": \"\",\n          \"description\": \"\",\n          \"steps\": {\n              \"step1\": {\n                  \"type\": \"task\",\n                  \"name\": \"step1\",\n                  \"next\": \"step2\",\n                  \"on_failure\": \"\",\n                  \"overrides\": {},\n                  \"catalog\": null,\n                  \"max_attempts\": 1,\n                  \"command\": \"examples.functions.return_parameter\",\n                  \"command_type\": \"python\",\n                  \"node_name\": \"step1\"\n              },\n              \"step2\": {\n                  \"type\": \"task\",\n                  \"name\": \"step2\",\n                  \"next\": \"success\",\n                  \"on_failure\": \"\",\n                  \"overrides\": {},\n                  \"catalog\": null,\n                  \"max_attempts\": 1,\n                  \"command\": \"examples.functions.display_parameter\",\n                  \"command_type\": \"python\",\n                  \"node_name\": \"step2\"\n              },\n              \"success\": {\n                  \"type\": \"success\",\n                  \"name\": \"success\"\n              },\n              \"fail\": {\n                  \"type\": \"fail\",\n                  \"name\": \"fail\"\n              }\n          }\n      },\n      \"dag_hash\": \"\",\n      \"execution_plan\": \"chained\"\n  }\n}\n</code></pre>"},{"location":"#cloud","title":"cloud","text":""},{"location":"extensions/","title":"Extensions","text":""},{"location":"extensions/#general_set_up","title":"General set up","text":"<p>runnable is built around the idea to decouple the pipeline definition and pipeline execution.</p> <p>All the concepts are defined with this principle and therefore are extendible as long as the API is satisfied.</p> <p>We internally use stevedore to manage extensions. Our pyproject.toml has plugin space for all the concepts.</p> <pre><code>[tool.poetry.plugins.\"executor\"]\n\"local\" = \"runnable.extensions.executor.local.implementation:LocalExecutor\"\n\"local-container\" = \"runnable.extensions.executor.local_container.implementation:LocalContainerExecutor\"\n\"argo\" = \"runnable.extensions.executor.argo.implementation:ArgoExecutor\"\n\n# Plugins for Catalog\n[tool.poetry.plugins.\"catalog\"]\n\"do-nothing\" = \"runnable.catalog:DoNothingCatalog\"\n\"file-system\" = \"runnable.extensions.catalog.file_system.implementation:FileSystemCatalog\"\n\n# Plugins for Secrets\n[tool.poetry.plugins.\"secrets\"]\n\"do-nothing\" = \"runnable.secrets:DoNothingSecretManager\"\n\"dotenv\" = \"runnable.extensions.secrets.dotenv.implementation:DotEnvSecrets\"\n\"env-secrets-manager\" = \"runnable.extensions.secrets.env_secrets.implementation:EnvSecretsManager\"\n\n# Plugins for Run Log store\n[tool.poetry.plugins.\"run_log_store\"]\n\"buffered\" = \"runnable.datastore:BufferRunLogstore\"\n\"file-system\" = \"runnable.extensions.run_log_store.file_system.implementation:FileSystemRunLogstore\"\n\"chunked-fs\" = \"runnable.extensions.run_log_store.chunked_file_system.implementation:ChunkedFileSystemRunLogStore\"\n\n# Plugins for Experiment tracker\n[tool.poetry.plugins.\"experiment_tracker\"]\n\"do-nothing\" = \"runnable.experiment_tracker:DoNothingTracker\"\n\"mlflow\" = \"runnable.extensions.experiment_tracker.mlflow.implementation:MLFlowExperimentTracker\"\n\n# Plugins for Pickler\n[tool.poetry.plugins.\"pickler\"]\n\"pickle\" = \"runnable.pickler:NativePickler\"\n\n\n# Plugins for Integration\n[tool.poetry.plugins.\"integration\"]\n# Left empty for 3rd party integrations\n\n# Plugins for Tasks\n[tool.poetry.plugins.\"tasks\"]\n\"python\" = \"runnable.tasks:PythonTaskType\"\n\"shell\" = \"runnable.tasks:ShellTaskType\"\n\"notebook\" = \"runnable.tasks:NotebookTaskType\"\n\n\n# Plugins for Nodes\n[tool.poetry.plugins.\"nodes\"]\n\"task\" = \"runnable.extensions.nodes:TaskNode\"\n\"fail\" = \"runnable.extensions.nodes:FailNode\"\n\"success\" = \"runnable.extensions.nodes:SuccessNode\"\n\"parallel\" = \"runnable.extensions.nodes:ParallelNode\"\n\"map\" = \"runnable.extensions.nodes:MapNode\"\n\"stub\" = \"runnable.extensions.nodes:StubNode\"\n</code></pre> <p>To submit extensions to this project (pretty please!!) submit a PR with plugin name and implementation path inserted in pyproject.toml. We are happy to work with you to write them, the complexity is mostly in having access to them.</p> <p>To write extensions for your project and are not useful for wider audience, include the plugin within your pyproject.toml or  setuptools entry points. During the execution of the pipeline, runnable would automatically pick up the extension if it registered to the correct namespace.</p> <p>The below section shows the base class implementation for all the concepts. All the base classes are extended from pydantic BaseModel.</p>"},{"location":"extensions/#executor","title":"Executor","text":"<p>Register to namespace: [tool.poetry.plugins.\"executor\"]</p> <p>Examples: local, local-container, argo</p>"},{"location":"extensions/#runnable.executor.BaseExecutor","title":"runnable.executor.BaseExecutor","text":"<p>             Bases: <code>ABC</code>, <code>BaseModel</code></p> <p>The skeleton of an executor class. Any implementation of an executor should inherit this class and over-ride accordingly.</p> <p>There is a extension available in runnable/extensions/executor/init.py which implements the most common functionality which is easier to extend/override in most scenarios.</p> Source code in <code>runnable/executor.py</code> <pre><code>class BaseExecutor(ABC, BaseModel):\n    \"\"\"\n    The skeleton of an executor class.\n    Any implementation of an executor should inherit this class and over-ride accordingly.\n\n    There is a extension available in runnable/extensions/executor/__init__.py\n    which implements the most common functionality which is easier to\n    extend/override in most scenarios.\n\n    \"\"\"\n\n    service_name: str = \"\"\n    service_type: str = \"executor\"\n\n    overrides: dict = {}\n\n    _local: bool = False  # This is a flag to indicate whether the executor is local or not.\n\n    _context_node = None  # type: BaseNode\n    model_config = ConfigDict(extra=\"forbid\")\n\n    @property\n    def _context(self):\n        return context.run_context\n\n    @abstractmethod\n    def _get_parameters(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Get the parameters for the execution.\n        The parameters can be defined in parameters file and can be overridden by environment variables.\n\n        Returns:\n            Dict[str, Any]: The parameters for the execution.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def _set_up_run_log(self, exists_ok=False):\n        \"\"\"\n        Create a run log and put that in the run log store\n\n        If exists_ok, we allow the run log to be already present in the run log store.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def prepare_for_graph_execution(self):\n        \"\"\"\n        This method should be called prior to calling execute_graph.\n        Perform any steps required before doing the graph execution.\n\n        The most common implementation is to prepare a run log for the run if the run uses local interactive compute.\n\n        But in cases of actual rendering the job specs (eg: AWS step functions, K8's) we check if the services are OK.\n        We do not set up a run log as its not relevant.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def prepare_for_node_execution(self):\n        \"\"\"\n        Perform any modifications to the services prior to execution of the node.\n\n        Args:\n            node (Node): [description]\n            map_variable (dict, optional): [description]. Defaults to None.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def _sync_catalog(self, stage: str, synced_catalogs=None) -&gt; Optional[List[DataCatalog]]:\n        \"\"\"\n        1). Identify the catalog settings by over-riding node settings with the global settings.\n        2). For stage = get:\n                Identify the catalog items that are being asked to get from the catalog\n                And copy them to the local compute data folder\n        3). For stage = put:\n                Identify the catalog items that are being asked to put into the catalog\n                Copy the items from local compute folder to the catalog\n        4). Add the items onto the step log according to the stage\n\n        Args:\n            node (Node): The current node being processed\n            step_log (StepLog): The step log corresponding to that node\n            stage (str): One of get or put\n\n        Raises:\n            Exception: If the stage is not in one of get/put\n\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def get_effective_compute_data_folder(self) -&gt; Optional[str]:\n        \"\"\"\n        Get the effective compute data folder for the given stage.\n        If there is nothing to catalog, we return None.\n\n        The default is the compute data folder of the catalog but this can be over-ridden by the node.\n\n        Args:\n            stage (str): The stage we are in the process of cataloging\n\n\n        Returns:\n            Optional[str]: The compute data folder as defined by catalog handler or the node or None.\n        \"\"\"\n        ...\n\n    @property\n    def step_attempt_number(self) -&gt; int:\n        \"\"\"\n        The attempt number of the current step.\n        Orchestrators should use this step to submit multiple attempts of the job.\n\n        Returns:\n            int: The attempt number of the current step. Defaults to 1.\n        \"\"\"\n        return int(os.environ.get(defaults.ATTEMPT_NUMBER, 1))\n\n    @abstractmethod\n    def _execute_node(self, node: BaseNode, map_variable: TypeMapVariable = None, mock: bool = False, **kwargs):\n        \"\"\"\n        This is the entry point when we do the actual execution of the function.\n\n        While in interactive execution, we just compute, in 3rd party interactive execution, we need to reach\n        this function.\n\n        In most cases,\n            * We get the corresponding step_log of the node and the parameters.\n            * We sync the catalog to GET any data sets that are in the catalog\n            * We call the execute method of the node for the actual compute and retry it as many times as asked.\n            * If the node succeeds, we get any of the user defined metrics provided by the user.\n            * We sync the catalog to PUT any data sets that are in the catalog.\n\n        Args:\n            node (Node): The node to execute\n            map_variable (dict, optional): If the node is of a map state, map_variable is the value of the iterable.\n                        Defaults to None.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def execute_node(self, node: BaseNode, map_variable: TypeMapVariable = None, **kwargs):\n        \"\"\"\n        The entry point for all executors apart from local.\n        We have already prepared for node execution.\n\n        Args:\n            node (BaseNode): The node to execute\n            map_variable (dict, optional): If the node is part of a map, send in the map dictionary. Defaults to None.\n\n        Raises:\n            NotImplementedError: _description_\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def add_code_identities(self, node: BaseNode, step_log: StepLog, **kwargs):\n        \"\"\"\n        Add code identities specific to the implementation.\n\n        The Base class has an implementation of adding git code identities.\n\n        Args:\n            step_log (object): The step log object\n            node (BaseNode): The node we are adding the step log for\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def execute_from_graph(self, node: BaseNode, map_variable: TypeMapVariable = None, **kwargs):\n        \"\"\"\n        This is the entry point to from the graph execution.\n\n        While the self.execute_graph is responsible for traversing the graph, this function is responsible for\n        actual execution of the node.\n\n        If the node type is:\n            * task : We can delegate to _execute_node after checking the eligibility for re-run in cases of a re-run\n            * success: We can delegate to _execute_node\n            * fail: We can delegate to _execute_node\n\n        For nodes that are internally graphs:\n            * parallel: Delegate the responsibility of execution to the node.execute_as_graph()\n            * dag: Delegate the responsibility of execution to the node.execute_as_graph()\n            * map: Delegate the responsibility of execution to the node.execute_as_graph()\n\n        Transpilers will NEVER use this method and will NEVER call ths method.\n        This method should only be used by interactive executors.\n\n        Args:\n            node (Node): The node to execute\n            map_variable (dict, optional): If the node if of a map state, this corresponds to the value of iterable.\n                    Defaults to None.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def trigger_job(self, node: BaseNode, map_variable: TypeMapVariable = None, **kwargs):\n        \"\"\"\n        Executor specific way of triggering jobs when runnable does both traversal and execution\n\n        Transpilers will NEVER use this method and will NEVER call them.\n        Only interactive executors who need execute_from_graph will ever implement it.\n\n        Args:\n            node (BaseNode): The node to execute\n            map_variable (str, optional): If the node if of a map state, this corresponds to the value of iterable.\n                    Defaults to ''.\n\n        NOTE: We do not raise an exception as this method is not required by many extensions\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def _get_status_and_next_node_name(self, current_node: BaseNode, dag: Graph, map_variable: TypeMapVariable = None):\n        \"\"\"\n        Given the current node and the graph, returns the name of the next node to execute.\n\n        The name is always relative the graph that the node resides in.\n\n        If the current node succeeded, we return the next node as per the graph.\n        If the current node failed, we return the on failure node of the node (if provided) or the global one.\n\n        Args:\n            current_node (BaseNode): The current node.\n            dag (Graph): The dag we are traversing.\n            map_variable (dict): If the node belongs to a map branch.\n        \"\"\"\n\n        ...\n\n    @abstractmethod\n    def execute_graph(self, dag: Graph, map_variable: TypeMapVariable = None, **kwargs):\n        \"\"\"\n        The parallelization is controlled by the nodes and not by this function.\n\n        Transpilers should over ride this method to do the translation of dag to the platform specific way.\n        Interactive methods should use this to traverse and execute the dag.\n            - Use execute_from_graph to handle sub-graphs\n\n        Logically the method should:\n            * Start at the dag.start_at of the dag.\n            * Call the self.execute_from_graph(node)\n            * depending upon the status of the execution, either move to the success node or failure node.\n\n        Args:\n            dag (Graph): The directed acyclic graph to traverse and execute.\n            map_variable (dict, optional): If the node if of a map state, this corresponds to the value of the iterable.\n                    Defaults to None.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def send_return_code(self, stage=\"traversal\"):\n        \"\"\"\n        Convenience function used by pipeline to send return code to the caller of the cli\n\n        Raises:\n            Exception: If the pipeline execution failed\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def _resolve_executor_config(self, node: BaseNode):\n        \"\"\"\n        The overrides section can contain specific over-rides to an global executor config.\n        To avoid too much clutter in the dag definition, we allow the configuration file to have overrides block.\n        The nodes can over-ride the global config by referring to key in the overrides.\n\n        For example:\n        # configuration.yaml\n        execution:\n          type: cloud-implementation\n          config:\n            k1: v1\n            k3: v3\n            overrides:\n              k2: v2 # Could be a mapping internally.\n\n        # in pipeline definition.yaml\n        dag:\n          steps:\n            step1:\n              overrides:\n                cloud-implementation:\n                  k1: value_specific_to_node\n                  k2:\n\n        This method should resolve the node_config to {'k1': 'value_specific_to_node', 'k2': 'v2', 'k3': 'v3'}\n\n        Args:\n            node (BaseNode): The current node being processed.\n\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def execute_job(self, node: TaskNode):\n        \"\"\"\n        Executor specific way of executing a job (python function or a notebook).\n\n        Interactive executors should execute the job.\n        Transpilers should write the instructions.\n\n        Args:\n            node (BaseNode): The job node to execute\n\n        Raises:\n            NotImplementedError: Executors should choose to extend this functionality or not.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def fan_out(self, node: BaseNode, map_variable: TypeMapVariable = None):\n        \"\"\"\n        This method is used to appropriately fan-out the execution of a composite node.\n        This is only useful when we want to execute a composite node during 3rd party orchestrators.\n\n        Reason: Transpilers typically try to run the leaf nodes but do not have any capacity to do anything for the\n        step which is composite. By calling this fan-out before calling the leaf nodes, we have an opportunity to\n        do the right set up (creating the step log, exposing the parameters, etc.) for the composite step.\n\n        All 3rd party orchestrators should use this method to fan-out the execution of a composite node.\n        This ensures:\n            - The dot path notation is preserved, this method should create the step and call the node's fan out to\n            create the branch logs and let the 3rd party do the actual step execution.\n            - Gives 3rd party orchestrators an opportunity to set out the required for running a composite node.\n\n        Args:\n            node (BaseNode): The node to fan-out\n            map_variable (dict, optional): If the node if of a map state,.Defaults to None.\n\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def fan_in(self, node: BaseNode, map_variable: TypeMapVariable = None):\n        \"\"\"\n        This method is used to appropriately fan-in after the execution of a composite node.\n        This is only useful when we want to execute a composite node during 3rd party orchestrators.\n\n        Reason: Transpilers typically try to run the leaf nodes but do not have any capacity to do anything for the\n        step which is composite. By calling this fan-in after calling the leaf nodes, we have an opportunity to\n        act depending upon the status of the individual branches.\n\n        All 3rd party orchestrators should use this method to fan-in the execution of a composite node.\n        This ensures:\n            - Gives the renderer's the control on where to go depending upon the state of the composite node.\n            - The status of the step and its underlying branches are correctly updated.\n\n        Args:\n            node (BaseNode): The node to fan-in\n            map_variable (dict, optional): If the node if of a map state,.Defaults to None.\n\n        \"\"\"\n        ...\n</code></pre>"},{"location":"extensions/#run_log","title":"Run Log","text":"<p>Register to namespace: [tool.poetry.plugins.\"run_log_store\"]</p> <p>Examples: buffered, file-system,  chunked-fs</p> <p>The <code>RunLog</code> is a nested pydantic model and is located in <code>runnable.datastore.RunLog</code>.</p>"},{"location":"extensions/#runnable.datastore.BaseRunLogStore","title":"runnable.datastore.BaseRunLogStore","text":"<p>             Bases: <code>ABC</code>, <code>BaseModel</code></p> <p>The base class of a Run Log Store with many common methods implemented.</p> Source code in <code>runnable/datastore.py</code> <pre><code>class BaseRunLogStore(ABC, BaseModel):\n    \"\"\"\n    The base class of a Run Log Store with many common methods implemented.\n    \"\"\"\n\n    service_name: str = \"\"\n    service_type: str = \"run_log_store\"\n\n    @property\n    def _context(self):\n        return context.run_context\n\n    @abstractmethod\n    def create_run_log(\n        self,\n        run_id: str,\n        dag_hash: str = \"\",\n        use_cached: bool = False,\n        tag: str = \"\",\n        original_run_id: str = \"\",\n        status: str = defaults.CREATED,\n        **kwargs,\n    ):\n        \"\"\"\n        Creates a Run Log object by using the config\n\n        Logically the method should do the following:\n            * Creates a Run log\n            * Adds it to the db\n            * Return the log\n        Raises:\n            NotImplementedError: This is a base class and therefore has no default implementation\n        \"\"\"\n\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_run_log_by_id(self, run_id: str, full: bool = False, **kwargs) -&gt; RunLog:\n        \"\"\"\n        Retrieves a Run log from the database using the config and the run_id\n\n        Args:\n            run_id (str): The run_id of the run\n            full (bool): return the full run log store or only the RunLog object\n\n        Returns:\n            RunLog: The RunLog object identified by the run_id\n\n        Logically the method should:\n            * Returns the run_log defined by id from the data store defined by the config\n\n        Raises:\n            NotImplementedError: This is a base class and therefore has no default implementation\n            RunLogNotFoundError: If the run log for run_id is not found in the datastore\n        \"\"\"\n\n        raise NotImplementedError\n\n    @abstractmethod\n    def put_run_log(self, run_log: RunLog, **kwargs):\n        \"\"\"\n        Puts the Run Log in the database as defined by the config\n\n        Args:\n            run_log (RunLog): The Run log of the run\n\n        Logically the method should:\n            Puts the run_log into the database\n\n        Raises:\n            NotImplementedError: This is a base class and therefore has no default implementation\n        \"\"\"\n        raise NotImplementedError\n\n    def update_run_log_status(self, run_id: str, status: str):\n        \"\"\"\n        Updates the status of the Run Log defined by the run_id\n\n        Args:\n            run_id (str): The run_id of the run\n            status (str): The new status of the run\n        \"\"\"\n        logger.info(f\"Updating status of run_id {run_id} to {status}\")\n        run_log = self.get_run_log_by_id(run_id, full=False)\n        run_log.status = status\n        self.put_run_log(run_log)\n\n    def get_parameters(self, run_id: str, **kwargs) -&gt; Dict[str, Parameter]:\n        \"\"\"\n        Get the parameters from the Run log defined by the run_id\n\n        Args:\n            run_id (str): The run_id of the run\n\n        The method should:\n            * Call get_run_log_by_id(run_id) to retrieve the run_log\n            * Return the parameters as identified in the run_log\n\n        Returns:\n            dict: A dictionary of the run_log parameters\n        Raises:\n            RunLogNotFoundError: If the run log for run_id is not found in the datastore\n        \"\"\"\n        run_log = self.get_run_log_by_id(run_id=run_id)\n        return run_log.parameters\n\n    def set_parameters(self, run_id: str, parameters: Dict[str, Parameter], **kwargs):\n        \"\"\"\n        Update the parameters of the Run log with the new parameters\n\n        This method would over-write the parameters, if the parameter exists in the run log already\n\n        The method should:\n            * Call get_run_log_by_id(run_id) to retrieve the run_log\n            * Update the parameters of the run_log\n            * Call put_run_log(run_log) to put the run_log in the datastore\n\n        Args:\n            run_id (str): The run_id of the run\n            parameters (dict): The parameters to update in the run log\n        Raises:\n            RunLogNotFoundError: If the run log for run_id is not found in the datastore\n        \"\"\"\n        run_log = self.get_run_log_by_id(run_id=run_id)\n        run_log.parameters.update(parameters)\n        self.put_run_log(run_log=run_log)\n\n    def get_run_config(self, run_id: str, **kwargs) -&gt; dict:\n        \"\"\"\n        Given a run_id, return the run_config used to perform the run.\n\n        Args:\n            run_id (str): The run_id of the run\n\n        Returns:\n            dict: The run config used for the run\n        \"\"\"\n\n        run_log = self.get_run_log_by_id(run_id=run_id)\n        return run_log.run_config\n\n    def set_run_config(self, run_id: str, run_config: dict, **kwargs):\n        \"\"\"Set the run config used to run the run_id\n\n        Args:\n            run_id (str): The run_id of the run\n            run_config (dict): The run_config of the run\n        \"\"\"\n\n        run_log = self.get_run_log_by_id(run_id=run_id)\n        run_log.run_config.update(run_config)\n        self.put_run_log(run_log=run_log)\n\n    def create_step_log(self, name: str, internal_name: str, **kwargs):\n        \"\"\"\n        Create a step log by the name and internal name\n\n        The method does not update the Run Log with the step log at this point in time.\n        This method is just an interface for external modules to create a step log\n\n\n        Args:\n            name (str): The friendly name of the step log\n            internal_name (str): The internal naming of the step log. The internal naming is a dot path convention\n\n        Returns:\n            StepLog: A uncommitted step log object\n        \"\"\"\n        logger.info(f\"{self.service_name} Creating a Step Log: {internal_name}\")\n        return StepLog(name=name, internal_name=internal_name, status=defaults.CREATED)\n\n    def get_step_log(self, internal_name: str, run_id: str, **kwargs) -&gt; StepLog:\n        \"\"\"\n        Get a step log from the datastore for run_id and the internal naming of the step log\n\n        The internal naming of the step log is a dot path convention.\n\n        The method should:\n            * Call get_run_log_by_id(run_id) to retrieve the run_log\n            * Identify the step location by decoding the internal naming\n            * Return the step log\n\n        Args:\n            internal_name (str): The internal name of the step log\n            run_id (str): The run_id of the run\n\n        Returns:\n            StepLog: The step log object for the step defined by the internal naming and run_id\n\n        Raises:\n            RunLogNotFoundError: If the run log for run_id is not found in the datastore\n            StepLogNotFoundError: If the step log for internal_name is not found in the datastore for run_id\n        \"\"\"\n        logger.info(f\"{self.service_name} Getting the step log: {internal_name} of {run_id}\")\n        run_log = self.get_run_log_by_id(run_id=run_id)\n        step_log, _ = run_log.search_step_by_internal_name(internal_name)\n        return step_log\n\n    def add_step_log(self, step_log: StepLog, run_id: str, **kwargs):\n        \"\"\"\n        Add the step log in the run log as identified by the run_id in the datastore\n\n        The method should:\n             * Call get_run_log_by_id(run_id) to retrieve the run_log\n             * Identify the branch to add the step by decoding the step_logs internal name\n             * Add the step log to the identified branch log\n             * Call put_run_log(run_log) to put the run_log in the datastore\n\n        Args:\n            step_log (StepLog): The Step log to add to the database\n            run_id (str): The run id of the run\n\n        Raises:\n            RunLogNotFoundError: If the run log for run_id is not found in the datastore\n            BranchLogNotFoundError: If the branch of the step log for internal_name is not found in the datastore\n                                    for run_id\n        \"\"\"\n        logger.info(f\"{self.service_name} Adding the step log to DB: {step_log.name}\")\n        run_log = self.get_run_log_by_id(run_id=run_id)\n\n        branch_to_add = \".\".join(step_log.internal_name.split(\".\")[:-1])\n        branch, _ = run_log.search_branch_by_internal_name(branch_to_add)\n\n        if branch is None:\n            branch = run_log\n        branch.steps[step_log.internal_name] = step_log\n        self.put_run_log(run_log=run_log)\n\n    def create_branch_log(self, internal_branch_name: str, **kwargs) -&gt; BranchLog:\n        \"\"\"\n        Creates a uncommitted branch log object by the internal name given\n\n        Args:\n            internal_branch_name (str): Creates a branch log by name internal_branch_name\n\n        Returns:\n            BranchLog: Uncommitted and initialized with defaults BranchLog object\n        \"\"\"\n        # Create a new BranchLog\n        logger.info(f\"{self.service_name} Creating a Branch Log : {internal_branch_name}\")\n        return BranchLog(internal_name=internal_branch_name, status=defaults.CREATED)\n\n    def get_branch_log(self, internal_branch_name: str, run_id: str, **kwargs) -&gt; Union[BranchLog, RunLog]:\n        \"\"\"\n        Returns the branch log by the internal branch name for the run id\n\n        If the internal branch name is none, returns the run log\n\n        Args:\n            internal_branch_name (str): The internal branch name to retrieve.\n            run_id (str): The run id of interest\n\n        Returns:\n            BranchLog: The branch log or the run log as requested.\n        \"\"\"\n        run_log = self.get_run_log_by_id(run_id=run_id)\n        if not internal_branch_name:\n            return run_log\n        branch, _ = run_log.search_branch_by_internal_name(internal_branch_name)\n        return branch\n\n    def add_branch_log(self, branch_log: Union[BranchLog, RunLog], run_id: str, **kwargs):\n        \"\"\"\n        The method should:\n        # Get the run log\n        # Get the branch and step containing the branch\n        # Add the branch to the step\n        # Write the run_log\n\n        The branch log could some times be a Run log and should be handled appropriately\n\n        Args:\n            branch_log (BranchLog): The branch log/run log to add to the database\n            run_id (str): The run id to which the branch/run log is added\n        \"\"\"\n\n        internal_branch_name = None\n\n        if isinstance(branch_log, BranchLog):\n            internal_branch_name = branch_log.internal_name\n\n        if not internal_branch_name:\n            self.put_run_log(branch_log)  # type: ignore # We are dealing with base dag here\n            return\n\n        run_log = self.get_run_log_by_id(run_id=run_id)\n\n        step_name = \".\".join(internal_branch_name.split(\".\")[:-1])\n        step, _ = run_log.search_step_by_internal_name(step_name)\n\n        step.branches[internal_branch_name] = branch_log  # type: ignore\n        self.put_run_log(run_log)\n\n    #\n    def create_code_identity(self, **kwargs) -&gt; CodeIdentity:\n        \"\"\"\n        Creates an uncommitted Code identity class\n\n        Returns:\n            CodeIdentity: An uncommitted code identity class\n        \"\"\"\n        logger.info(f\"{self.service_name} Creating Code identity\")\n        return CodeIdentity()\n\n    def create_data_catalog(self, name: str, **kwargs) -&gt; DataCatalog:\n        \"\"\"\n        Create a uncommitted data catalog object\n\n        Args:\n            name (str): The name of the data catalog item to put\n\n        Returns:\n            DataCatalog: The DataCatalog object.\n        \"\"\"\n        logger.info(f\"{self.service_name} Creating Data Catalog for {name}\")\n        return DataCatalog(name=name)\n</code></pre>"},{"location":"extensions/#catalog","title":"Catalog","text":"<p>Register to namespace: [tool.poetry.plugins.\"catalog\"]</p> <p>Example: do-nothing,  file-system</p>"},{"location":"extensions/#runnable.catalog.BaseCatalog","title":"runnable.catalog.BaseCatalog","text":"<p>             Bases: <code>ABC</code>, <code>BaseModel</code></p> <p>Base Catalog class definition.</p> <p>All implementations of the catalog handler should inherit and extend this class.</p> Source code in <code>runnable/catalog.py</code> <pre><code>class BaseCatalog(ABC, BaseModel):\n    \"\"\"\n    Base Catalog class definition.\n\n    All implementations of the catalog handler should inherit and extend this class.\n    \"\"\"\n\n    service_name: str = \"\"\n    service_type: str = \"catalog\"\n    model_config = ConfigDict(extra=\"forbid\")\n\n    @property\n    def _context(self):\n        return context.run_context\n\n    @property\n    def compute_data_folder(self) -&gt; str:\n        return defaults.COMPUTE_DATA_FOLDER\n\n    @abstractmethod\n    def get(self, name: str, run_id: str, compute_data_folder: str = \"\", **kwargs) -&gt; List[DataCatalog]:\n        \"\"\"\n        Get the catalog item by 'name' for the 'run id' and store it in compute data folder.\n\n        The catalog location should have been created before you can get from it.\n\n        Args:\n            name (str): The name of the catalog item\n            run_id (str): The run_id of the run.\n            compute_data_folder (str, optional): The compute data folder. Defaults to runnable default (data/)\n\n        Raises:\n            NotImplementedError: Base class, hence not implemented\n\n        Returns:\n            List(object) : A list of catalog objects\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def put(\n        self,\n        name: str,\n        run_id: str,\n        compute_data_folder: str = \"\",\n        synced_catalogs: Optional[List[DataCatalog]] = None,\n        **kwargs,\n    ) -&gt; List[DataCatalog]:\n        \"\"\"\n        Put the file by 'name' from the 'compute_data_folder' in the catalog for the run_id.\n\n        If previous syncing has happened and the file has not been changed, we do not sync again.\n\n        Args:\n            name (str): The name of the catalog item.\n            run_id (str): The run_id of the run.\n            compute_data_folder (str, optional): The compute data folder. Defaults to runnable default (data/)\n            synced_catalogs (dict, optional): Any previously synced catalogs. Defaults to None.\n\n        Raises:\n            NotImplementedError: Base class, hence not implemented\n\n        Returns:\n            List(object) : A list of catalog objects\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def sync_between_runs(self, previous_run_id: str, run_id: str):\n        \"\"\"\n        Given run_id of a previous run, sync them to the catalog of the run given by run_id\n\n        Args:\n            previous_run_id (str): The run id of the previous run\n            run_id (str): The run_id to which the data catalogs should be synced to.\n\n        Raises:\n            NotImplementedError: Base class, hence not implemented\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"extensions/#secrets","title":"Secrets","text":"<p>Register to namespace: [tool.poetry.plugins.\"secrets\"]</p> <p>Example: do-nothing,  env-secrets-manager,  dotenv</p>"},{"location":"extensions/#runnable.secrets.BaseSecrets","title":"runnable.secrets.BaseSecrets","text":"<p>             Bases: <code>ABC</code>, <code>BaseModel</code></p> <p>A base class for Secrets Handler. All implementations should extend this class.</p> <p>Raises:</p> <ul> <li> <code>NotImplementedError</code>           \u2013          <p>Base class and not implemented</p> </li> </ul> Source code in <code>runnable/secrets.py</code> <pre><code>class BaseSecrets(ABC, BaseModel):\n    \"\"\"\n    A base class for Secrets Handler.\n    All implementations should extend this class.\n\n    Raises:\n        NotImplementedError: Base class and not implemented\n    \"\"\"\n\n    service_name: str = \"\"\n    service_type: str = \"secrets\"\n    model_config = ConfigDict(extra=\"forbid\")\n\n    @property\n    def _context(self):\n        return context.run_context\n\n    @abstractmethod\n    def get(self, name: str, **kwargs) -&gt; str:\n        \"\"\"\n        Return the secret by name.\n\n        Args:\n            name (str): The name of the secret to return.\n\n        Raises:\n            NotImplementedError: Base class and hence not implemented.\n            exceptions.SecretNotFoundError: Secret not found in the secrets manager.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"extensions/#experiment_tracking","title":"Experiment tracking","text":"<p>Register to namespace: [tool.poetry.plugins.\"experiment_tracker\"]</p> <p>Example: do-nothing, <code>mlflow</code></p>"},{"location":"extensions/#runnable.experiment_tracker.BaseExperimentTracker","title":"runnable.experiment_tracker.BaseExperimentTracker","text":"<p>             Bases: <code>ABC</code>, <code>BaseModel</code></p> <p>Base Experiment tracker class definition.</p> Source code in <code>runnable/experiment_tracker.py</code> <pre><code>class BaseExperimentTracker(ABC, BaseModel):\n    \"\"\"\n    Base Experiment tracker class definition.\n    \"\"\"\n\n    service_name: str = \"\"\n    service_type: str = \"experiment_tracker\"\n\n    @property\n    def _context(self):\n        return context.run_context\n\n    model_config = ConfigDict(extra=\"forbid\")\n\n    @property\n    def client_context(self) -&gt; ContextManager:\n        \"\"\"\n        Returns the client context.\n        \"\"\"\n        return contextlib.nullcontext()\n\n    def publish_data(self, tracked_data: Dict[str, Any]):\n        for key, value in tracked_data.items():\n            if isinstance(value, dict):\n                for key2, value2 in value.items():\n                    self.log_metric(key, value2, step=key2)\n                continue\n            self.log_metric(key, value)\n\n    @abstractmethod\n    def log_metric(self, key: str, value: Union[int, float], step: int = 0):\n        \"\"\"\n        Sets the metric in the experiment tracking.\n\n        Args:\n            key (str): The key against you want to store the value\n            value (float): The value of the metric\n            step (int): Optional step at which it was recorded\n\n        Raises:\n            NotImplementedError: Base class, hence not implemented\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def log_parameter(self, key: str, value: Any):\n        \"\"\"\n        Logs a parameter in the experiment tracking.\n\n        Args:\n            key (str): The key against you want to store the value\n            value (any): The value of the metric\n\n        Raises:\n            NotImplementedError: Base class, hence not implemented\n        \"\"\"\n        pass\n</code></pre>"},{"location":"extensions/#nodes","title":"Nodes","text":"<p>Register to namespace: [tool.poetry.plugins.\"nodes\"]</p> <p>Example: task, stub, parallel, map</p>"},{"location":"extensions/#runnable.nodes.BaseNode","title":"runnable.nodes.BaseNode","text":"<p>             Bases: <code>ABC</code>, <code>BaseModel</code></p> <p>Base class with common functionality provided for a Node of a graph.</p> <p>A node of a graph could be a     * single execution node as task, success, fail.     * Could be graph in itself as parallel, dag and map.     * could be a convenience function like as-is.</p> <p>The name is relative to the DAG. The internal name of the node, is absolute name in dot path convention.     This has one to one mapping to the name in the run log The internal name of a node, should always be odd when split against dot.</p> <p>The internal branch name, only applies for branched nodes, is the branch it belongs to. The internal branch name should always be even when split against dot.</p> Source code in <code>runnable/nodes.py</code> <pre><code>class BaseNode(ABC, BaseModel):\n    \"\"\"\n    Base class with common functionality provided for a Node of a graph.\n\n    A node of a graph could be a\n        * single execution node as task, success, fail.\n        * Could be graph in itself as parallel, dag and map.\n        * could be a convenience function like as-is.\n\n    The name is relative to the DAG.\n    The internal name of the node, is absolute name in dot path convention.\n        This has one to one mapping to the name in the run log\n    The internal name of a node, should always be odd when split against dot.\n\n    The internal branch name, only applies for branched nodes, is the branch it belongs to.\n    The internal branch name should always be even when split against dot.\n    \"\"\"\n\n    node_type: str = Field(serialization_alias=\"type\")\n    name: str\n    internal_name: str = Field(exclude=True)\n    internal_branch_name: str = Field(default=\"\", exclude=True)\n    is_composite: bool = Field(default=False, exclude=True)\n\n    @property\n    def _context(self):\n        return context.run_context\n\n    model_config = ConfigDict(extra=\"forbid\", arbitrary_types_allowed=False)\n\n    @field_validator(\"name\")\n    @classmethod\n    def validate_name(cls, name: str):\n        if \".\" in name or \"%\" in name:\n            raise ValueError(\"Node names cannot have . or '%' in them\")\n        return name\n\n    def _command_friendly_name(self, replace_with=defaults.COMMAND_FRIENDLY_CHARACTER) -&gt; str:\n        \"\"\"\n        Replace spaces with special character for spaces.\n        Spaces in the naming of the node is convenient for the user but causes issues when used programmatically.\n\n        Returns:\n            str: The command friendly name of the node\n        \"\"\"\n        return self.internal_name.replace(\" \", replace_with)\n\n    @classmethod\n    def _get_internal_name_from_command_name(cls, command_name: str) -&gt; str:\n        \"\"\"\n        Replace runnable specific character (%) with whitespace.\n        The opposite of _command_friendly_name.\n\n        Args:\n            command_name (str): The command friendly node name\n\n        Returns:\n            str: The internal name of the step\n        \"\"\"\n        return command_name.replace(defaults.COMMAND_FRIENDLY_CHARACTER, \" \")\n\n    @classmethod\n    def _resolve_map_placeholders(cls, name: str, map_variable: TypeMapVariable = None) -&gt; str:\n        \"\"\"\n        If there is no map step used, then we just return the name as we find it.\n\n        If there is a map variable being used, replace every occurrence of the map variable placeholder with\n        the value sequentially.\n\n        For example:\n        1). dag:\n              start_at: step1\n              steps:\n                step1:\n                    type: map\n                    iterate_on: y\n                    iterate_as: y_i\n                    branch:\n                        start_at: map_step1\n                        steps:\n                            map_step1: # internal_name step1.placeholder.map_step1\n                                type: task\n                                command: a.map_func\n                                command_type: python\n                                next: map_success\n                            map_success:\n                                type: success\n                            map_failure:\n                                type: fail\n\n            and if y is ['a', 'b', 'c'].\n\n            This method would be called 3 times with map_variable = {'y_i': 'a'}, map_variable = {'y_i': 'b'} and\n            map_variable = {'y_i': 'c'} corresponding to the three branches.\n\n        For nested map branches, we would get the map_variables ordered hierarchically.\n\n        Args:\n            name (str): The name to resolve\n            map_variable (dict): The dictionary of map variables\n\n        Returns:\n            [str]: The resolved name\n        \"\"\"\n        if not map_variable:\n            return name\n\n        for _, value in map_variable.items():\n            name = name.replace(defaults.MAP_PLACEHOLDER, str(value), 1)\n\n        return name\n\n    def _get_step_log_name(self, map_variable: TypeMapVariable = None) -&gt; str:\n        \"\"\"\n        For every step in the dag, there is a corresponding step log name.\n        This method returns the step log name in dot path convention.\n\n        All node types except a map state has a \"static\" defined step_log names and are equivalent to internal_name.\n        For nodes belonging to map state, the internal name has a placeholder that is replaced at runtime.\n\n        Args:\n            map_variable (dict): If the node is of type map, the names are based on the current iteration state of the\n            parameter.\n\n        Returns:\n            str: The dot path name of the step log name\n        \"\"\"\n        return self._resolve_map_placeholders(self.internal_name, map_variable=map_variable)\n\n    def _get_branch_log_name(self, map_variable: TypeMapVariable = None) -&gt; str:\n        \"\"\"\n        For nodes that are internally branches, this method returns the branch log name.\n        The branch log name is in dot path convention.\n\n        For nodes that are not map, the internal branch name is equivalent to the branch name.\n        For map nodes, the internal branch name has a placeholder that is replaced at runtime.\n\n        Args:\n            map_variable (dict): If the node is of type map, the names are based on the current iteration state of the\n            parameter.\n\n        Returns:\n            str: The dot path name of the branch log\n        \"\"\"\n        return self._resolve_map_placeholders(self.internal_branch_name, map_variable=map_variable)\n\n    def __str__(self) -&gt; str:  # pragma: no cover\n        \"\"\"\n        String representation of the node.\n\n        Returns:\n            str: The string representation of the node.\n        \"\"\"\n        return f\"Node of type {self.node_type} and name {self.internal_name}\"\n\n    @abstractmethod\n    def _get_on_failure_node(self) -&gt; str:\n        \"\"\"\n        If the node defines a on_failure node in the config, return this or None.\n\n        The naming is relative to the dag, the caller is supposed to resolve it to the correct graph\n\n        Returns:\n            str: The on_failure node defined by the dag or ''\n        This is a base implementation which the BaseNode does not satisfy\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def _get_next_node(self) -&gt; str:\n        \"\"\"\n        Return the next node as defined by the config.\n\n        Returns:\n            str: The node name, relative to the dag, as defined by the config\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def _is_terminal_node(self) -&gt; bool:\n        \"\"\"\n        Returns whether a node has a next node\n\n        Returns:\n            bool: True or False of whether there is next node.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def _get_catalog_settings(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        If the node defines a catalog settings, return it or None\n\n        Returns:\n            dict: catalog settings defined as per the node or None\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def _get_branch_by_name(self, branch_name: str):\n        \"\"\"\n        Retrieve a branch by name.\n\n        The name is expected to follow a dot path convention.\n\n        Args:\n            branch_name (str): [description]\n\n        Raises:\n            Exception: [description]\n        \"\"\"\n        ...\n\n    def _get_neighbors(self) -&gt; List[str]:\n        \"\"\"\n        Gets the connecting neighbor nodes, either the \"next\" node or \"on_failure\" node.\n\n        Returns:\n            list: List of connected neighbors for a given node. Empty if terminal node.\n        \"\"\"\n        neighbors = []\n        try:\n            next_node = self._get_next_node()\n            neighbors += [next_node]\n        except exceptions.TerminalNodeError:\n            pass\n\n        try:\n            fail_node = self._get_on_failure_node()\n            if fail_node:\n                neighbors += [fail_node]\n        except exceptions.TerminalNodeError:\n            pass\n\n        return neighbors\n\n    @abstractmethod\n    def _get_executor_config(self, executor_type: str) -&gt; str:\n        \"\"\"\n        Return the executor config of the node, if defined, or empty dict\n\n        Args:\n            executor_type (str): The executor type that the config refers to.\n\n        Returns:\n            dict: The executor config, if defined or an empty dict\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def _get_max_attempts(self) -&gt; int:\n        \"\"\"\n        The number of max attempts as defined by the config or 1.\n\n        Returns:\n            int: The number of maximum retries as defined by the config or 1.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def execute(\n        self,\n        mock=False,\n        map_variable: TypeMapVariable = None,\n        attempt_number: int = 1,\n        **kwargs,\n    ) -&gt; StepLog:\n        \"\"\"\n        The actual function that does the execution of the command in the config.\n\n        Should only be implemented for task, success, fail and as-is and never for\n        composite nodes.\n\n        Args:\n            executor (runnable.executor.BaseExecutor): The executor class\n            mock (bool, optional): Don't run, just pretend. Defaults to False.\n            map_variable (str, optional): The value of the map iteration variable, if part of a map node.\n                Defaults to ''.\n\n        Raises:\n            NotImplementedError: Base class, hence not implemented.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def execute_as_graph(self, map_variable: TypeMapVariable = None, **kwargs):\n        \"\"\"\n        This function would be called to set up the execution of the individual\n        branches of a composite node.\n\n        Function should only be implemented for composite nodes like dag, map, parallel.\n\n        Args:\n            executor (runnable.executor.BaseExecutor): The executor.\n\n        Raises:\n            NotImplementedError: Base class, hence not implemented.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def fan_out(self, map_variable: TypeMapVariable = None, **kwargs):\n        \"\"\"\n        This function would be called to set up the execution of the individual\n        branches of a composite node.\n\n        Function should only be implemented for composite nodes like dag, map, parallel.\n\n        Args:\n            executor (runnable.executor.BaseExecutor): The executor.\n            map_variable (str, optional): The value of the map iteration variable, if part of a map node.\n\n        Raises:\n            Exception: If the node is not a composite node.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def fan_in(self, map_variable: TypeMapVariable = None, **kwargs):\n        \"\"\"\n        This function would be called to tear down the execution of the individual\n        branches of a composite node.\n\n        Function should only be implemented for composite nodes like dag, map, parallel.\n\n        Args:\n            executor (runnable.executor.BaseExecutor): The executor.\n            map_variable (str, optional): The value of the map iteration variable, if part of a map node.\n\n        Raises:\n            Exception: If the node is not a composite node.\n        \"\"\"\n        ...\n\n    @classmethod\n    @abstractmethod\n    def parse_from_config(cls, config: Dict[str, Any]) -&gt; \"BaseNode\":\n        \"\"\"\n        Parse the config from the user and create the corresponding node.\n\n        Args:\n            config (Dict[str, Any]): The config of the node from the yaml or from the sdk.\n\n        Returns:\n            BaseNode: The corresponding node.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"extensions/#tasks","title":"Tasks","text":"<p>Register to namespace: [tool.poetry.plugins.\"tasks\"]</p> <p>Example: python, shell, notebook</p>"},{"location":"extensions/#runnable.tasks.BaseTaskType","title":"runnable.tasks.BaseTaskType","text":"<p>             Bases: <code>BaseModel</code></p> <p>A base task class which does the execution of command defined by the user.</p> Source code in <code>runnable/tasks.py</code> <pre><code>class BaseTaskType(BaseModel):\n    \"\"\"A base task class which does the execution of command defined by the user.\"\"\"\n\n    task_type: str = Field(serialization_alias=\"command_type\")\n    node_name: str = Field(exclude=True)\n    secrets: Dict[str, str] = Field(default_factory=dict)\n    returns: List[TaskReturns] = Field(default_factory=list, alias=\"returns\")\n\n    model_config = ConfigDict(extra=\"forbid\")\n\n    @property\n    def _context(self):\n        return context.run_context\n\n    def get_cli_options(self) -&gt; Tuple[str, dict]:\n        \"\"\"\n        Key is the name of the cli option and value is the value of the cli option.\n        This should always be in sync with the cli options defined in execute_*.\n\n        Returns:\n            str: The name of the cli option.\n            dict: The dict of cli options for the task.\n\n        Raises:\n            NotImplementedError: Base class, not implemented\n        \"\"\"\n        raise NotImplementedError()\n\n    def set_secrets_as_env_variables(self):\n        for key, value in self.secrets.items():\n            secret_value = context.run_context.secrets_handler.get(key)\n            self.secrets[value] = secret_value\n            os.environ[value] = secret_value\n\n    def delete_secrets_from_env_variables(self):\n        for _, value in self.secrets.items():\n            if value in os.environ:\n                del os.environ[value]\n\n    def execute_command(\n        self,\n        map_variable: TypeMapVariable = None,\n        **kwargs,\n    ) -&gt; StepAttempt:\n        \"\"\"The function to execute the command.\n\n        And map_variable is sent in as an argument into the function.\n\n        Args:\n            map_variable (dict, optional): If the command is part of map node, the value of map. Defaults to None.\n\n        Raises:\n            NotImplementedError: Base class, not implemented\n        \"\"\"\n        raise NotImplementedError()\n\n    @contextlib.contextmanager\n    def expose_secrets(self):\n        \"\"\"Context manager to expose secrets to the execution.\n\n        Args:\n            map_variable (dict, optional): If the command is part of map node, the value of map. Defaults to None.\n\n        \"\"\"\n        self.set_secrets_as_env_variables()\n        try:\n            yield\n        finally:\n            self.delete_secrets_from_env_variables()\n\n    @contextlib.contextmanager\n    def execution_context(self, map_variable: TypeMapVariable = None, allow_complex: bool = True):\n        params = self._context.run_log_store.get_parameters(run_id=self._context.run_id).copy()\n\n        for param_name, param in params.items():\n            # Any access to unreduced param should be replaced.\n            # The replacement is the context param\n            # It is possible that the unreduced param is not created as no upstream step\n            # has created it yet.\n            if param.reduced is False:\n                context_param = param_name\n                for _, v in map_variable.items():  # type: ignore\n                    context_param = f\"{context_param}_{v}\"\n\n                if context_param in params:\n                    params[param_name].value = params[context_param].value\n\n        if not allow_complex:\n            params = {key: value for key, value in params.items() if isinstance(value, JsonParameter)}\n\n        log_file_name = self.node_name.replace(\" \", \"_\") + \".execution.log\"\n        if map_variable:\n            for _, value in map_variable.items():\n                log_file_name += \"_\" + str(value)\n\n        log_file = open(log_file_name, \"w\")\n\n        f = io.StringIO()\n        try:\n            with contextlib.redirect_stdout(f):\n                yield params\n        finally:\n            print(f.getvalue())  # print to console\n            log_file.write(f.getvalue())  # Print to file\n\n            f.close()\n            log_file.close()\n\n            # Put the log file in the catalog\n            catalog_handler = context.run_context.catalog_handler\n            catalog_handler.put(name=log_file.name, run_id=context.run_context.run_id)\n            os.remove(log_file.name)\n\n            # Update parameters\n            self._context.run_log_store.set_parameters(parameters=params, run_id=self._context.run_id)\n\n            return True  # To suppress exceptions\n</code></pre>"},{"location":"roadmap/","title":"Roadmap","text":""},{"location":"roadmap/#aws_environments","title":"AWS environments","text":"<p>Bring in native AWS services to orchestrate workflows. The stack should be:</p> <ul> <li>AWS step functions.</li> <li>Sagemaker jobs - Since they can take dynamic image name, AWS batch needs job definition and can be tricky.</li> <li>S3 for Run log and Catalog: Already tested and working prototype.</li> <li>AWS secrets manager: Access to AWS secrets manager via the RBAC of the execution role.</li> </ul>"},{"location":"roadmap/#hpc_environment_using_slurm_executor","title":"HPC environment using SLURM executor.","text":"<ul> <li>Without native orchestration tools, the preferred way is to run it as local but use SLURM to schedule jobs.</li> </ul>"},{"location":"roadmap/#database_based_run_log_store","title":"Database based Run log store.","text":""},{"location":"roadmap/#better_integrations_with_experiment_tracking_tools","title":"Better integrations with experiment tracking tools.","text":"<p>Currently, the implementation of experiment tracking tools within runnable is limited. It might be better to choose a good open source implementation and stick with it.</p>"},{"location":"roadmap/#model_registry_service","title":"Model registry service","text":"<p>Could be interesting to bring in a model registry to catalog models.</p>"},{"location":"sdk/","title":"Python SDK","text":""},{"location":"sdk/#runnable.Catalog","title":"runnable.Catalog","text":"<p>Use to instruct a task to sync data from/to the central catalog. Please refer to concepts for more information.</p> <p>Attributes:</p> <ul> <li> <code>get</code>             (<code>List[str]</code>)         \u2013          <p>List of glob patterns to get from central catalog to the compute data folder.</p> </li> <li> <code>put</code>             (<code>List[str]</code>)         \u2013          <p>List of glob patterns to put into central catalog from the compute data folder.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from runnable import Catalog, Task\n&gt;&gt;&gt; catalog = Catalog(compute_data_folder=\"/path/to/data\", get=[\"*.csv\"], put=[\"*.csv\"])\n</code></pre> <pre><code>&gt;&gt;&gt; task = Task(name=\"task\", catalog=catalog, command=\"echo 'hello'\")\n</code></pre>"},{"location":"sdk/#runnable.Stub","title":"runnable.Stub","text":"<p>A node that does nothing.</p> <p>A stub node can tak arbitrary number of arguments. Please refer to concepts for more information.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>The name of the node.</p> </li> <li> <code>terminate_with_failure</code>             (<code>bool</code>)         \u2013          <p>Whether to terminate the pipeline with a failure after this node.</p> </li> <li> <code>terminate_with_success</code>             (<code>bool</code>)         \u2013          <p>Whether to terminate the pipeline with a success after this node.</p> </li> </ul>"},{"location":"sdk/#runnable.PythonTask","title":"runnable.PythonTask","text":"<p>An execution node of the pipeline of python functions. Please refer to concepts for more information.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>The name of the node.</p> </li> <li> <code>function</code>             (<code>callable</code>)         \u2013          <p>The function to execute.</p> </li> <li> <code>catalog</code>             (<code>Optional[Catalog]</code>)         \u2013          <p>The catalog to sync data from/to. Please see Catalog about the structure of the catalog.</p> </li> <li> <code>overrides</code>             (<code>Dict[str, Any]</code>)         \u2013          <p>Any overrides to the command. Individual tasks can override the global configuration config by referring to the specific override.</p> <p>For example,</p> </li> <li> <code>terminate_with_failure</code>             (<code>bool</code>)         \u2013          <p>Whether to terminate the pipeline with a failure after this node.</p> </li> <li> <code>terminate_with_success</code>             (<code>bool</code>)         \u2013          <p>Whether to terminate the pipeline with a success after this node.</p> </li> <li> <code>on_failure</code>             (<code>str</code>)         \u2013          <p>The name of the node to execute if the step fails.</p> </li> </ul>"},{"location":"sdk/#runnable.PythonTask--global_configuration","title":"Global configuration","text":"<pre><code>executor:\n  type: local-container\n  config:\n    docker_image: \"runnable/runnable:latest\"\n    overrides:\n      custom_docker_image:\n        docker_image: \"runnable/runnable:custom\"\n</code></pre>"},{"location":"sdk/#runnable.PythonTask--task_specific_configuration","title":"Task specific configuration","text":"<pre><code>task = PythonTask(name=\"task\", function=\"function'\",\n        overrides={'local-container': custom_docker_image})\n</code></pre>"},{"location":"sdk/#runnable.ShellTask","title":"runnable.ShellTask","text":"<p>An execution node of the pipeline of type shell. Please refer to concepts for more information.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>The name of the node.</p> </li> <li> <code>command</code>             (<code>str</code>)         \u2013          <p>The shell command to execute.</p> </li> <li> <code>catalog</code>             (<code>Optional[Catalog]</code>)         \u2013          <p>The catalog to sync data from/to. Please see Catalog about the structure of the catalog.</p> </li> <li> <code>returns</code>             (<code>Optional[Catalog]</code>)         \u2013          <p>A list of the names of variables to capture from environment variables of shell.</p> </li> <li> <code>overrides</code>             (<code>Dict[str, Any]</code>)         \u2013          <p>Any overrides to the command. Individual tasks can override the global configuration config by referring to the specific override.</p> <p>For example,</p> </li> <li> <code>terminate_with_failure</code>             (<code>bool</code>)         \u2013          <p>Whether to terminate the pipeline with a failure after this node.</p> </li> <li> <code>terminate_with_success</code>             (<code>bool</code>)         \u2013          <p>Whether to terminate the pipeline with a success after this node.</p> </li> <li> <code>on_failure</code>             (<code>str</code>)         \u2013          <p>The name of the node to execute if the step fails.</p> </li> </ul>"},{"location":"sdk/#runnable.ShellTask--global_configuration","title":"Global configuration","text":"<pre><code>executor:\n  type: local-container\n  config:\n    docker_image: \"runnable/runnable:latest\"\n    overrides:\n      custom_docker_image:\n        docker_image: \"runnable/runnable:custom\"\n</code></pre>"},{"location":"sdk/#runnable.ShellTask--task_specific_configuration","title":"Task specific configuration","text":"<pre><code>task = ShellTask(name=\"task\", command=\"exit 0\",\n        overrides={'local-container': custom_docker_image})\n</code></pre>"},{"location":"sdk/#runnable.NotebookTask","title":"runnable.NotebookTask","text":"<p>An execution node of the pipeline of type notebook. Please refer to concepts for more information.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>The name of the node.</p> </li> <li> <code>notebook</code>             (<code>str</code>)         \u2013          <p>The path to the notebook</p> </li> <li> <code>catalog</code>             (<code>Optional[Catalog]</code>)         \u2013          <p>The catalog to sync data from/to. Please see Catalog about the structure of the catalog.</p> </li> <li> <code>returns</code>             (<code>Optional[Catalog]</code>)         \u2013          <p>A list of the names of variables to return from the notebook.</p> </li> <li> <code>overrides</code>             (<code>Dict[str, Any]</code>)         \u2013          <p>Any overrides to the command. Individual tasks can override the global configuration config by referring to the specific override.</p> <p>For example,</p> </li> <li> <code>notebook_output_path</code>             (<code>Optional[str]</code>)         \u2013          <p>The path to save the notebook output. Only used when command_type is 'notebook', defaults to command+_out.ipynb</p> </li> <li> <code>optional_ploomber_args</code>             (<code>Optional[Dict[str, Any]]</code>)         \u2013          <p>Any optional ploomber args. Only used when command_type is 'notebook', defaults to {}</p> </li> <li> <code>terminate_with_failure</code>             (<code>bool</code>)         \u2013          <p>Whether to terminate the pipeline with a failure after this node.</p> </li> <li> <code>terminate_with_success</code>             (<code>bool</code>)         \u2013          <p>Whether to terminate the pipeline with a success after this node.</p> </li> <li> <code>on_failure</code>             (<code>str</code>)         \u2013          <p>The name of the node to execute if the step fails.</p> </li> </ul>"},{"location":"sdk/#runnable.NotebookTask--global_configuration","title":"Global configuration","text":"<pre><code>executor:\n  type: local-container\n  config:\n    docker_image: \"runnable/runnable:latest\"\n    overrides:\n      custom_docker_image:\n        docker_image: \"runnable/runnable:custom\"\n</code></pre>"},{"location":"sdk/#runnable.NotebookTask--task_specific_configuration","title":"Task specific configuration","text":"<pre><code>task = NotebookTask(name=\"task\", notebook=\"evaluation.ipynb\",\n        overrides={'local-container': custom_docker_image})\n</code></pre>"},{"location":"sdk/#runnable.Parallel","title":"runnable.Parallel","text":"<p>A node that executes multiple branches in parallel. Please refer to concepts for more information.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>The name of the node.</p> </li> <li> <code>branches</code>             (<code>Dict[str, Pipeline]</code>)         \u2013          <p>A dictionary of branches to execute in parallel.</p> </li> <li> <code>terminate_with_failure</code>             (<code>bool</code>)         \u2013          <p>Whether to terminate the pipeline with a failure after this node.</p> </li> <li> <code>terminate_with_success</code>             (<code>bool</code>)         \u2013          <p>Whether to terminate the pipeline with a success after this node.</p> </li> <li> <code>on_failure</code>             (<code>str</code>)         \u2013          <p>The name of the node to execute if any of the branches fail.</p> </li> </ul>"},{"location":"sdk/#runnable.Map","title":"runnable.Map","text":"<p>A node that iterates over a list of items and executes a pipeline for each item. Please refer to concepts for more information.</p> <p>Attributes:</p> <ul> <li> <code>branch</code>             (<code>'Pipeline'</code>)         \u2013          <p>The pipeline to execute for each item.</p> </li> <li> <code>iterate_on</code>             (<code>str</code>)         \u2013          <p>The name of the parameter to iterate over. The parameter should be defined either by previous steps or statically at the start of execution.</p> </li> <li> <code>iterate_as</code>             (<code>str</code>)         \u2013          <p>The name of the iterable to be passed to functions.</p> </li> <li> <code>overrides</code>             (<code>Dict[str, Any]</code>)         \u2013          <p>Any overrides to the command.</p> </li> </ul>"},{"location":"sdk/#runnable.Success","title":"runnable.Success","text":"<p>A node that represents a successful execution of the pipeline.</p> <p>Most often, there is no need to use this node as nodes can be instructed to terminate_with_success and pipeline with add_terminal_nodes=True.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>The name of the node.</p> </li> </ul>"},{"location":"sdk/#runnable.Fail","title":"runnable.Fail","text":"<p>A node that represents a failed execution of the pipeline.</p> <p>Most often, there is no need to use this node as nodes can be instructed to terminate_with_failure and pipeline with add_terminal_nodes=True.</p> <p>Attributes:</p> <ul> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>The name of the node.</p> </li> </ul>"},{"location":"sdk/#runnable.Pipeline","title":"runnable.Pipeline","text":"<p>A Pipeline is a directed acyclic graph of Steps that define a workflow.</p> <p>Attributes:</p> <ul> <li> <code>steps</code>             (<code>List[Stub | PythonTask | NotebookTask | ShellTask | Parallel | Map | Success | Fail]</code>)         \u2013          <p>A list of Steps that make up the Pipeline.</p> </li> <li> <code>start_at</code>             (<code>Stub | Task | Parallel | Map</code>)         \u2013          <p>The name of the first Step in the Pipeline.</p> </li> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>The name of the Pipeline. Defaults to \"\".</p> </li> <li> <code>description</code>             (<code>str</code>)         \u2013          <p>A description of the Pipeline. Defaults to \"\".</p> </li> <li> <code>add_terminal_nodes</code>             (<code>bool</code>)         \u2013          <p>Whether to add terminal nodes to the Pipeline. Defaults to True.</p> </li> </ul> <p>The default behavior is to add \"success\" and \"fail\" nodes to the Pipeline. To add custom success and fail nodes, set add_terminal_nodes=False and create success and fail nodes manually.</p>"},{"location":"sdk/#runnable.Pipeline.execute","title":"execute","text":"<pre><code>execute(configuration_file: str = '', run_id: str = '', tag: str = '', parameters_file: str = '', log_level: str = defaults.LOG_LEVEL)\n</code></pre> <p>Execute the Pipeline.</p> <p>Execution of pipeline could either be:</p> <p>Traverse and execute all the steps of the pipeline, eg. local execution.</p> <p>Or create the <code>yaml</code> representation of the pipeline for other executors.</p> <p>Please refer to concepts for more information.</p> <p>Parameters:</p> <ul> <li> <code>configuration_file</code>             (<code>str</code>, default:                 <code>''</code> )         \u2013          <p>The path to the configuration file. Defaults to \"\". The configuration file can be overridden by the environment variable runnable_CONFIGURATION_FILE.</p> </li> <li> <code>run_id</code>             (<code>str</code>, default:                 <code>''</code> )         \u2013          <p>The ID of the run. Defaults to \"\".</p> </li> <li> <code>tag</code>             (<code>str</code>, default:                 <code>''</code> )         \u2013          <p>The tag of the run. Defaults to \"\". Use to group multiple runs.</p> </li> <li> <code>parameters_file</code>             (<code>str</code>, default:                 <code>''</code> )         \u2013          <p>The path to the parameters file. Defaults to \"\".</p> </li> <li> <code>use_cached</code>             (<code>str</code>)         \u2013          <p>Whether to use cached results. Defaults to \"\". Provide the run_id of the older execution to recover.</p> </li> <li> <code>log_level</code>             (<code>str</code>, default:                 <code>LOG_LEVEL</code> )         \u2013          <p>The log level. Defaults to defaults.LOG_LEVEL.</p> </li> </ul>"},{"location":"sdk/#runnable.Pipeline.model_post_init","title":"model_post_init","text":"<pre><code>model_post_init(__context: Any) -&gt; None\n</code></pre> The sequence of steps can either be <p>[step1, step2,..., stepN, [step11, step12,..., step1N], [step21, step22,...,]] indicates:     - step1 &gt; step2 &gt; ... &gt; stepN     - We expect terminate with success or fail to be explicitly stated on a step.         - If it is stated, the step cannot have a next step defined apart from \"success\" and \"fail\".</p> <pre><code>The inner list of steps is only to accommodate on-failure behaviors.\n    - For sake of simplicity, lets assume that it has the same behavior as the happy pipeline.\n    - A task which was already seen should not be part of this.\n    - There should be at least one step which terminates with success\n\nAny definition of pipeline should have one node that terminates with success.\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#installation","title":"Installation","text":"<p>runnable is a python package and should be installed like any other python package. The minimum python version is <code>3.8</code></p> <pre><code>pip install runnable\n</code></pre> <p>We recommend the installation in a virtual environment using <code>poetry</code> or any other package manager.</p>"},{"location":"usage/#extras","title":"Extras","text":""},{"location":"usage/#docker","title":"Docker","text":"<p>To run the pipelines/functions/notebooks in a container, install runnable with docker functionality.</p> <pre><code>pip install \"runnable[docker]\"\n</code></pre>"},{"location":"usage/#notebook","title":"Notebook","text":"<p>To use notebooks as tasks, install runnable with <code>notebook</code> functionality.</p> <pre><code>pip install \"runnable[notebook]\"\n</code></pre>"},{"location":"usage/#usage","title":"Usage","text":"<p>Pipelines defined in runnable can be either via python sdk or <code>yaml</code> based definitions.</p> <p>To execute a pipeline, defined in <code>yaml</code>, use the runnable cli. The options are detailed below:</p> <ul> <li><code>-f, --file</code> (str): The pipeline definition file, defaults to pipeline.yaml</li> <li><code>-c, --config-file</code> (str): config file to be used for the run [default: None]</li> <li><code>-p, --parameters-file</code> (str): Parameters  accessible by the application [default: None]</li> <li><code>--log-level</code> : The log level, one of <code>INFO | DEBUG | WARNING| ERROR| FATAL</code> [default: INFO]</li> <li><code>--tag</code> (str): A tag attached to the run[default: ]</li> <li><code>--run-id</code> (str): An optional run_id, one would be generated if not provided</li> <li><code>--use-cached</code> (str): Provide the previous run_id to re-run.</li> </ul>"},{"location":"usage/#examples","title":"Examples","text":"<p>All the examples in the documentation are present in the <code>examples</code> directory of the repo with instructions on how to run them.</p> <p>All the examples are tested, with multiple configurations, as part of our CI test suite.</p>"},{"location":"why-runnable/","title":"Why runnable","text":"<p>runnable allows the data scientists/engineers to hook into production stack without knowledge of them. It offers a simpler abstraction of the concepts found in production stack thereby aligning to the production standards even during development.</p> <p>runnable is not a end to end deployment platform but limited to be an aid during the development phase without modifying the production stack or application code.</p> <ul> <li> <p> Easy to adopt, its mostly your code</p> <p>Your application code remains as it is. Runnable exists outside of it.</p> <p> Getting started</p> </li> <li> <p> Bring your infrastructure</p> <p>Runnable can be adapted to your infrastructure stack instead of dictating it.</p> <p> Infrastructure</p> </li> <li> <p> Reproducibility</p> <p>Runnable tracks key information to reproduce the execution.</p> <p> Run Log</p> </li> <li> <p> Retry failues</p> <p>Debug any failure in your local development environment.</p> <p> Retry</p> </li> <li> <p> Testing</p> <p>Unit test your code and pipelines.</p> <p> Test</p> </li> <li> <p> Move on</p> <p>Moving away from runnable is as simple as deleting relevant files.</p> </li> </ul>"},{"location":"why-runnable/#alternatives","title":"Alternatives","text":"<p>runnable as an SDK competes with</p> <p>Kedro and metaflow are also based on similar ideas and have established presence in this field. We took a lot of inspiration from these excellent projects when writing runnable.</p> <p>Caveat</p> <p>The scope of runnable is limited in comparison to metaflow. The below points are on the design philosophy rather that implementation specifics.</p> <p>The highlighted differences are subjective opinions and should be taken as preferences rather than criticisms.</p>"},{"location":"why-runnable/#infrastructure","title":"Infrastructure","text":"<p>Metaflow stipulates infrastructure prerequisites that are established and validated across numerous scenarios.</p> <p>In contrast, runnable empowers engineering teams to define infrastructure specifications through a configuration file tailored to the stack they maintain. This versatility enables specialized teams to leverage their domain expertise, thereby enhancing the project's overall efficacy.</p> <p>As runnable is mostly responsible for translating workflows to infrastructure patterns, it can adapt to different environments.</p>"},{"location":"why-runnable/#project_structure","title":"Project structure","text":"<p>Kedro and metaflow come with their own predefined project structures, which might be appealing to some users while others might find them restrictive.</p> <p>runnable, on the other hand, offers a more flexible approach. It doesn't impose a specific structure on your project. Whether you're working with Python functions, Jupyter notebooks, or shell scripts, runnable allows you to organize your work as you see fit. Even the location of the data folder can be tailored for each step, avoiding a one-size-fits-all design and providing the freedom to structure your project in a way that suits your preferences and requirements.</p>"},{"location":"why-runnable/#notebook_support","title":"Notebook support","text":"<p>Both metaflow and kedro do not support notebooks as tasks. Notebooks are great during the iterative phase of the project allowing for interactive development.</p> <p>runnable supports notebooks as tasks and has the ability to pass data/parameters between them to allow orchestrating notebooks.</p>"},{"location":"why-runnable/#testing_pipelines","title":"Testing pipelines","text":"<p>runnable supports patching and mocking tasks to test the end to end execution of the pipeline. It is not clear on how to achieve the same in kedro or metaflow.</p>"},{"location":"why-runnable/#learning_curve","title":"Learning curve","text":"<p>runnable allows tasks to stand on their own, separate from the orchestration system. Explaining and understanding these tasks is made easy through the use of simple \"driver\" functions. This approach makes it easier for anyone working on the project to get up to speed and maintain it, as the orchestration part of runnable remains distinct and straightforward.</p> <p>In contrast, learning to use Kedro and Metaflow can take more time because they have their own specific ways of structuring projects and code that users need to learn.</p>"},{"location":"why-runnable/#language_support","title":"Language support","text":"<p>Kedro and metaflow only support python based pipeline definitions. It is possible to run the non-python tasks as <code>subprocesses</code> in the pipeline tasks but the definition is only possible using the python API.</p> <p>runnable supports <code>yaml</code> based pipeline definitions and has <code>shell</code> tasks which can be used for non-python tasks.</p>"},{"location":"concepts/catalog/","title":"Catalog","text":"<p>Opt out</p> <p>Pipelines need not use the <code>catalog</code> if they prefer other ways to transfer data between tasks. The default configuration of <code>do-nothing</code> is no-op by design. We kindly request to raise a feature request to make us aware of the eco-system.</p>"},{"location":"concepts/catalog/#todo_simplify_this","title":"TODO: Simplify this","text":"<p>Catalog provides a way to store and retrieve data generated by the individual steps of the dag to downstream steps of the dag. It can be any storage system that indexes its data by a unique identifier.</p> <p>For example, a local directory structure partitioned by a <code>run_id</code> or S3 bucket prefixed by <code>run_id</code>.</p> <p>Checkpoint</p> <p>Cataloging happens even if the step execution eventually fails. This behavior can be used to recover from a failed run from a checkpoint.</p> <p>The directory structure within a partition is the same as the project directory structure. This enables you to get/put data in the catalog as if you are working with local directory structure. Every interaction with the catalog (either by API or configuration) results in an entry in the <code>run log</code></p> <p>Internally, runnable also uses the catalog to store execution logs of tasks i.e stdout and stderr from python or shell and executed notebook from notebook tasks.</p> <p>Since the catalog captures the data files flowing through the pipeline and the execution logs, it enables you to debug failed pipelines or keep track of data lineage.</p> <p>Storage considerations</p> <p>Since the data is stored per-run, it might cause the catalog to inflate.</p> <p>Please consider some clean up mechanisms to regularly prune catalog for executions that are not relevant.</p>"},{"location":"concepts/catalog/#example","title":"Example","text":"Configurationpython sdkyaml <p>Below is a sample configuration that uses the local file system as a catalog store. The default location of the catalog is <code>.catalog</code> and is configurable.</p> <p>Every execution of the pipeline will create a sub-directory of name <code>run_id</code> to store the artifacts generated from the execution of the pipeline.</p> <pre><code>catalog:\n  type: file-system # (1)\n</code></pre> <ol> <li>Use local file system as a central catalog, defaults to <code>.catalog</code></li> </ol> <p>In the below example, the steps <code>create_content_in_data_folder</code> and <code>create_content_in_another_folder</code> create content for downstream steps, i.e <code>retrieve_content_from_both</code> to consume.</p> <p>Delete?</p> <p>Since we are executing in local compute and creating sub-directory <code>another</code>, it might be mistaken that we are not cataloging anything. We delete <code>another</code> directory between steps to demonstrate that we indeed move files in and out of the catalog.</p> <p>The highlighted lines in the below example show how to specify the files to get/put from the catalog using python SDK.</p> <pre><code>\"\"\"\nA pipeline to demonstrate using the catalog service to create and retrieve content.\n\nYou can run this pipeline by:\n    python run examples/concepts/catalog.py\n\"\"\"\n\nfrom pathlib import Path\n\n\ndef create_content_in_data_folder():\n    \"\"\"\n    Create a data directory and write a file \"hello.txt\" in the data folder.\n    \"\"\"\n    Path(\"data\").mkdir(parents=True, exist_ok=True)\n    with open(Path(\"data\") / \"hello.txt\", \"w\") as f:\n        f.write(\"Hello from data folder!!\")\n\n\ndef create_content_in_another_folder():\n    \"\"\"\n    Create a \"another\" directory and write a file \"world.txt\" in it.\n    \"\"\"\n    Path(\"another\").mkdir(parents=True, exist_ok=True)\n    with open(Path(\"another\") / \"world.txt\", \"w\") as f:\n        f.write(\"Hello from another folder!!\")\n\n\ndef retrieve_content_from_both():\n    \"\"\"\n    Display the contents of the files in data and \"another\" folder\n    \"\"\"\n    with open(Path(\"data\") / \"hello.txt\", \"r\") as f:\n        print(f.read())\n\n    with open(Path(\"another\") / \"world.txt\", \"r\") as f:\n        print(f.read())\n\n\ndef main():\n    from runnable import Catalog, Pipeline, PythonTask, ShellTask\n\n    # This step creates a file in the data folder and syncs it to the catalog.\n    data_catalog = Catalog(put=[\"data/hello.txt\"])\n    data_create = PythonTask(\n        name=\"create_content_in_data_folder\",\n        function=create_content_in_data_folder,\n        catalog=data_catalog,\n    )\n\n    # This step creates a file in the another folder and syncs it to the catalog.\n    another_catalog = Catalog(put=[\"another/world.txt\"])\n    another_create = PythonTask(\n        name=\"create_content_in_another_folder\",\n        function=create_content_in_another_folder,\n        catalog=another_catalog,\n    )\n\n    # Delete the another folder to showcase that the folder will be recreated\n    # when we run the retrieve task.\n    delete_another_folder = ShellTask(\n        name=\"delete_another_folder\",\n        command=\"rm -rf another/\",\n    )\n\n    # This step retrieves the file from the catalog and prints its content.\n    all_catalog = Catalog(get=[\"**/*\"])\n    retrieve = PythonTask(\n        name=\"retrieve_content_from_both\",\n        function=retrieve_content_from_both,\n        catalog=all_catalog,\n        terminate_with_success=True,\n    )\n\n    pipeline = Pipeline(\n        steps=[data_create, another_create, delete_another_folder, retrieve],\n        add_terminal_nodes=True,\n    )\n\n    # Override the default configuration file with the one that has file-system as the catalog.\n    _ = pipeline.execute(configuration_file=\"examples/configs/fs-catalog.yaml\")\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>In the below example, the steps <code>data_create</code> and <code>another_create</code> create content for downstream steps, i.e <code>retrieve</code> to consume.</p> <p>Delete?</p> <p>Since we are executing in local compute and creating sub-directory <code>another</code>, it might be mistaken that we are not cataloging anything. We delete <code>another</code> directory between steps to demonstrate that we indeed move files in and out of the catalog.</p> <p>The highlighted lines in the below example show how to specify the files to get/put from the catalog using yaml.</p> <pre><code>dag:\n  description: |\n    An example pipeline to showcase catalog functionality.\n\n    The pipeline consists of four steps:\n    create_content_in_data_folder: Creates a file in \"data\" folder and syncs it to catalog\n    create_content_in_another_folder: Creates another file in \"another\" folder and syncs it to catalog\n    delete_another_folder: Deletes the another folder to showcase that it is recreated later.\n    retrieve_content_from_both: Retrieves the content from both \"data\" and \"another\n\n    You can run this pipeline by:\n    runnable execute -f examples/concepts/catalog.yaml -c examples/configs/fs-catalog.yaml\n\n  start_at: create_content_in_data_folder\n  steps:\n    create_content_in_data_folder:\n      type: task\n      command: examples.concepts.catalog.create_content_in_data_folder\n      catalog:\n        put:\n          - \"data/hello.txt\"\n      next: create_content_in_another_folder\n    create_content_in_another_folder:\n      type: task\n      command: examples.concepts.catalog.create_content_in_another_folder\n      catalog:\n        put:\n          - \"another/world.txt\"\n      next: delete_another_folder\n    delete_another_folder:\n      type: task\n      command_type: shell\n      command: rm -rf another\n      next: retrieve_content_from_both\n    retrieve_content_from_both:\n      type: task\n      command: examples.concepts.catalog.retrieve_content_from_both\n      catalog:\n        get:\n          - \"**/*\"\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p>glob pattern</p> <p>We use glob pattern to search for files.</p> <p>Note that, the pattern to recursively match all directories is <code>**/*</code></p> <p>The execution results in the <code>catalog</code> populated with the artifacts and the execution logs of the tasks.</p> Directory structureRun log <p>The directory structure within the <code>catalog</code> for the execution, i.e meek-stonebraker-0626, resembles the project directory structure.</p> <p>The execution logs of all the tasks are also present in the <code>catalog</code>.</p> <pre><code>&gt;&gt;&gt; tree .catalog\n.catalog\n\u2514\u2500\u2500 meek-stonebraker-0626\n    \u251c\u2500\u2500 another\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 world.txt\n    \u251c\u2500\u2500 create_content_in_another_folder.execution.log\n    \u251c\u2500\u2500 create_content_in_data_folder.execution.log\n    \u251c\u2500\u2500 data\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 hello.txt\n    \u251c\u2500\u2500 delete_another_folder.execution.log\n    \u2514\u2500\u2500 retrieve_content_from_both.execution.log\n\n4 directories, 6 files\n</code></pre> <p>The run log captures the data identities of the data flowing through the catalog.</p> <pre><code>{\n\"run_id\": \"meek-stonebraker-0626\",\n\"dag_hash\": \"\",\n\"use_cached\": false,\n\"tag\": \"\",\n\"original_run_id\": \"\",\n\"status\": \"SUCCESS\",\n\"steps\": {\n    \"create_content_in_data_folder\": {\n        \"name\": \"create_content_in_data_folder\",\n        \"internal_name\": \"create_content_in_data_folder\",\n        \"status\": \"SUCCESS\",\n        \"step_type\": \"task\",\n        \"message\": \"\",\n        \"mock\": false,\n        \"code_identities\": [\n            {\n                \"code_identifier\": \"6029841c3737fe1163e700b4324d22a469993bb0\",\n                \"code_identifier_type\": \"git\",\n                \"code_identifier_dependable\": true,\n                \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                \"code_identifier_message\": \"\"\n            }\n        ],\n        \"attempts\": [\n            {\n                \"attempt_number\": 1,\n                \"start_time\": \"2024-01-06 06:26:56.279278\",\n                \"end_time\": \"2024-01-06 06:26:56.284564\",\n                \"duration\": \"0:00:00.005286\",\n                \"status\": \"SUCCESS\",\n                \"message\": \"\",\n                \"parameters\": {}\n            }\n        ],\n        \"user_defined_metrics\": {},\n        \"branches\": {},\n        \"data_catalog\": [\n            {\n                \"name\": \"create_content_in_data_folder.execution.log\",\n                \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                \"catalog_relative_path\": \"meek-stonebraker-0626/create_content_in_data_folder.execution.log\",\n                \"catalog_handler_location\": \".catalog\",\n                \"stage\": \"put\"\n            },\n            {\n                \"name\": \"data/hello.txt\",\n                \"data_hash\": \"6ccad99847c78bfdc7a459399c9957893675d4fec2d675cec750b50ab4842542\",\n                \"catalog_relative_path\": \"meek-stonebraker-0626/data/hello.txt\",\n                \"catalog_handler_location\": \".catalog\",\n                \"stage\": \"put\"\n            }\n        ]\n    },\n    \"create_content_in_another_folder\": {\n        \"name\": \"create_content_in_another_folder\",\n        \"internal_name\": \"create_content_in_another_folder\",\n        \"status\": \"SUCCESS\",\n        \"step_type\": \"task\",\n        \"message\": \"\",\n        \"mock\": false,\n        \"code_identities\": [\n            {\n                \"code_identifier\": \"6029841c3737fe1163e700b4324d22a469993bb0\",\n                \"code_identifier_type\": \"git\",\n                \"code_identifier_dependable\": true,\n                \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                \"code_identifier_message\": \"\"\n            }\n        ],\n        \"attempts\": [\n            {\n                \"attempt_number\": 1,\n                \"start_time\": \"2024-01-06 06:26:56.353734\",\n                \"end_time\": \"2024-01-06 06:26:56.357519\",\n                \"duration\": \"0:00:00.003785\",\n                \"status\": \"SUCCESS\",\n                \"message\": \"\",\n                \"parameters\": {}\n            }\n        ],\n        \"user_defined_metrics\": {},\n        \"branches\": {},\n        \"data_catalog\": [\n            {\n                \"name\": \"create_content_in_another_folder.execution.log\",\n                \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                \"catalog_relative_path\": \"meek-stonebraker-0626/create_content_in_another_folder.execution.log\",\n                \"catalog_handler_location\": \".catalog\",\n                \"stage\": \"put\"\n            },\n            {\n                \"name\": \"another/world.txt\",\n                \"data_hash\": \"869ae2ac8365d5353250fc502b084a28b2029f951ea7da0a6948f82172accdfd\",\n                \"catalog_relative_path\": \"meek-stonebraker-0626/another/world.txt\",\n                \"catalog_handler_location\": \".catalog\",\n                \"stage\": \"put\"\n            }\n        ]\n    },\n    \"delete_another_folder\": {\n        \"name\": \"delete_another_folder\",\n        \"internal_name\": \"delete_another_folder\",\n        \"status\": \"SUCCESS\",\n        \"step_type\": \"task\",\n        \"message\": \"\",\n        \"mock\": false,\n        \"code_identities\": [\n            {\n                \"code_identifier\": \"6029841c3737fe1163e700b4324d22a469993bb0\",\n                \"code_identifier_type\": \"git\",\n                \"code_identifier_dependable\": true,\n                \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                \"code_identifier_message\": \"\"\n            }\n        ],\n        \"attempts\": [\n            {\n                \"attempt_number\": 1,\n                \"start_time\": \"2024-01-06 06:26:56.428437\",\n                \"end_time\": \"2024-01-06 06:26:56.450148\",\n                \"duration\": \"0:00:00.021711\",\n                \"status\": \"SUCCESS\",\n                \"message\": \"\",\n                \"parameters\": {}\n            }\n        ],\n        \"user_defined_metrics\": {},\n        \"branches\": {},\n        \"data_catalog\": [\n            {\n                \"name\": \"delete_another_folder.execution.log\",\n                \"data_hash\": \"a9b49c92ed63cb54a8b02c0271a925d9fac254034ed45df83f3ff24c0bd53ef6\",\n                \"catalog_relative_path\": \"meek-stonebraker-0626/delete_another_folder.execution.log\",\n                \"catalog_handler_location\": \".catalog\",\n                \"stage\": \"put\"\n            }\n        ]\n    },\n    \"retrieve_content_from_both\": {\n        \"name\": \"retrieve_content_from_both\",\n        \"internal_name\": \"retrieve_content_from_both\",\n        \"status\": \"SUCCESS\",\n        \"step_type\": \"task\",\n        \"message\": \"\",\n        \"mock\": false,\n        \"code_identities\": [\n            {\n                \"code_identifier\": \"6029841c3737fe1163e700b4324d22a469993bb0\",\n                \"code_identifier_type\": \"git\",\n                \"code_identifier_dependable\": true,\n                \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                \"code_identifier_message\": \"\"\n            }\n        ],\n        \"attempts\": [\n            {\n                \"attempt_number\": 1,\n                \"start_time\": \"2024-01-06 06:26:56.520948\",\n                \"end_time\": \"2024-01-06 06:26:56.530135\",\n                \"duration\": \"0:00:00.009187\",\n                \"status\": \"SUCCESS\",\n                \"message\": \"\",\n                \"parameters\": {}\n            }\n        ],\n        \"user_defined_metrics\": {},\n        \"branches\": {},\n        \"data_catalog\": [\n            {\n                \"name\": \"data/hello.txt\",\n                \"data_hash\": \"6ccad99847c78bfdc7a459399c9957893675d4fec2d675cec750b50ab4842542\",\n                \"catalog_relative_path\": \"data/hello.txt\",\n                \"catalog_handler_location\": \".catalog\",\n                \"stage\": \"get\"\n            },\n            {\n                \"name\": \"another/world.txt\",\n                \"data_hash\": \"869ae2ac8365d5353250fc502b084a28b2029f951ea7da0a6948f82172accdfd\",\n                \"catalog_relative_path\": \"another/world.txt\",\n                \"catalog_handler_location\": \".catalog\",\n                \"stage\": \"get\"\n            },\n            {\n                \"name\": \"retrieve_content_from_both.execution.log\",\n                \"data_hash\": \"0a085cb15df6c70c5859b44cc62bfdc98383600ba4f2983124375a4f64f1ae83\",\n                \"catalog_relative_path\": \"meek-stonebraker-0626/retrieve_content_from_both.execution.log\",\n                \"catalog_handler_location\": \".catalog\",\n                \"stage\": \"put\"\n            }\n        ]\n    },\n    \"success\": {\n        \"name\": \"success\",\n        \"internal_name\": \"success\",\n        \"status\": \"SUCCESS\",\n        \"step_type\": \"success\",\n        \"message\": \"\",\n        \"mock\": false,\n        \"code_identities\": [\n            {\n                \"code_identifier\": \"6029841c3737fe1163e700b4324d22a469993bb0\",\n                \"code_identifier_type\": \"git\",\n                \"code_identifier_dependable\": true,\n                \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                \"code_identifier_message\": \"\"\n            }\n        ],\n        \"attempts\": [\n            {\n                \"attempt_number\": 1,\n                \"start_time\": \"2024-01-06 06:26:56.591948\",\n                \"end_time\": \"2024-01-06 06:26:56.592032\",\n                \"duration\": \"0:00:00.000084\",\n                \"status\": \"SUCCESS\",\n                \"message\": \"\",\n                \"parameters\": {}\n            }\n        ],\n        \"user_defined_metrics\": {},\n        \"branches\": {},\n        \"data_catalog\": []\n    }\n},\n\"parameters\": {},\n\"run_config\": {\n    \"executor\": {\n        \"service_name\": \"local\",\n        \"service_type\": \"executor\",\n        \"enable_parallel\": false,\n        \"placeholders\": {}\n    },\n    \"run_log_store\": {\n        \"service_name\": \"buffered\",\n        \"service_type\": \"run_log_store\"\n    },\n    \"secrets_handler\": {\n        \"service_name\": \"do-nothing\",\n        \"service_type\": \"secrets\"\n    },\n    \"catalog_handler\": {\n        \"service_name\": \"file-system\",\n        \"service_type\": \"catalog\"\n    },\n    \"experiment_tracker\": {\n        \"service_name\": \"do-nothing\",\n        \"service_type\": \"experiment_tracker\"\n    },\n    \"pipeline_file\": \"\",\n    \"parameters_file\": \"\",\n    \"configuration_file\": \"examples/configs/fs-catalog.yaml\",\n    \"tag\": \"\",\n    \"run_id\": \"meek-stonebraker-0626\",\n    \"variables\": {},\n    \"use_cached\": false,\n    \"original_run_id\": \"\",\n    \"dag\": {\n        \"start_at\": \"create_content_in_data_folder\",\n        \"name\": \"\",\n        \"description\": \"\",\n        \"internal_branch_name\": \"\",\n        \"steps\": {\n            \"create_content_in_data_folder\": {\n                \"type\": \"task\",\n                \"name\": \"create_content_in_data_folder\",\n                \"internal_name\": \"create_content_in_data_folder\",\n                \"internal_branch_name\": \"\",\n                \"is_composite\": false\n            },\n            \"create_content_in_another_folder\": {\n                \"type\": \"task\",\n                \"name\": \"create_content_in_another_folder\",\n                \"internal_name\": \"create_content_in_another_folder\",\n                \"internal_branch_name\": \"\",\n                \"is_composite\": false\n            },\n            \"retrieve_content_from_both\": {\n                \"type\": \"task\",\n                \"name\": \"retrieve_content_from_both\",\n                \"internal_name\": \"retrieve_content_from_both\",\n                \"internal_branch_name\": \"\",\n                \"is_composite\": false\n            },\n            \"delete_another_folder\": {\n                \"type\": \"task\",\n                \"name\": \"delete_another_folder\",\n                \"internal_name\": \"delete_another_folder\",\n                \"internal_branch_name\": \"\",\n                \"is_composite\": false\n            },\n            \"success\": {\n                \"type\": \"success\",\n                \"name\": \"success\",\n                \"internal_name\": \"success\",\n                \"internal_branch_name\": \"\",\n                \"is_composite\": false\n            },\n            \"fail\": {\n                \"type\": \"fail\",\n                \"name\": \"fail\",\n                \"internal_name\": \"fail\",\n                \"internal_branch_name\": \"\",\n                \"is_composite\": false\n            }\n        }\n    },\n    \"dag_hash\": \"\",\n    \"execution_plan\": \"chained\"\n}\n}\n</code></pre>"},{"location":"concepts/catalog/#using_python_api","title":"Using python API","text":"<p>Files could also be cataloged using python API</p> <p>This functionality is possible in python and notebook tasks.</p>"},{"location":"concepts/catalog/#passing_data_objects","title":"Passing Data Objects","text":"<p>Data objects can be shared between python or notebook tasks, instead of serializing data and deserializing to file structure, using get_object and put_object.</p> <p>Internally, we use pickle to serialize and deserialize python objects. Please ensure that the object can be serialized via pickle.</p>"},{"location":"concepts/catalog/#example_1","title":"Example","text":"<p>In the below example, the step <code>put_data_object</code> puts a pydantic object into the catalog while the step <code>retrieve_object</code> retrieves the pydantic object from the catalog and prints it.</p> <p>You can run this example by <code>python run examples/concepts/catalog_object.py</code></p> <pre><code>\n</code></pre>"},{"location":"concepts/executor/","title":"Executor","text":""},{"location":"concepts/executor/#todo_simplify","title":"TODO: Simplify","text":"<p>Executors are the heart of runnable, they traverse the workflow and execute the tasks within the workflow while coordinating with different services (eg. run log, catalog, secrets etc)</p> <p>To enable workflows run in varied computational environments, we distinguish between two core functions of any workflow engine.</p> <code>Graph Traversal</code> <p>Involves following the user-defined workflow graph to its eventual conclusion. The navigation process encompasses the sequential execution of tasks or complex tasks such as parallel paths. It also includes decision-making regarding the pathway to follow in case of task failure and the upkeep of the overall status of graph execution.</p> <code>Executing Individual Steps</code> <p>This refers to the concrete execution of the task as specified by the user along with allowing for data flow between tasks. This could involve activities such as launching a container or initiating a SQL query, among others.</p>"},{"location":"concepts/executor/#graph_traversal","title":"Graph Traversal","text":"<p>In runnable, the graph traversal can be performed by runnable itself or can be handed over to other orchestration frameworks (e.g Argo workflows, AWS step functions).</p>"},{"location":"concepts/executor/#example","title":"Example","text":"<p>Below is a simple pipeline definition that does one task of printing \"Hello World\".</p> <pre><code>dag:\n  description: |\n    This is a sample pipeline with one step that executes a shell command.\n\n    The step name \"shell\" has the \"command_type\" to be shell to\n    let runnable know to execute a shell while the command is directly\n    executed in the current environment.\n\n    You can run this pipeline as:\n      runnable execute -f examples/concepts/task_shell_simple.yaml\n\n  start_at: shell\n  steps:\n    shell:\n      type: task\n      command_type: shell\n      command: echo \"Hello world!!\"\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p>The above pipeline can be executed by the default config to execute it locally or could be translated to argo specification just by changing the configuration.</p> Default ConfigurationArgo ConfigurationTranspiled Workflow <p>The configuration defines the local compute to the execution environment with the <code>run log</code> being completely in memory and buffered with no other services active.</p> <p>You can execute the pipeline in default configuration by:</p> <p><code>runnable execute -f examples/concepts/task_shell_simple.yaml</code></p> <pre><code>executor:\n  type: local # (1)\n\nrun_log_store:\n  type: buffered # (2)\n\ncatalog:\n  type: do-nothing # (3)\n\nsecrets:\n  type: do-nothing # (4)\n</code></pre> <ol> <li>Run the pipeline in local environment.</li> <li>Use the buffer as run log, this will not persist the run log to disk.</li> <li>Do not move any files to central storage.</li> <li>Do not use any secrets manager.</li> <li>Do not integrate with any experiment tracking tools</li> </ol> <p>In this configuration, we are using argo workflows as our workflow engine. We are also instructing the workflow engine to use a docker image, <code>runnable:demo</code> defined in line #4, as our execution environment. Please read containerised environments for more information.</p> <p>Since runnable needs to track the execution status of the workflow, we are using a <code>run log</code> which is persistent and available in for jobs in kubernetes environment.</p> <p>You can execute the pipeline in argo configuration by:</p> <p><code>runnable execute -f examples/concepts/task_shell_simple.yaml -c examples/configs/argo-config.yaml</code></p> <pre><code>executor:\n  type: \"argo\" # (1)\n  config:\n    image: runnable:demo # (2)\n    service_account_name: default-editor\n    persistent_volumes: # (3)\n      - name: runnable-volume\n        mount_path: /mnt\n\nrun_log_store: # (4)\n  type: file-system\n  config:\n    log_folder: /mnt/run_log_store\n\ncatalog:\n  type: do-nothing\n\nsecrets:\n  type: do-nothing\n\nexperiment_tracker:\n  type: do-nothing\n</code></pre> <ol> <li>Use argo workflows as the execution engine to run the pipeline.</li> <li>Run this docker image for every step of the pipeline. The docker image should have the same directory structure as the project directory.</li> <li>Mount the volume from Kubernetes persistent volumes (runnable-volume) to /mnt directory.</li> <li>Resource constraints for the container runtime.</li> <li>Since every step runs in a container, the run log should be persisted. Here we are using the file-system as our run log store.</li> <li>Kubernetes PVC is mounted to every container as <code>/mnt</code>, use that to surface the run log to every step.</li> </ol> <p>In the below generated argo workflow template:</p> <ul> <li>Lines 10-17 define a <code>dag</code> with tasks that corresponding to the tasks in the example workflow.</li> <li>The graph traversal rules follow the the same rules as our workflow. The step <code>success-success-ou7qlf</code> in line #15 only happens if the step <code>shell-task-dz3l3t</code> defined in line #12 succeeds.</li> <li>The execution fails if any of the tasks fail. Both argo workflows and runnable <code>run log</code> mark the execution as failed.</li> </ul> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: runnable-dag-\n  annotations: {}\n  labels: {}\nspec:\n  activeDeadlineSeconds: 172800\n  entrypoint: runnable-dag\n  podGC:\n    strategy: OnPodCompletion\n  retryStrategy:\n    limit: '0'\n    retryPolicy: Always\n    backoff:\n      duration: '120'\n      factor: 2\n      maxDuration: '3600'\n  serviceAccountName: default-editor\n  templates:\n    - name: runnable-dag\n      failFast: true\n      dag:\n        tasks:\n          - name: shell-task-4jy8pl\n            template: shell-task-4jy8pl\n            depends: ''\n          - name: success-success-djhm6j\n            template: success-success-djhm6j\n            depends: shell-task-4jy8pl.Succeeded\n    - name: shell-task-4jy8pl\n      container:\n        image: runnable:demo\n        command:\n          - runnable\n          - execute_single_node\n          - '{{workflow.parameters.run_id}}'\n          - shell\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/task_shell_simple.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: ''\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n    - name: success-success-djhm6j\n      container:\n        image: runnable:demo\n        command:\n          - runnable\n          - execute_single_node\n          - '{{workflow.parameters.run_id}}'\n          - success\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/task_shell_simple.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: ''\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n  templateDefaults:\n    activeDeadlineSeconds: 7200\n    timeout: 10800s\n  arguments:\n    parameters:\n      - name: run_id\n        value: '{{workflow.uid}}'\n  volumes:\n    - name: executor-0\n      persistentVolumeClaim:\n        claimName: runnable-volume\n</code></pre> <p>As seen from the above example, once a pipeline is defined in runnable either via yaml or SDK, we can run the pipeline in different environments just by providing a different configuration. Most often, there is no need to change the code or deviate from standard best practices while coding.</p>"},{"location":"concepts/executor/#step_execution","title":"Step Execution","text":"<p>Note</p> <p>This section is to understand the internal mechanism of runnable and not required if you just want to use different executors.</p> <p>Independent of traversal, all the tasks are executed within the <code>context</code> of runnable.</p> <p>A closer look at the actual task implemented as part of transpiled workflow in argo specification details the inner workings. Below is a snippet of the argo specification from lines 18 to 34.</p> <pre><code>- name: shell-task-dz3l3t\n  container:\n    image: runnable-example:latest\n    command:\n    - runnable\n    - execute_single_node\n    - '{{workflow.parameters.run_id}}'\n    - shell\n    - --log-level\n    - WARNING\n    - --file\n    - examples/concepts/task_shell_simple.yaml\n    - --config-file\n    - examples/configs/argo-config.yaml\n  volumeMounts:\n    - name: executor-0\n      mountPath: /mnt\n</code></pre> <p>The actual <code>command</code> to run is not the <code>command</code> defined in the workflow, i.e <code>echo hello world</code>, but a command in the CLI of runnable which specifies the workflow file, the step name and the configuration file.</p>"},{"location":"concepts/executor/#context_of_runnable","title":"Context of runnable","text":"<p>Any <code>task</code> defined by the user as part of the workflow always runs as a sub-command of runnable. In that sense, runnable follows the decorator pattern without being part of the application codebase.</p> <p>In a very simplistic sense, the below stubbed-code explains the context of runnable during execution of a task.</p> <pre><code>def execute_single_node(workflow, step_name, configuration):\n\n    ##### PRE EXECUTION #####\n    # Instantiate the service providers of run_log and catalog\n    # These are provided as part of the configuration.\n    run_log = configuration.get_run_log() # (1)\n    catalog = configuration.get_catalog() # (2)\n\n    step = workflow.get_step(step_name) # (3)\n\n    # Get the current parameters set by the initial parameters\n    # or by previous steps.\n    existing_parameters = run_log.get_parameters()\n    # Get the data requested by the step and populate\n    # the data folder defined in the catalog configuration\n    catalog.get_data(step.get_from_catalog) # (4)\n\n    # Choose the parameters to pass into the function and\n    # the right data type.\n    task_parameters = filter_and_cast_parameters(existing_parameters, step.task) # (5)\n\n    ##### END PRE EXECUTION #####\n    try:\n      # We call the actual task here!!\n      updated_parameters = step.task(**task_parameters) # (6)\n    except:\n      update_status_in_run_log(step, FAIL)\n      send_error_response() # (7)\n\n    ##### POST EXECUTION #####\n    run_log.update_parameters(updated_parameters) # (8)\n    catalog.put_data(step.put_into_catalog) # (9)\n    update_status_in_run_log(step, SUCCESS)\n    send_success_response() # (10)\n    ##### END POST EXECUTION #####\n</code></pre> <ol> <li>The run log maintains the state of the execution of the tasks and subsequently the pipeline. It also holds the latest state of parameters along with captured metrics.</li> <li>The catalog contains the information about the data flowing through the pipeline. You can get/put artifacts generated during the current execution of the pipeline to a central storage.</li> <li>Read the workflow and get the step definition which holds the <code>command</code> or <code>function</code> to execute along with the other optional information.</li> <li>Any artifacts from previous steps that are needed to execute the current step can be retrieved from the catalog.</li> <li>The current function or step might need only some of the parameters casted as pydantic models, filter and cast them appropriately.</li> <li>At this point in time, we have the required parameters and data to execute the actual command. The command can internally request for more data using the python API or record experiment tracking metrics.</li> <li>If the task failed, we update the run log with that information and also raise an exception for the workflow engine to handle. Any on-failure traversals are already handled as part of the workflow definition.</li> <li>Upon successful execution, we update the run log with current state of parameters for downstream steps.</li> <li>Any artifacts generated from this step are put into the central storage for downstream steps.</li> <li>We send a success message to the workflow engine and mark the step as completed.</li> </ol>"},{"location":"concepts/experiment-tracking/","title":"Overview","text":"<p>Run log stores a lot of information about the execution along with the metrics captured during the execution of the pipeline.</p>"},{"location":"concepts/experiment-tracking/#example","title":"Example","text":"Using the APIUsing environment variablesRun log entry <p>The highlighted lines in the below example show how to use the API</p> <p>Any pydantic model as a value would be dumped as a dict, respecting the alias, before tracking it.</p> <p>You can run this example by <code>python run examples/concepts/experiment_tracking_api.py</code></p> <pre><code>\n</code></pre> <p>The highlighted lines in the below example show how to use environment variables to track metrics.</p> <p>Only string values are allowed to be environment variables. Numeric values sent in as strings are converted to int/float before storing them as metrics.</p> <p>There is no support for boolean values in environment variables.</p> <pre><code>\n</code></pre> <p>Any experiment tracking metrics found during the execution of the task are stored in <code>user_defined_metrics</code> field of the step log.</p> <p>For example, below is the content for the shell execution.</p> <pre><code>{\n    \"run_id\": \"blazing-colden-0544\",\n    \"dag_hash\": \"4494aeb907ef950934fbcc34b226f72134d06687\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {\n        \"shell\": {\n            \"name\": \"shell\",\n            \"internal_name\": \"shell\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"793b052b8b603760ff1eb843597361219832b61c\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-09 05:44:42.841295\",\n                    \"end_time\": \"2024-01-09 05:44:42.849938\",\n                    \"duration\": \"0:00:00.008643\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {\n                \"eggs\": {\n                    \"ham\": \"world\"\n                },\n                \"answer\": 42.0,\n                \"spam\": \"hello\"\n            },\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"shell.execution.log\",\n                    \"data_hash\": \"07723e6188e7893ac79e8f07b7cc15dd1a62d2974335f173a0b5a6e58a3735d6\",\n                    \"catalog_relative_path\": \"blazing-colden-0544/shell.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"793b052b8b603760ff1eb843597361219832b61c\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-09 05:44:42.913905\",\n                    \"end_time\": \"2024-01-09 05:44:42.913963\",\n                    \"duration\": \"0:00:00.000058\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"placeholders\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"buffered\",\n            \"service_type\": \"run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"examples/concepts/experiment_tracking_env.yaml\",\n        \"parameters_file\": null,\n        \"configuration_file\": null,\n        \"tag\": \"\",\n        \"run_id\": \"blazing-colden-0544\",\n        \"variables\": {},\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"shell\",\n            \"name\": \"\",\n            \"description\": \"An example pipeline to demonstrate setting experiment tracking metrics\\nusing environment variables. Any environment variable with\n            prefix\\n'runnable_TRACK_' will be recorded as a metric captured during the step.\\n\\nYou can run this pipeline as:\\n  runnable execute -f\n            examples/concepts/experiment_tracking_env.yaml\\n\",\n            \"internal_branch_name\": \"\",\n            \"steps\": {\n                \"shell\": {\n                    \"type\": \"task\",\n                    \"name\": \"shell\",\n                    \"internal_name\": \"shell\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\",\n                    \"internal_name\": \"success\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\",\n                    \"internal_name\": \"fail\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                }\n            }\n        },\n        \"dag_hash\": \"4494aeb907ef950934fbcc34b226f72134d06687\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre>"},{"location":"concepts/experiment-tracking/#incremental_tracking","title":"Incremental tracking","text":"<p>It is possible to track metrics over time within a task. To do so, use the <code>step</code> parameter in the API or post-fixing <code>_STEP_</code> and the increment when using environment variables.</p> <p>The step is defaulted to be 0.</p>"},{"location":"concepts/experiment-tracking/#example_1","title":"Example","text":"Using the APIUsing environment variablesRun log entry <p>The highlighted lines in the below example show how to use the API with the step parameter.</p> <p>You can run this example by <code>python run examples/concepts/experiment_tracking_step.py</code></p> <pre><code>\n</code></pre> <p>The highlighted lines in the below example show how to use environment variables to track metrics.</p> <pre><code>\n</code></pre> <pre><code>{\n    \"run_id\": \"blocking-stonebraker-1545\",\n    \"dag_hash\": \"\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {\n        \"Emit Metrics\": {\n            \"name\": \"Emit Metrics\",\n            \"internal_name\": \"Emit Metrics\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"858c4df44f15d81139341641c63ead45042e0d89\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-09 15:45:34.940999\",\n                    \"end_time\": \"2024-01-09 15:45:34.943648\",\n                    \"duration\": \"0:00:00.002649\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {\n                \"spam\": {\n                    \"0\": \"hello\",\n                    \"1\": \"hey\"\n                },\n                \"eggs\": {\n                    \"0\": {\n                        \"ham\": \"world\"\n                    },\n                    \"1\": {\n                        \"ham\": \"universe\"\n                    }\n                },\n                \"answer\": 42.0,\n                \"is_it_true\": false\n            },\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"Emit_Metrics.execution.log\",\n                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                    \"catalog_relative_path\": \"blocking-stonebraker-1545/Emit_Metrics.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"858c4df44f15d81139341641c63ead45042e0d89\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-09 15:45:35.126659\",\n                    \"end_time\": \"2024-01-09 15:45:35.126745\",\n                    \"duration\": \"0:00:00.000086\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"placeholders\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"buffered\",\n            \"service_type\": \"run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"\",\n        \"parameters_file\": \"\",\n        \"configuration_file\": \"\",\n        \"tag\": \"\",\n        \"run_id\": \"blocking-stonebraker-1545\",\n        \"variables\": {},\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"Emit Metrics\",\n            \"name\": \"\",\n            \"description\": \"\",\n            \"internal_branch_name\": \"\",\n            \"steps\": {\n                \"Emit Metrics\": {\n                    \"type\": \"task\",\n                    \"name\": \"Emit Metrics\",\n                    \"internal_name\": \"Emit Metrics\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\",\n                    \"internal_name\": \"success\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\",\n                    \"internal_name\": \"fail\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                }\n            }\n        },\n        \"dag_hash\": \"\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre>"},{"location":"concepts/experiment-tracking/#experiment_tracking_tools","title":"Experiment tracking tools","text":"<p>Opt out</p> <p>Pipelines need not use the <code>experiment-tracking</code> if the preferred tools of choice is not implemented in runnable. The default configuration of <code>do-nothing</code> is no-op by design. We kindly request to raise a feature request to make us aware of the eco-system.</p> <p>The default experiment tracking tool of runnable is a no-op as the <code>run log</code> captures all the required details. To make it compatible with other experiment tracking tools like mlflow or Weights and Biases, we map attributes of runnable to the underlying tool.</p> <p>For example, for mlflow:</p> <ul> <li> <p>Any numeric (int/float) observation is logged as a metric with a step.</p> </li> <li> <p>Any non numeric observation is logged as a parameter. Since mlflow does not support step wise logging of parameters, the key name is formatted as <code>key_step</code>.</p> </li> <li> <p>The tag associate with an execution is used as the experiment name.</p> </li> </ul> <p>Shortcomings</p> <p>Experiment tracking capabilities of runnable are inferior in integration with popular python frameworks like pytorch and tensorflow as compared to other experiment tracking tools.</p> <p>We strongly advise to use them if you need advanced capabilities.</p> Example configurationPipelineIn mlflow UI <p>In the below configuration, the mlflow tracking server is a local instance listening on port 8080.</p> <pre><code>\n</code></pre> <p>As with other examples, we are using the <code>track_this</code> python API to capture metrics. During the pipeline execution in line #39, we use the configuration of <code>mlflow</code> as experiment tracking tool.</p> <p>The tag provided during the execution is used as a experiment name in mlflow.</p> <p>You can run this example by <code>python run examples/concepts/experiment_tracking_integration.py</code></p> <pre><code>\n</code></pre> <p> mlflow UI for the execution. The run_id remains the same as the run_id of runnable </p> <p> The step wise metric plotted as a graph in mlflow </p> <p>To provide implementation specific capabilities, we also provide a python API to obtain the client context. The default client context is a null context manager.</p>"},{"location":"concepts/map/","title":"Map","text":"<p><code>map</code> nodes in runnable allows you to execute a sequence of nodes (i.e a pipeline) for all the items in a list. This is similar to Map state of AWS Step functions or loops in Argo workflows.</p> <p>Conceptually, map node can be represented in python like below.</p> <pre><code>#technically it is async for\nfor i in iterable_parameter:\n    # a pipeline of steps\n    execute_first_step(i)\n    execute_second_step(i)\n    ...\n</code></pre> <p>You can control the parallelism by configuration of the executor.</p>"},{"location":"concepts/map/#example","title":"Example","text":"<p>Below is an example of processing a inventory of files (50) in parallel batches of 10 files per batch. The <code>stride</code> parameter controls the chunk size and every batch is given the start index of the files to process.</p> visualizationpython sdkpipeline in yamlpipeline with shell tasksRun log <p>The step \"chunk files\" identifies the number of files to process and computes the start index of every batch of files to process for a chunk size of 10, the stride.</p> <p>\"Process Chunk\" pipelines are then triggered in parallel to process the chunk of files between <code>start index</code> and <code>start index + stride</code></p> <pre><code>flowchart TD\nchunkify([Chunk files]):::green\nsuccess([Success]):::green\n\nsubgraph one[Process Chunk]\n    process_chunk1([Process Chunk]):::yellow\n    success_chunk1([Success]):::yellow\n\n    process_chunk1 --&gt; success_chunk1\nend\n\nsubgraph two[Process Chunk]\n    process_chunk2([Process Chunk]):::yellow\n    success_chunk2([Success]):::yellow\n\n    process_chunk2 --&gt; success_chunk2\nend\n\nsubgraph three[Process Chunk]\n    process_chunk3([Process Chunk]):::yellow\n    success_chunk3([Success]):::yellow\n\n    process_chunk3 --&gt; success_chunk3\nend\n\nsubgraph four[Process Chunk]\n    process_chunk4([Process Chunk]):::yellow\n    success_chunk4([Success]):::yellow\n\n    process_chunk4 --&gt; success_chunk4\nend\n\nsubgraph five[Process Chunk]\n    process_chunk5([Process Chunk]):::yellow\n    success_chunk5([Success]):::yellow\n\n    process_chunk5 --&gt; success_chunk5\nend\n\n\n\nchunkify -- (stride=10, start_index=0)--&gt; one --&gt; success\nchunkify -- (stride=10, start_index=10)--&gt; two --&gt; success\nchunkify -- (stride=10, start_index=20)--&gt; three --&gt; success\nchunkify -- (stride=10, start_index=30)--&gt; four --&gt; success\nchunkify -- (stride=10, start_index=40)--&gt; five --&gt; success\n\nclassDef yellow stroke:#FFFF00\nclassDef green stroke:#0f0</code></pre> <p>The <code>start_index</code> argument for the function <code>process_chunk</code> is dynamically set by iterating over <code>chunks</code>.</p> <p>If the argument <code>start_index</code> is not provided, you can still access the current value by <code>runnable_MAP_VARIABLE</code> environment variable. The environment variable <code>runnable_MAP_VARIABLE</code> is a dictionary with keys as <code>iterate_as</code></p> <p>This instruction is set while defining the map node.</p> <p>You can run this example by <code>python examples/concepts/map.py</code></p> <pre><code>\"\"\"\nAn example pipeline of using \"map\" to process a sequence of nodes repeatedly over a iterable\nparameter.\n\nThe start_index argument for the function process_chunk is dynamically set by iterating over chunks.\n\nIf the argument start_index is not provided, you can still access the current value by\nrunnable_MAP_VARIABLE environment variable. The environment variable runnable_MAP_VARIABLE\nis a dictionary with keys as iterate_as.\n\nRun this pipeline by:\n    python examples/concepts/map.py\n\"\"\"\n\n\ndef chunk_files():\n    \"\"\"\n    Identify the number of chunks and files to execute per batch.\n\n    Set the parameter \"chunks\" to be the start indexes of batch.\n    Set the parameter \"stride\" to be the number of files to\n    execute per batch.\n    \"\"\"\n    return 10, list(range(0, 50, 10))\n    # create_model(\n    #     \"DynamicModel\",\n    #     chunks=(List[int], list(range(0, 50, 10))),\n    #     stride=(int, 10),\n    # )()\n\n\ndef process_chunk(stride: int, start_index: int):\n    \"\"\"\n    The function processes a chunk of files.\n    The files between the start_index and the start_index + stride\n    are processed per chunk.\n    \"\"\"\n    print(\"stride\", stride, type(stride))\n    print(\"start_index\", start_index, type(start_index))\n    for i in range(start_index, start_index + stride, stride):\n        pass\n\n\ndef main():\n    \"\"\"\n    The pythonic equivalent of the following pipeline.\n\n    chunks = chunk_files()\n\n    for start_index in chunks.chunks:\n        process_chunk(chunks.stride, start_index)\n\n    \"\"\"\n    from runnable import Map, Pipeline, PythonTask\n\n    execute = PythonTask(\n        name=\"execute\",\n        function=process_chunk,\n        terminate_with_success=True,\n    )\n\n    execute_branch = Pipeline(steps=[execute], add_terminal_nodes=True)\n\n    generate = PythonTask(\n        name=\"chunk files\",\n        function=chunk_files,\n        returns=[\"stride\", \"chunks\"],\n    )\n    iterate_and_execute = Map(\n        name=\"iterate and execute\",\n        branch=execute_branch,\n        iterate_on=\"chunks\",  # iterate on chunks parameter set by execute step\n        iterate_as=\"start_index\",  # expose the current start_index as the iterate_as parameter\n        terminate_with_success=True,\n    )\n\n    pipeline = Pipeline(steps=[generate, iterate_and_execute], add_terminal_nodes=True)\n\n    _ = pipeline.execute(configuration_file=\"examples/configs/fs-catalog-run_log.yaml\")\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>The <code>start_index</code> argument for the function <code>process_chunk</code> is dynamically set by iterating over <code>chunks</code>.</p> <p>This instruction is set while defining the map node. Note that the <code>branch</code> of the map node has a similar schema of the pipeline.</p> <p>You can run this example by <code>runnable execute examples/concepts/map.yaml</code></p> <pre><code>dag:\n  description: |\n    This pipeline demonstrates the usage of map state to dynamically\n    execute workflows in parallel.\n\n    The step \"chunk files\" identifies the total number of batches to\n    execute in parallel and sets the parameters\n     - start_index of every batch to process, chunks\n     - number of files to process per batch, stride.\n\n    The step \"iterate and execute\" iterates on \"chunks\" and the\n    parameter name per chunk is set to be \"start_index\".\n\n    Run this example by:\n      runnable execute -f examples/concepts/map.yaml\n  start_at: chunk files\n  steps:\n    chunk files:\n      type: task\n      command_type: python\n      command: \"examples.concepts.map.chunk_files\"\n      returns:\n        - name: stride\n          kind: json\n        - name: chunks\n          kind: json\n      next: iterate and execute\n    iterate and execute:\n      type: map\n      iterate_on: chunks\n      iterate_as: start_index\n      next: success\n      branch:\n        start_at: execute\n        steps:\n          execute:\n            type: task\n            command_type: python\n            command: \"examples.concepts.map.process_chunk\"\n            next: success\n          success:\n            type: success\n          fail:\n            type: fail\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p>The task <code>chunk files</code> sets the parameters <code>stride</code> and <code>chunks</code> similar to the python functions.</p> <p>The map branch \"iterate and execute\" iterates over chunks and exposes the current start_index of as environment variable <code>runnable_MAP_VARIABLE</code>.</p> <p>The environment variable <code>runnable_MAP_VARIABLE</code> is a json string with keys of the <code>iterate_as</code>.</p> <p>You can run this example by <code>runnable execute examples/concepts/map_shell.yaml</code></p> <pre><code>dag:\n  description: |\n    This pipeline demonstrates the usage of map state to dynamically\n    execute workflows in parallel.\n\n    The step \"chunk files\" identifies the total number of batches to\n    execute in parallel and sets the parameters\n     - start_index of every batch to process, chunks\n     - number of files to process per batch, stride.\n\n    The step \"iterate and execute\" iterates on \"chunks\" and the\n    parameter name per chunk is set to be \"start_index\".\n\n    The shell script can access the start_index as\n    runnable_MAP_VARIABLE environment variable.\n\n    Run this pipeline by:\n      runnable execute -f examples/concepts/map_shell.yaml\n\n  start_at: chunk files\n  steps:\n    chunk files:\n      type: task\n      command_type: shell\n      returns:\n        - name: stride\n          kind: json\n        - name: chunks\n          kind: json\n      command: |\n        export stride=10 &amp;&amp;\n        export chunks=\"[0, 10, 20, 30, 40]\"\n      next: iterate and execute\n    iterate and execute:\n      type: map\n      iterate_on: chunks\n      iterate_as: start_index\n      next: success\n      branch:\n        start_at: execute\n        steps:\n          execute:\n            type: task\n            command_type: shell\n            command: |\n              echo stride\n              echo start_index\n              # prints 10 and 0, 10, 20, 30, 40\n            next: success\n          success:\n            type: success\n          fail:\n            type: fail\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p>The step log of the <code>iterate and execute</code> has branches for every dynamically executed branch of the format <code>iterate and execute.&lt;iterate_as value&gt;</code>.</p> <pre><code>{\n    \"run_id\": \"simple-turing-0153\",\n    \"dag_hash\": \"\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {\n        \"chunk files\": {\n            \"name\": \"chunk files\",\n            \"internal_name\": \"chunk files\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"30ca73bb01ac45db08b1ca75460029da142b53fa\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-18 01:54:00.038461\",\n                    \"end_time\": \"2024-01-18 01:54:00.045343\",\n                    \"duration\": \"0:00:00.006882\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"chunk_files.execution.log\",\n                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                    \"catalog_relative_path\": \"simple-turing-0153/chunk_files.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"iterate and execute\": {\n            \"name\": \"iterate and execute\",\n            \"internal_name\": \"iterate and execute\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"map\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"30ca73bb01ac45db08b1ca75460029da142b53fa\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [],\n            \"user_defined_metrics\": {},\n            \"branches\": {\n                \"iterate and execute.0\": {\n                    \"internal_name\": \"iterate and execute.0\",\n                    \"status\": \"SUCCESS\",\n                    \"steps\": {\n                        \"iterate and execute.0.execute\": {\n                            \"name\": \"execute\",\n                            \"internal_name\": \"iterate and execute.0.execute\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"task\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"30ca73bb01ac45db08b1ca75460029da142b53fa\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 01:54:00.221240\",\n                                    \"end_time\": \"2024-01-18 01:54:00.222560\",\n                                    \"duration\": \"0:00:00.001320\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {\n                                        \"chunks\": [\n                                            0,\n                                            10,\n                                            20,\n                                            30,\n                                            40\n                                        ],\n                                        \"stride\": 10\n                                    }\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": [\n                                {\n                                    \"name\": \"execute.execution.log_0\",\n                                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                                    \"catalog_relative_path\": \"simple-turing-0153/execute.execution.log_0\",\n                                    \"catalog_handler_location\": \".catalog\",\n                                    \"stage\": \"put\"\n                                }\n                            ]\n                        },\n                        \"iterate and execute.0.success\": {\n                            \"name\": \"success\",\n                            \"internal_name\": \"iterate and execute.0.success\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"success\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"30ca73bb01ac45db08b1ca75460029da142b53fa\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 01:54:00.301335\",\n                                    \"end_time\": \"2024-01-18 01:54:00.302161\",\n                                    \"duration\": \"0:00:00.000826\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {\n                                        \"chunks\": [\n                                            0,\n                                            10,\n                                            20,\n                                            30,\n                                            40\n                                        ],\n                                        \"stride\": 10\n                                    }\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": []\n                        }\n                    }\n                },\n                \"iterate and execute.10\": {\n                    \"internal_name\": \"iterate and execute.10\",\n                    \"status\": \"SUCCESS\",\n                    \"steps\": {\n                        \"iterate and execute.10.execute\": {\n                            \"name\": \"execute\",\n                            \"internal_name\": \"iterate and execute.10.execute\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"task\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"30ca73bb01ac45db08b1ca75460029da142b53fa\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 01:54:00.396194\",\n                                    \"end_time\": \"2024-01-18 01:54:00.397462\",\n                                    \"duration\": \"0:00:00.001268\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {\n                                        \"chunks\": [\n                                            0,\n                                            10,\n                                            20,\n                                            30,\n                                            40\n                                        ],\n                                        \"stride\": 10\n                                    }\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": [\n                                {\n                                    \"name\": \"execute.execution.log_10\",\n                                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                                    \"catalog_relative_path\": \"simple-turing-0153/execute.execution.log_10\",\n                                    \"catalog_handler_location\": \".catalog\",\n                                    \"stage\": \"put\"\n                                }\n                            ]\n                        },\n                        \"iterate and execute.10.success\": {\n                            \"name\": \"success\",\n                            \"internal_name\": \"iterate and execute.10.success\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"success\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"30ca73bb01ac45db08b1ca75460029da142b53fa\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 01:54:00.469211\",\n                                    \"end_time\": \"2024-01-18 01:54:00.470266\",\n                                    \"duration\": \"0:00:00.001055\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {\n                                        \"chunks\": [\n                                            0,\n                                            10,\n                                            20,\n                                            30,\n                                            40\n                                        ],\n                                        \"stride\": 10\n                                    }\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": []\n                        }\n                    }\n                },\n                \"iterate and execute.20\": {\n                    \"internal_name\": \"iterate and execute.20\",\n                    \"status\": \"SUCCESS\",\n                    \"steps\": {\n                        \"iterate and execute.20.execute\": {\n                            \"name\": \"execute\",\n                            \"internal_name\": \"iterate and execute.20.execute\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"task\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"30ca73bb01ac45db08b1ca75460029da142b53fa\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 01:54:00.558053\",\n                                    \"end_time\": \"2024-01-18 01:54:00.561472\",\n                                    \"duration\": \"0:00:00.003419\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {\n                                        \"chunks\": [\n                                            0,\n                                            10,\n                                            20,\n                                            30,\n                                            40\n                                        ],\n                                        \"stride\": 10\n                                    }\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": [\n                                {\n                                    \"name\": \"execute.execution.log_20\",\n                                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                                    \"catalog_relative_path\": \"simple-turing-0153/execute.execution.log_20\",\n                                    \"catalog_handler_location\": \".catalog\",\n                                    \"stage\": \"put\"\n                                }\n                            ]\n                        },\n                        \"iterate and execute.20.success\": {\n                            \"name\": \"success\",\n                            \"internal_name\": \"iterate and execute.20.success\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"success\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"30ca73bb01ac45db08b1ca75460029da142b53fa\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 01:54:00.660092\",\n                                    \"end_time\": \"2024-01-18 01:54:00.661215\",\n                                    \"duration\": \"0:00:00.001123\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {\n                                        \"chunks\": [\n                                            0,\n                                            10,\n                                            20,\n                                            30,\n                                            40\n                                        ],\n                                        \"stride\": 10\n                                    }\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": []\n                        }\n                    }\n                },\n                \"iterate and execute.30\": {\n                    \"internal_name\": \"iterate and execute.30\",\n                    \"status\": \"SUCCESS\",\n                    \"steps\": {\n                        \"iterate and execute.30.execute\": {\n                            \"name\": \"execute\",\n                            \"internal_name\": \"iterate and execute.30.execute\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"task\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"30ca73bb01ac45db08b1ca75460029da142b53fa\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 01:54:00.765689\",\n                                    \"end_time\": \"2024-01-18 01:54:00.766705\",\n                                    \"duration\": \"0:00:00.001016\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {\n                                        \"chunks\": [\n                                            0,\n                                            10,\n                                            20,\n                                            30,\n                                            40\n                                        ],\n                                        \"stride\": 10\n                                    }\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": [\n                                {\n                                    \"name\": \"execute.execution.log_30\",\n                                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                                    \"catalog_relative_path\": \"simple-turing-0153/execute.execution.log_30\",\n                                    \"catalog_handler_location\": \".catalog\",\n                                    \"stage\": \"put\"\n                                }\n                            ]\n                        },\n                        \"iterate and execute.30.success\": {\n                            \"name\": \"success\",\n                            \"internal_name\": \"iterate and execute.30.success\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"success\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"30ca73bb01ac45db08b1ca75460029da142b53fa\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 01:54:00.851112\",\n                                    \"end_time\": \"2024-01-18 01:54:00.852454\",\n                                    \"duration\": \"0:00:00.001342\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {\n                                        \"chunks\": [\n                                            0,\n                                            10,\n                                            20,\n                                            30,\n                                            40\n                                        ],\n                                        \"stride\": 10\n                                    }\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": []\n                        }\n                    }\n                },\n                \"iterate and execute.40\": {\n                    \"internal_name\": \"iterate and execute.40\",\n                    \"status\": \"SUCCESS\",\n                    \"steps\": {\n                        \"iterate and execute.40.execute\": {\n                            \"name\": \"execute\",\n                            \"internal_name\": \"iterate and execute.40.execute\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"task\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"30ca73bb01ac45db08b1ca75460029da142b53fa\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 01:54:00.950911\",\n                                    \"end_time\": \"2024-01-18 01:54:00.952000\",\n                                    \"duration\": \"0:00:00.001089\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {\n                                        \"chunks\": [\n                                            0,\n                                            10,\n                                            20,\n                                            30,\n                                            40\n                                        ],\n                                        \"stride\": 10\n                                    }\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": [\n                                {\n                                    \"name\": \"execute.execution.log_40\",\n                                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                                    \"catalog_relative_path\": \"simple-turing-0153/execute.execution.log_40\",\n                                    \"catalog_handler_location\": \".catalog\",\n                                    \"stage\": \"put\"\n                                }\n                            ]\n                        },\n                        \"iterate and execute.40.success\": {\n                            \"name\": \"success\",\n                            \"internal_name\": \"iterate and execute.40.success\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"success\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"30ca73bb01ac45db08b1ca75460029da142b53fa\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 01:54:01.032790\",\n                                    \"end_time\": \"2024-01-18 01:54:01.034254\",\n                                    \"duration\": \"0:00:00.001464\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {\n                                        \"chunks\": [\n                                            0,\n                                            10,\n                                            20,\n                                            30,\n                                            40\n                                        ],\n                                        \"stride\": 10\n                                    }\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": []\n                        }\n                    }\n                }\n            },\n            \"data_catalog\": []\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"30ca73bb01ac45db08b1ca75460029da142b53fa\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-18 01:54:01.141928\",\n                    \"end_time\": \"2024-01-18 01:54:01.142928\",\n                    \"duration\": \"0:00:00.001000\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {\n                        \"chunks\": [\n                            0,\n                            10,\n                            20,\n                            30,\n                            40\n                        ],\n                        \"stride\": 10\n                    }\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {\n        \"chunks\": [\n            0,\n            10,\n            20,\n            30,\n            40\n        ],\n        \"stride\": 10\n    },\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"placeholders\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"\",\n        \"parameters_file\": \"\",\n        \"configuration_file\": \"examples/configs/fs-catalog-run_log.yaml\",\n        \"tag\": \"\",\n        \"run_id\": \"simple-turing-0153\",\n        \"variables\": {},\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"chunk files\",\n            \"name\": \"\",\n            \"description\": \"\",\n            \"steps\": {\n                \"chunk files\": {\n                    \"type\": \"task\",\n                    \"name\": \"chunk files\",\n                    \"next\": \"iterate and execute\",\n                    \"on_failure\": \"\",\n                    \"executor_config\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1,\n                    \"command\": \"examples.concepts.map.chunk_files\",\n                    \"node_name\": \"chunk files\"\n                },\n                \"iterate and execute\": {\n                    \"type\": \"map\",\n                    \"name\": \"iterate and execute\",\n                    \"is_composite\": true,\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"executor_config\": {},\n                    \"iterate_on\": \"chunks\",\n                    \"iterate_as\": \"start_index\",\n                    \"branch\": {\n                        \"start_at\": \"execute\",\n                        \"name\": \"\",\n                        \"description\": \"\",\n                        \"steps\": {\n                            \"execute\": {\n                                \"type\": \"task\",\n                                \"name\": \"execute\",\n                                \"next\": \"success\",\n                                \"on_failure\": \"\",\n                                \"executor_config\": {},\n                                \"catalog\": null,\n                                \"max_attempts\": 1,\n                                \"command\": \"examples.concepts.map.process_chunk\",\n                                \"node_name\": \"execute\"\n                            },\n                            \"success\": {\n                                \"type\": \"success\",\n                                \"name\": \"success\"\n                            },\n                            \"fail\": {\n                                \"type\": \"fail\",\n                                \"name\": \"fail\"\n                            }\n                        }\n                    }\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre>"},{"location":"concepts/map/#traversal","title":"Traversal","text":"<p>A branch of a map step is considered success only if the <code>success</code> step is reached at the end. The steps of the pipeline can fail and be handled by on failure and redirected to <code>success</code> if that is the desired behavior.</p> <p>The map step is considered successful only if all the branches of the step have terminated successfully.</p>"},{"location":"concepts/map/#parameters","title":"Parameters","text":"<p>All the tasks defined in the branches of the map pipeline can access to parameters and data as usual.</p> <p>Warning</p> <p>The parameters can be updated by all the tasks and the last task to execute overwrites the previous changes.</p> <p>Since the order of execution is not guaranteed, its best to avoid mutating the same parameters in the steps belonging to map step.</p>"},{"location":"concepts/nesting/","title":"Nesting","text":"<p>As seen from the definitions of parallel or map, the branches are pipelines themselves. This allows for deeply nested workflows in runnable.</p> <p>Technically there is no limit in the depth of nesting but there are some practical considerations.</p> <ul> <li> <p>Not all workflow engines that runnable can transpile the workflow to support deeply nested workflows. AWS Step functions and Argo workflows support them.</p> </li> <li> <p>Deeply nested workflows are complex to understand and debug during errors.</p> </li> </ul>"},{"location":"concepts/nesting/#example","title":"Example","text":"python sdkyamlRun log <p>You can run this pipeline by <code>python examples/concepts/nesting.py</code></p> <pre><code>\"\"\"\nAn example to demonstrate nesting workflows within workflows.\n\n\nRun this pipeline by:\n    python examples/concepts/nesting.py\n\n\"\"\"\n\nfrom typing import List\n\nfrom runnable import Map, Parallel, Pipeline, PythonTask, Stub\n\n\ndef generate_list():\n    return List[int], list(range(2))\n\n\ndef main():\n    stub = Stub(name=\"executable\", terminate_with_success=True)\n    # A dummy pipeline that does nothing interesting\n    stubbed_pipeline = Pipeline(steps=[stub], add_terminal_nodes=True)\n\n    # A map step that executes the stubbed pipeline dynamically\n    # This step represents 2 parallel workflows when executed.\n    inner_most_map = Map(\n        name=\"inner most\",\n        branch=stubbed_pipeline,\n        iterate_on=\"array\",  # Parameter defined in line #20\n        iterate_as=\"y\",\n        terminate_with_success=True,\n    )\n\n    # A pipeline with map state.\n    map_pipeline = Pipeline(steps=[inner_most_map], add_terminal_nodes=True)\n\n    # A parallel step that executes a map_pipeline and stubbed pipeline\n    # By nesting a map within the parallel step, the total number of workflows is 4  (2 X 2 = 4)\n    nested_parallel = Parallel(\n        name=\"nested parallel\",\n        branches={\"a\": map_pipeline, \"b\": map_pipeline},\n        terminate_with_success=True,\n    )\n\n    # A pipeline with one nested parallel step\n    nested_parallel_pipeline = Pipeline(steps=[nested_parallel], add_terminal_nodes=True)\n\n    list_generator = PythonTask(name=\"generate list\", function=generate_list, returns=[\"array\"])\n\n    # A map step that iterates over array and executes nested_parallel_pipeline\n    # The total number of workflows is 50 by this time (2 X 2 X 2 = 8)\n    outer_most_map = Map(\n        name=\"outer most\",\n        branch=nested_parallel_pipeline,\n        iterate_on=\"array\",\n        iterate_as=\"x\",\n        terminate_with_success=True,\n    )\n\n    root_pipeline = Pipeline(steps=[list_generator, outer_most_map], add_terminal_nodes=True)\n\n    _ = root_pipeline.execute(configuration_file=\"examples/configs/fs-catalog-run_log.yaml\")\n\n    return root_pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>You can run this pipeline by <code>runnable execute examples/concepts/nesting.yaml</code></p> <pre><code>dag:\n  description: |\n    An example of nesting pipelines within pipelines.\n\n    Run this pipeline by:\n      runnable execute -f examples/concepts/nesting.yaml\n\n  start_at: generate_list\n  steps:\n    generate_list:\n      type: task\n      command_type: shell\n      returns:\n        - name: array\n          kind: json\n      command: export array=\"[0, 1]\"\n      next: outer most map\n    outer most map:\n      type: map\n      iterate_on: array\n      iterate_as: xarg\n      next: success\n      branch:\n        start_at: nested parallel\n        steps:\n          nested parallel:\n            type: parallel\n            next: success\n            branches:\n              a:\n                start_at: inner most map\n                steps:\n                  inner most map:\n                    type: map\n                    iterate_on: array\n                    iterate_as: yarg\n                    next: success\n                    branch:\n                      start_at: executable\n                      steps:\n                        executable:\n                          type: stub\n                          next: success\n                        success:\n                          type: success\n                        fail:\n                          type: fail\n                  success:\n                    type: success\n                  fail:\n                    type: fail\n              b:\n                start_at: inner most map\n                steps:\n                  inner most map:\n                    type: map\n                    iterate_on: array\n                    iterate_as: yarg\n                    next: success\n                    branch:\n                      start_at: executable\n                      steps:\n                        executable:\n                          type: stub\n                          next: success\n                        success:\n                          type: success\n                        fail:\n                          type: fail\n                  success:\n                    type: success\n                  fail:\n                    type: fail\n          success:\n            type: success\n          fail:\n            type: fail\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p> Click to expand! <p><pre><code>{\n    \"run_id\": \"bipartite-neumann-1913\",\n    \"dag_hash\": \"\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {\n        \"generate list\": {\n            \"name\": \"generate list\",\n            \"internal_name\": \"generate list\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-18 19:13:49.748656\",\n                    \"end_time\": \"2024-01-18 19:13:49.756826\",\n                    \"duration\": \"0:00:00.008170\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"generate_list.execution.log\",\n                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                    \"catalog_relative_path\": \"bipartite-neumann-1913/generate_list.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"outer most\": {\n            \"name\": \"outer most\",\n            \"internal_name\": \"outer most\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"map\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [],\n            \"user_defined_metrics\": {},\n            \"branches\": {\n                \"outer most.0\": {\n                    \"internal_name\": \"outer most.0\",\n                    \"status\": \"SUCCESS\",\n                    \"steps\": {\n                        \"outer most.0.nested parallel\": {\n                            \"name\": \"nested parallel\",\n                            \"internal_name\": \"outer most.0.nested parallel\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"parallel\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {\n                                \"outer most.0.nested parallel.a\": {\n                                    \"internal_name\": \"outer most.0.nested parallel.a\",\n                                    \"status\": \"SUCCESS\",\n                                    \"steps\": {\n                                        \"outer most.0.nested parallel.a.inner most\": {\n                                            \"name\": \"inner most\",\n                                            \"internal_name\": \"outer most.0.nested parallel.a.inner most\",\n                                            \"status\": \"SUCCESS\",\n                                            \"step_type\": \"map\",\n                                            \"message\": \"\",\n                                            \"mock\": false,\n                                            \"code_identities\": [\n                                                {\n                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                    \"code_identifier_type\": \"git\",\n                                                    \"code_identifier_dependable\": true,\n                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                    \"code_identifier_message\": \"\"\n                                                }\n                                            ],\n                                            \"attempts\": [],\n                                            \"user_defined_metrics\": {},\n                                            \"branches\": {\n                                                \"outer most.0.nested parallel.a.inner most.0\": {\n                                                    \"internal_name\": \"outer most.0.nested parallel.a.inner most.0\",\n                                                    \"status\": \"SUCCESS\",\n                                                    \"steps\": {\n                                                        \"outer most.0.nested parallel.a.inner most.0.executable\": {\n                                                            \"name\": \"executable\",\n                                                            \"internal_name\": \"outer most.0.nested parallel.a.inner most.0.executable\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"stub\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:49.997158\",\n                                                                    \"end_time\": \"2024-01-18 19:13:49.997172\",\n                                                                    \"duration\": \"0:00:00.000014\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        },\n                                                        \"outer most.0.nested parallel.a.inner most.0.success\": {\n                                                            \"name\": \"success\",\n                                                            \"internal_name\": \"outer most.0.nested parallel.a.inner most.0.success\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"success\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:50.060734\",\n                                                                    \"end_time\": \"2024-01-18 19:13:50.061345\",\n                                                                    \"duration\": \"0:00:00.000611\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        }\n                                                    }\n                                                },\n                                                \"outer most.0.nested parallel.a.inner most.1\": {\n                                                    \"internal_name\": \"outer most.0.nested parallel.a.inner most.1\",\n                                                    \"status\": \"SUCCESS\",\n                                                    \"steps\": {\n                                                        \"outer most.0.nested parallel.a.inner most.1.executable\": {\n                                                            \"name\": \"executable\",\n                                                            \"internal_name\": \"outer most.0.nested parallel.a.inner most.1.executable\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"stub\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:50.131067\",\n                                                                    \"end_time\": \"2024-01-18 19:13:50.131078\",\n                                                                    \"duration\": \"0:00:00.000011\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        },\n                                                        \"outer most.0.nested parallel.a.inner most.1.success\": {\n                                                            \"name\": \"success\",\n                                                            \"internal_name\": \"outer most.0.nested parallel.a.inner most.1.success\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"success\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:50.194038\",\n                                                                    \"end_time\": \"2024-01-18 19:13:50.194978\",\n                                                                    \"duration\": \"0:00:00.000940\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        }\n                                                    }\n                                                }\n                                            },\n                                            \"data_catalog\": []\n                                        },\n                                        \"outer most.0.nested parallel.a.success\": {\n                                            \"name\": \"success\",\n                                            \"internal_name\": \"outer most.0.nested parallel.a.success\",\n                                            \"status\": \"SUCCESS\",\n                                            \"step_type\": \"success\",\n                                            \"message\": \"\",\n                                            \"mock\": false,\n                                            \"code_identities\": [\n                                                {\n                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                    \"code_identifier_type\": \"git\",\n                                                    \"code_identifier_dependable\": true,\n                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                    \"code_identifier_message\": \"\"\n                                                }\n                                            ],\n                                            \"attempts\": [\n                                                {\n                                                    \"attempt_number\": 1,\n                                                    \"start_time\": \"2024-01-18 19:13:50.263302\",\n                                                    \"end_time\": \"2024-01-18 19:13:50.264215\",\n                                                    \"duration\": \"0:00:00.000913\",\n                                                    \"status\": \"SUCCESS\",\n                                                    \"message\": \"\",\n                                                    \"parameters\": {\n                                                        \"array\": [\n                                                            0,\n                                                            1\n                                                        ]\n                                                    }\n                                                }\n                                            ],\n                                            \"user_defined_metrics\": {},\n                                            \"branches\": {},\n                                            \"data_catalog\": []\n                                        }\n                                    }\n                                },\n                                \"outer most.0.nested parallel.b\": {\n                                    \"internal_name\": \"outer most.0.nested parallel.b\",\n                                    \"status\": \"SUCCESS\",\n                                    \"steps\": {\n                                        \"outer most.0.nested parallel.b.inner most\": {\n                                            \"name\": \"inner most\",\n                                            \"internal_name\": \"outer most.0.nested parallel.b.inner most\",\n                                            \"status\": \"SUCCESS\",\n                                            \"step_type\": \"map\",\n                                            \"message\": \"\",\n                                            \"mock\": false,\n                                            \"code_identities\": [\n                                                {\n                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                    \"code_identifier_type\": \"git\",\n                                                    \"code_identifier_dependable\": true,\n                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                    \"code_identifier_message\": \"\"\n                                                }\n                                            ],\n                                            \"attempts\": [],\n                                            \"user_defined_metrics\": {},\n                                            \"branches\": {\n                                                \"outer most.0.nested parallel.b.inner most.0\": {\n                                                    \"internal_name\": \"outer most.0.nested parallel.b.inner most.0\",\n                                                    \"status\": \"SUCCESS\",\n                                                    \"steps\": {\n                                                        \"outer most.0.nested parallel.b.inner most.0.executable\": {\n                                                            \"name\": \"executable\",\n                                                            \"internal_name\": \"outer most.0.nested parallel.b.inner most.0.executable\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"stub\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:50.402511\",\n                                                                    \"end_time\": \"2024-01-18 19:13:50.402525\",\n                                                                    \"duration\": \"0:00:00.000014\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        },\n                                                        \"outer most.0.nested parallel.b.inner most.0.success\": {\n                                                            \"name\": \"success\",\n                                                            \"internal_name\": \"outer most.0.nested parallel.b.inner most.0.success\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"success\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:50.468196\",\n                                                                    \"end_time\": \"2024-01-18 19:13:50.469218\",\n                                                                    \"duration\": \"0:00:00.001022\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        }\n                                                    }\n                                                },\n                                                \"outer most.0.nested parallel.b.inner most.1\": {\n                                                    \"internal_name\": \"outer most.0.nested parallel.b.inner most.1\",\n                                                    \"status\": \"SUCCESS\",\n                                                    \"steps\": {\n                                                        \"outer most.0.nested parallel.b.inner most.1.executable\": {\n                                                            \"name\": \"executable\",\n                                                            \"internal_name\": \"outer most.0.nested parallel.b.inner most.1.executable\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"stub\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:50.543884\",\n                                                                    \"end_time\": \"2024-01-18 19:13:50.543896\",\n                                                                    \"duration\": \"0:00:00.000012\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        },\n                                                        \"outer most.0.nested parallel.b.inner most.1.success\": {\n                                                            \"name\": \"success\",\n                                                            \"internal_name\": \"outer most.0.nested parallel.b.inner most.1.success\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"success\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:50.610499\",\n                                                                    \"end_time\": \"2024-01-18 19:13:50.611839\",\n                                                                    \"duration\": \"0:00:00.001340\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        }\n                                                    }\n                                                }\n                                            },\n                                            \"data_catalog\": []\n                                        },\n                                        \"outer most.0.nested parallel.b.success\": {\n                                            \"name\": \"success\",\n                                            \"internal_name\": \"outer most.0.nested parallel.b.success\",\n                                            \"status\": \"SUCCESS\",\n                                            \"step_type\": \"success\",\n                                            \"message\": \"\",\n                                            \"mock\": false,\n                                            \"code_identities\": [\n                                                {\n                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                    \"code_identifier_type\": \"git\",\n                                                    \"code_identifier_dependable\": true,\n                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                    \"code_identifier_message\": \"\"\n                                                }\n                                            ],\n                                            \"attempts\": [\n                                                {\n                                                    \"attempt_number\": 1,\n                                                    \"start_time\": \"2024-01-18 19:13:50.682749\",\n                                                    \"end_time\": \"2024-01-18 19:13:50.684374\",\n                                                    \"duration\": \"0:00:00.001625\",\n                                                    \"status\": \"SUCCESS\",\n                                                    \"message\": \"\",\n                                                    \"parameters\": {\n                                                        \"array\": [\n                                                            0,\n                                                            1\n                                                        ]\n                                                    }\n                                                }\n                                            ],\n                                            \"user_defined_metrics\": {},\n                                            \"branches\": {},\n                                            \"data_catalog\": []\n                                        }\n                                    }\n                                }\n                            },\n                            \"data_catalog\": []\n                        },\n                        \"outer most.0.success\": {\n                            \"name\": \"success\",\n                            \"internal_name\": \"outer most.0.success\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"success\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 19:13:50.763079\",\n                                    \"end_time\": \"2024-01-18 19:13:50.763895\",\n                                    \"duration\": \"0:00:00.000816\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {\n                                        \"array\": [\n                                            0,\n                                            1\n                                        ]\n                                    }\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": []\n                        }\n                    }\n                },\n                \"outer most.1\": {\n                    \"internal_name\": \"outer most.1\",\n                    \"status\": \"SUCCESS\",\n                    \"steps\": {\n                        \"outer most.1.nested parallel\": {\n                            \"name\": \"nested parallel\",\n                            \"internal_name\": \"outer most.1.nested parallel\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"parallel\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {\n                                \"outer most.1.nested parallel.a\": {\n                                    \"internal_name\": \"outer most.1.nested parallel.a\",\n                                    \"status\": \"SUCCESS\",\n                                    \"steps\": {\n                                        \"outer most.1.nested parallel.a.inner most\": {\n                                            \"name\": \"inner most\",\n                                            \"internal_name\": \"outer most.1.nested parallel.a.inner most\",\n                                            \"status\": \"SUCCESS\",\n                                            \"step_type\": \"map\",\n                                            \"message\": \"\",\n                                            \"mock\": false,\n                                            \"code_identities\": [\n                                                {\n                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                    \"code_identifier_type\": \"git\",\n                                                    \"code_identifier_dependable\": true,\n                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                    \"code_identifier_message\": \"\"\n                                                }\n                                            ],\n                                            \"attempts\": [],\n                                            \"user_defined_metrics\": {},\n                                            \"branches\": {\n                                                \"outer most.1.nested parallel.a.inner most.0\": {\n                                                    \"internal_name\": \"outer most.1.nested parallel.a.inner most.0\",\n                                                    \"status\": \"SUCCESS\",\n                                                    \"steps\": {\n                                                        \"outer most.1.nested parallel.a.inner most.0.executable\": {\n                                                            \"name\": \"executable\",\n                                                            \"internal_name\": \"outer most.1.nested parallel.a.inner most.0.executable\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"stub\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:50.981456\",\n                                                                    \"end_time\": \"2024-01-18 19:13:50.981467\",\n                                                                    \"duration\": \"0:00:00.000011\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        },\n                                                        \"outer most.1.nested parallel.a.inner most.0.success\": {\n                                                            \"name\": \"success\",\n                                                            \"internal_name\": \"outer most.1.nested parallel.a.inner most.0.success\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"success\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:51.045547\",\n                                                                    \"end_time\": \"2024-01-18 19:13:51.046526\",\n                                                                    \"duration\": \"0:00:00.000979\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        }\n                                                    }\n                                                },\n                                                \"outer most.1.nested parallel.a.inner most.1\": {\n                                                    \"internal_name\": \"outer most.1.nested parallel.a.inner most.1\",\n                                                    \"status\": \"SUCCESS\",\n                                                    \"steps\": {\n                                                        \"outer most.1.nested parallel.a.inner most.1.executable\": {\n                                                            \"name\": \"executable\",\n                                                            \"internal_name\": \"outer most.1.nested parallel.a.inner most.1.executable\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"stub\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:51.116489\",\n                                                                    \"end_time\": \"2024-01-18 19:13:51.116501\",\n                                                                    \"duration\": \"0:00:00.000012\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        },\n                                                        \"outer most.1.nested parallel.a.inner most.1.success\": {\n                                                            \"name\": \"success\",\n                                                            \"internal_name\": \"outer most.1.nested parallel.a.inner most.1.success\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"success\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:51.180471\",\n                                                                    \"end_time\": \"2024-01-18 19:13:51.181726\",\n                                                                    \"duration\": \"0:00:00.001255\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        }\n                                                    }\n                                                }\n                                            },\n                                            \"data_catalog\": []\n                                        },\n                                        \"outer most.1.nested parallel.a.success\": {\n                                            \"name\": \"success\",\n                                            \"internal_name\": \"outer most.1.nested parallel.a.success\",\n                                            \"status\": \"SUCCESS\",\n                                            \"step_type\": \"success\",\n                                            \"message\": \"\",\n                                            \"mock\": false,\n                                            \"code_identities\": [\n                                                {\n                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                    \"code_identifier_type\": \"git\",\n                                                    \"code_identifier_dependable\": true,\n                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                    \"code_identifier_message\": \"\"\n                                                }\n                                            ],\n                                            \"attempts\": [\n                                                {\n                                                    \"attempt_number\": 1,\n                                                    \"start_time\": \"2024-01-18 19:13:51.253035\",\n                                                    \"end_time\": \"2024-01-18 19:13:51.254294\",\n                                                    \"duration\": \"0:00:00.001259\",\n                                                    \"status\": \"SUCCESS\",\n                                                    \"message\": \"\",\n                                                    \"parameters\": {\n                                                        \"array\": [\n                                                            0,\n                                                            1\n                                                        ]\n                                                    }\n                                                }\n                                            ],\n                                            \"user_defined_metrics\": {},\n                                            \"branches\": {},\n                                            \"data_catalog\": []\n                                        }\n                                    }\n                                },\n                                \"outer most.1.nested parallel.b\": {\n                                    \"internal_name\": \"outer most.1.nested parallel.b\",\n                                    \"status\": \"SUCCESS\",\n                                    \"steps\": {\n                                        \"outer most.1.nested parallel.b.inner most\": {\n                                            \"name\": \"inner most\",\n                                            \"internal_name\": \"outer most.1.nested parallel.b.inner most\",\n                                            \"status\": \"SUCCESS\",\n                                            \"step_type\": \"map\",\n                                            \"message\": \"\",\n                                            \"mock\": false,\n                                            \"code_identities\": [\n                                                {\n                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                    \"code_identifier_type\": \"git\",\n                                                    \"code_identifier_dependable\": true,\n                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                    \"code_identifier_message\": \"\"\n                                                }\n                                            ],\n                                            \"attempts\": [],\n                                            \"user_defined_metrics\": {},\n                                            \"branches\": {\n                                                \"outer most.1.nested parallel.b.inner most.0\": {\n                                                    \"internal_name\": \"outer most.1.nested parallel.b.inner most.0\",\n                                                    \"status\": \"SUCCESS\",\n                                                    \"steps\": {\n                                                        \"outer most.1.nested parallel.b.inner most.0.executable\": {\n                                                            \"name\": \"executable\",\n                                                            \"internal_name\": \"outer most.1.nested parallel.b.inner most.0.executable\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"stub\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:51.399358\",\n                                                                    \"end_time\": \"2024-01-18 19:13:51.399368\",\n                                                                    \"duration\": \"0:00:00.000010\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        },\n                                                        \"outer most.1.nested parallel.b.inner most.0.success\": {\n                                                            \"name\": \"success\",\n                                                            \"internal_name\": \"outer most.1.nested parallel.b.inner most.0.success\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"success\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:51.465371\",\n                                                                    \"end_time\": \"2024-01-18 19:13:51.466805\",\n                                                                    \"duration\": \"0:00:00.001434\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        }\n                                                    }\n                                                },\n                                                \"outer most.1.nested parallel.b.inner most.1\": {\n                                                    \"internal_name\": \"outer most.1.nested parallel.b.inner most.1\",\n                                                    \"status\": \"SUCCESS\",\n                                                    \"steps\": {\n                                                        \"outer most.1.nested parallel.b.inner most.1.executable\": {\n                                                            \"name\": \"executable\",\n                                                            \"internal_name\": \"outer most.1.nested parallel.b.inner most.1.executable\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"stub\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:51.536944\",\n                                                                    \"end_time\": \"2024-01-18 19:13:51.536959\",\n                                                                    \"duration\": \"0:00:00.000015\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        },\n                                                        \"outer most.1.nested parallel.b.inner most.1.success\": {\n                                                            \"name\": \"success\",\n                                                            \"internal_name\": \"outer most.1.nested parallel.b.inner most.1.success\",\n                                                            \"status\": \"SUCCESS\",\n                                                            \"step_type\": \"success\",\n                                                            \"message\": \"\",\n                                                            \"mock\": false,\n                                                            \"code_identities\": [\n                                                                {\n                                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                                    \"code_identifier_type\": \"git\",\n                                                                    \"code_identifier_dependable\": true,\n                                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                                    \"code_identifier_message\": \"\"\n                                                                }\n                                                            ],\n                                                            \"attempts\": [\n                                                                {\n                                                                    \"attempt_number\": 1,\n                                                                    \"start_time\": \"2024-01-18 19:13:51.602562\",\n                                                                    \"end_time\": \"2024-01-18 19:13:51.604264\",\n                                                                    \"duration\": \"0:00:00.001702\",\n                                                                    \"status\": \"SUCCESS\",\n                                                                    \"message\": \"\",\n                                                                    \"parameters\": {\n                                                                        \"array\": [\n                                                                            0,\n                                                                            1\n                                                                        ]\n                                                                    }\n                                                                }\n                                                            ],\n                                                            \"user_defined_metrics\": {},\n                                                            \"branches\": {},\n                                                            \"data_catalog\": []\n                                                        }\n                                                    }\n                                                }\n                                            },\n                                            \"data_catalog\": []\n                                        },\n                                        \"outer most.1.nested parallel.b.success\": {\n                                            \"name\": \"success\",\n                                            \"internal_name\": \"outer most.1.nested parallel.b.success\",\n                                            \"status\": \"SUCCESS\",\n                                            \"step_type\": \"success\",\n                                            \"message\": \"\",\n                                            \"mock\": false,\n                                            \"code_identities\": [\n                                                {\n                                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                                    \"code_identifier_type\": \"git\",\n                                                    \"code_identifier_dependable\": true,\n                                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                                    \"code_identifier_message\": \"\"\n                                                }\n                                            ],\n                                            \"attempts\": [\n                                                {\n                                                    \"attempt_number\": 1,\n                                                    \"start_time\": \"2024-01-18 19:13:51.676208\",\n                                                    \"end_time\": \"2024-01-18 19:13:51.678050\",\n                                                    \"duration\": \"0:00:00.001842\",\n                                                    \"status\": \"SUCCESS\",\n                                                    \"message\": \"\",\n                                                    \"parameters\": {\n                                                        \"array\": [\n                                                            0,\n                                                            1\n                                                        ]\n                                                    }\n                                                }\n                                            ],\n                                            \"user_defined_metrics\": {},\n                                            \"branches\": {},\n                                            \"data_catalog\": []\n                                        }\n                                    }\n                                }\n                            },\n                            \"data_catalog\": []\n                        },\n                        \"outer most.1.success\": {\n                            \"name\": \"success\",\n                            \"internal_name\": \"outer most.1.success\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"success\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 19:13:51.760988\",\n                                    \"end_time\": \"2024-01-18 19:13:51.762012\",\n                                    \"duration\": \"0:00:00.001024\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {\n                                        \"array\": [\n                                            0,\n                                            1\n                                        ]\n                                    }\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": []\n                        }\n                    }\n                }\n            },\n            \"data_catalog\": []\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"99139c3507898c60932ad5d35c08b395399a19f6\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-18 19:13:51.863908\",\n                    \"end_time\": \"2024-01-18 19:13:51.863975\",\n                    \"duration\": \"0:00:00.000067\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {\n                        \"array\": [\n                            0,\n                            1\n                        ]\n                    }\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {\n        \"array\": [\n            0,\n            1\n        ]\n    },\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"placeholders\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"buffered\",\n            \"service_type\": \"run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"\",\n        \"parameters_file\": \"\",\n        \"configuration_file\": \"\",\n        \"tag\": \"\",\n        \"run_id\": \"bipartite-neumann-1913\",\n        \"variables\": {},\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"generate list\",\n            \"name\": \"\",\n            \"description\": \"\",\n            \"steps\": {\n                \"generate list\": {\n                    \"type\": \"task\",\n                    \"name\": \"generate list\",\n                    \"next\": \"outer most\",\n                    \"on_failure\": \"\",\n                    \"executor_config\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1,\n                    \"command\": \"examples.concepts.nesting.generate_list\",\n                    \"node_name\": \"generate list\"\n                },\n                \"outer most\": {\n                    \"type\": \"map\",\n                    \"name\": \"outer most\",\n                    \"is_composite\": true,\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"executor_config\": {},\n                    \"iterate_on\": \"array\",\n                    \"iterate_as\": \"x\",\n                    \"branch\": {\n                        \"start_at\": \"nested parallel\",\n                        \"name\": \"\",\n                        \"description\": \"\",\n                        \"steps\": {\n                            \"nested parallel\": {\n                                \"type\": \"parallel\",\n                                \"name\": \"nested parallel\",\n                                \"next\": \"success\",\n                                \"on_failure\": \"\",\n                                \"executor_config\": {},\n                                \"branches\": {\n                                    \"a\": {\n                                        \"start_at\": \"inner most\",\n                                        \"name\": \"\",\n                                        \"description\": \"\",\n                                        \"steps\": {\n                                            \"inner most\": {\n                                                \"type\": \"map\",\n                                                \"name\": \"inner most\",\n                                                \"is_composite\": true,\n                                                \"next\": \"success\",\n                                                \"on_failure\": \"\",\n                                                \"executor_config\": {},\n                                                \"iterate_on\": \"array\",\n                                                \"iterate_as\": \"y\",\n                                                \"branch\": {\n                                                    \"start_at\": \"executable\",\n                                                    \"name\": \"\",\n                                                    \"description\": \"\",\n                                                    \"steps\": {\n                                                        \"executable\": {\n                                                            \"type\": \"stub\",\n                                                            \"name\": \"executable\",\n                                                            \"next\": \"success\",\n                                                            \"on_failure\": \"\",\n                                                            \"executor_config\": {},\n                                                            \"catalog\": null,\n                                                            \"max_attempts\": 1\n                                                        },\n                                                        \"success\": {\n                                                            \"type\": \"success\",\n                                                            \"name\": \"success\"\n                                                        },\n                                                        \"fail\": {\n                                                            \"type\": \"fail\",\n                                                            \"name\": \"fail\"\n                                                        }\n                                                    }\n                                                }\n                                            },\n                                            \"success\": {\n                                                \"type\": \"success\",\n                                                \"name\": \"success\"\n                                            },\n                                            \"fail\": {\n                                                \"type\": \"fail\",\n                                                \"name\": \"fail\"\n                                            }\n                                        }\n                                    },\n                                    \"b\": {\n                                        \"start_at\": \"inner most\",\n                                        \"name\": \"\",\n                                        \"description\": \"\",\n                                        \"steps\": {\n                                            \"inner most\": {\n                                                \"type\": \"map\",\n                                                \"name\": \"inner most\",\n                                                \"is_composite\": true,\n                                                \"next\": \"success\",\n                                                \"on_failure\": \"\",\n                                                \"executor_config\": {},\n                                                \"iterate_on\": \"array\",\n                                                \"iterate_as\": \"y\",\n                                                \"branch\": {\n                                                    \"start_at\": \"executable\",\n                                                    \"name\": \"\",\n                                                    \"description\": \"\",\n                                                    \"steps\": {\n                                                        \"executable\": {\n                                                            \"type\": \"stub\",\n                                                            \"name\": \"executable\",\n                                                            \"next\": \"success\",\n                                                            \"on_failure\": \"\",\n                                                            \"executor_config\": {},\n                                                            \"catalog\": null,\n                                                            \"max_attempts\": 1\n                                                        },\n                                                        \"success\": {\n                                                            \"type\": \"success\",\n                                                            \"name\": \"success\"\n                                                        },\n                                                        \"fail\": {\n                                                            \"type\": \"fail\",\n                                                            \"name\": \"fail\"\n                                                        }\n                                                    }\n                                                }\n                                            },\n                                            \"success\": {\n                                                \"type\": \"success\",\n                                                \"name\": \"success\"\n                                            },\n                                            \"fail\": {\n                                                \"type\": \"fail\",\n                                                \"name\": \"fail\"\n                                            }\n                                        }\n                                    }\n                                }\n                            },\n                            \"success\": {\n                                \"type\": \"success\",\n                                \"name\": \"success\"\n                            },\n                            \"fail\": {\n                                \"type\": \"fail\",\n                                \"name\": \"fail\"\n                            }\n                        }\n                    }\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre> </p>"},{"location":"concepts/parallel/","title":"Parallel","text":"<p>Parallel nodes in runnable allows you to run multiple pipelines in parallel and use your compute resources efficiently.</p>"},{"location":"concepts/parallel/#example","title":"Example","text":"<p>Only stubs?</p> <p>All the steps in the below example are <code>stubbed</code> for convenience. The functionality is similar even if the steps are execution units like <code>tasks</code> or any other nodes.</p> <p>We support deeply nested steps. For example, a step in the parallel branch can be a <code>map</code> which internally loops over a <code>dag</code> and so on. Though this functionality is useful, it can be difficult to debug and understand in large code bases.</p> <p>Below is a stubbed out example of a pipeline that trains two models in parallel and create an ensemble model to do the inference. The models XGBoost and Random Forest (RF model) are trained in parallel and training of the ensemble model happens only after both models are (successfully) trained.</p> VisualisationPipeline in yamlpython sdkRun log <p>In the below visualisation, the green lined steps happen in sequence and wait for the previous step to successfully complete.</p> <p>The branches lined in yellow run in parallel to each other but sequential within the branch.</p> <pre><code>flowchart TD\n\n    getFeatures([Get Features]):::green\n    trainStep(Train Models):::green\n    ensembleModel([Ensemble Modelling]):::green\n    inference([Run Inference]):::green\n    success([Success]):::green\n\n    prepareXG([Prepare for XGBoost]):::yellow\n    trainXG([Train XGBoost]):::yellow\n    successXG([XGBoost success]):::yellow\n    prepareXG --&gt; trainXG --&gt; successXG\n\n    trainRF([Train RF model]):::yellow\n    successRF([RF Model success]):::yellow\n    trainRF --&gt; successRF\n\n\n    getFeatures --&gt; trainStep\n    trainStep --&gt; prepareXG\n    trainStep --&gt; trainRF\n    successXG --&gt; ensembleModel\n    successRF --&gt; ensembleModel\n    ensembleModel --&gt; inference\n    inference --&gt; success\n\n\n    classDef yellow stroke:#FFFF00\n    classDef green stroke:#0f0\n\n</code></pre> <pre><code>dag:\n  description: |\n    This is a stubbed pipeline that demonstrates parallel\n    pipeline execution.\n    Note that the branches schema is same as dag schema.\n\n    All the steps are mocked and they will just pass through.\n    Use this pattern to define the skeleton of your pipeline and\n    flesh out the steps later.\n\n    You can run this pipeline by:\n       runnable execute -f examples/concepts/parallel.yaml\n  start_at: Get Features\n  steps:\n    Get Features:\n      type: stub\n      next: Train Models\n    Train Models:\n      type: parallel\n      next: Ensemble Modelling\n      branches:\n        XGBoost:\n          start_at: Prepare for XGBoost\n          steps:\n            Prepare for XGBoost:\n              type: stub\n              next: Train XGBoost\n            Train XGBoost:\n              type: stub\n              next: XGBoost success\n            XGBoost success:\n              type: success\n            fail:\n              type: fail\n        RF model:\n          start_at: Train RF Model\n          steps:\n            Train RF Model:\n              type: stub\n              next: RF Model Success\n            RF Model Success:\n              type: success\n            fail:\n              type: fail\n    Ensemble Modelling:\n      type: stub\n      next: Run Inference\n    Run Inference:\n      type: stub\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p>You can run this example by: <code>python examples/concepts/parallel.py</code></p> <pre><code>\"\"\"\nThis is a stubbed pipeline that demonstrates parallel\n    pipeline execution.\n    Note that the branches schema is same as dag schema.\n\n    All the steps are mocked and they will just pass through.\n    Use this pattern to define the skeleton of your pipeline and\n    flesh out the steps later.\n\n    You can run this pipeline by:\n       python examples/concepts/parallel.py\n\"\"\"\n\nfrom runnable import Parallel, Pipeline, Stub\n\n\ndef main():\n    # The steps in XGBoost training pipeline\n    prepare_xgboost = Stub(name=\"Prepare for XGBoost\")\n    train_xgboost = Stub(name=\"Train XGBoost\", terminate_with_success=True)\n\n    # prepare_xgboost &gt;&gt; train_xgboost\n\n    # The pipeline for XGBoost training\n    xgboost = Pipeline(\n        name=\"XGBoost\",\n        steps=[prepare_xgboost, train_xgboost],\n        # start_at=prepare_xgboost,\n        add_terminal_nodes=True,\n    )\n\n    # The steps and pipeline  in Random Forest training\n    train_rf = Stub(name=\"Train RF\", terminate_with_success=True)\n    rfmodel = Pipeline(\n        steps=[train_rf],\n        # start_at=train_rf,\n        add_terminal_nodes=True,\n    )\n\n    # The steps in parent pipeline\n    get_features = Stub(name=\"Get Features\")\n    # The parallel step definition.\n    # Branches are just pipelines themselves\n    train_models = Parallel(\n        name=\"Train Models\",\n        branches={\"XGBoost\": xgboost, \"RF Model\": rfmodel},\n    )\n    ensemble_model = Stub(name=\"Ensemble Modelling\")\n    run_inference = Stub(name=\"Run Inference\", terminate_with_success=True)\n\n    # get_features &gt;&gt; train_models &gt;&gt; ensemble_model &gt;&gt; run_inference\n\n    # The parent pipeline\n    pipeline = Pipeline(\n        steps=[get_features, train_models, ensemble_model, run_inference],\n        # start_at=get_features,\n        add_terminal_nodes=True,\n    )\n\n    _ = pipeline.execute(configuration_file=\"examples/configs/fs-catalog-run_log.yaml\")\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>The step log for the parallel branch <code>Train models</code> has branches which have similar structure to a run log.</p> <pre><code>{\n    \"run_id\": \"savory-pike-0201\",\n    \"dag_hash\": \"\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {\n        \"Get Features\": {\n            \"name\": \"Get Features\",\n            \"internal_name\": \"Get Features\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"stub\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f0a2719001de9be30c27069933e4b4a64a065e2b\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-18 02:01:10.978646\",\n                    \"end_time\": \"2024-01-18 02:01:10.978665\",\n                    \"duration\": \"0:00:00.000019\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"Train Models\": {\n            \"name\": \"Train Models\",\n            \"internal_name\": \"Train Models\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"parallel\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f0a2719001de9be30c27069933e4b4a64a065e2b\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [],\n            \"user_defined_metrics\": {},\n            \"branches\": {\n                \"Train Models.XGBoost\": {\n                    \"internal_name\": \"Train Models.XGBoost\",\n                    \"status\": \"SUCCESS\",\n                    \"steps\": {\n                        \"Train Models.XGBoost.Prepare for XGBoost\": {\n                            \"name\": \"Prepare for XGBoost\",\n                            \"internal_name\": \"Train Models.XGBoost.Prepare for XGBoost\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"stub\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"f0a2719001de9be30c27069933e4b4a64a065e2b\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 02:01:11.132822\",\n                                    \"end_time\": \"2024-01-18 02:01:11.132840\",\n                                    \"duration\": \"0:00:00.000018\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {}\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": []\n                        },\n                        \"Train Models.XGBoost.Train XGBoost\": {\n                            \"name\": \"Train XGBoost\",\n                            \"internal_name\": \"Train Models.XGBoost.Train XGBoost\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"stub\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"f0a2719001de9be30c27069933e4b4a64a065e2b\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 02:01:11.216418\",\n                                    \"end_time\": \"2024-01-18 02:01:11.216430\",\n                                    \"duration\": \"0:00:00.000012\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {}\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": []\n                        },\n                        \"Train Models.XGBoost.success\": {\n                            \"name\": \"success\",\n                            \"internal_name\": \"Train Models.XGBoost.success\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"success\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"f0a2719001de9be30c27069933e4b4a64a065e2b\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 02:01:11.291222\",\n                                    \"end_time\": \"2024-01-18 02:01:11.292140\",\n                                    \"duration\": \"0:00:00.000918\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {}\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": []\n                        }\n                    }\n                },\n                \"Train Models.RF Model\": {\n                    \"internal_name\": \"Train Models.RF Model\",\n                    \"status\": \"SUCCESS\",\n                    \"steps\": {\n                        \"Train Models.RF Model.Train RF\": {\n                            \"name\": \"Train RF\",\n                            \"internal_name\": \"Train Models.RF Model.Train RF\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"stub\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"f0a2719001de9be30c27069933e4b4a64a065e2b\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 02:01:11.379438\",\n                                    \"end_time\": \"2024-01-18 02:01:11.379453\",\n                                    \"duration\": \"0:00:00.000015\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {}\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": []\n                        },\n                        \"Train Models.RF Model.success\": {\n                            \"name\": \"success\",\n                            \"internal_name\": \"Train Models.RF Model.success\",\n                            \"status\": \"SUCCESS\",\n                            \"step_type\": \"success\",\n                            \"message\": \"\",\n                            \"mock\": false,\n                            \"code_identities\": [\n                                {\n                                    \"code_identifier\": \"f0a2719001de9be30c27069933e4b4a64a065e2b\",\n                                    \"code_identifier_type\": \"git\",\n                                    \"code_identifier_dependable\": true,\n                                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                                    \"code_identifier_message\": \"\"\n                                }\n                            ],\n                            \"attempts\": [\n                                {\n                                    \"attempt_number\": 1,\n                                    \"start_time\": \"2024-01-18 02:01:11.458716\",\n                                    \"end_time\": \"2024-01-18 02:01:11.459695\",\n                                    \"duration\": \"0:00:00.000979\",\n                                    \"status\": \"SUCCESS\",\n                                    \"message\": \"\",\n                                    \"parameters\": {}\n                                }\n                            ],\n                            \"user_defined_metrics\": {},\n                            \"branches\": {},\n                            \"data_catalog\": []\n                        }\n                    }\n                }\n            },\n            \"data_catalog\": []\n        },\n        \"Ensemble Modelling\": {\n            \"name\": \"Ensemble Modelling\",\n            \"internal_name\": \"Ensemble Modelling\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"stub\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f0a2719001de9be30c27069933e4b4a64a065e2b\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-18 02:01:11.568072\",\n                    \"end_time\": \"2024-01-18 02:01:11.568085\",\n                    \"duration\": \"0:00:00.000013\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"Run Inference\": {\n            \"name\": \"Run Inference\",\n            \"internal_name\": \"Run Inference\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"stub\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f0a2719001de9be30c27069933e4b4a64a065e2b\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-18 02:01:11.650023\",\n                    \"end_time\": \"2024-01-18 02:01:11.650037\",\n                    \"duration\": \"0:00:00.000014\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f0a2719001de9be30c27069933e4b4a64a065e2b\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-18 02:01:11.727802\",\n                    \"end_time\": \"2024-01-18 02:01:11.728651\",\n                    \"duration\": \"0:00:00.000849\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"placeholders\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"\",\n        \"parameters_file\": \"\",\n        \"configuration_file\": \"examples/configs/fs-catalog-run_log.yaml\",\n        \"tag\": \"\",\n        \"run_id\": \"savory-pike-0201\",\n        \"variables\": {},\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"Get Features\",\n            \"name\": \"\",\n            \"description\": \"\",\n            \"steps\": {\n                \"Get Features\": {\n                    \"type\": \"stub\",\n                    \"name\": \"Get Features\",\n                    \"next\": \"Train Models\",\n                    \"on_failure\": \"\",\n                    \"executor_config\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1\n                },\n                \"Train Models\": {\n                    \"type\": \"parallel\",\n                    \"name\": \"Train Models\",\n                    \"next\": \"Ensemble Modelling\",\n                    \"on_failure\": \"\",\n                    \"executor_config\": {},\n                    \"branches\": {\n                        \"XGBoost\": {\n                            \"start_at\": \"Prepare for XGBoost\",\n                            \"name\": \"\",\n                            \"description\": \"\",\n                            \"steps\": {\n                                \"Prepare for XGBoost\": {\n                                    \"type\": \"stub\",\n                                    \"name\": \"Prepare for XGBoost\",\n                                    \"next\": \"Train XGBoost\",\n                                    \"on_failure\": \"\",\n                                    \"executor_config\": {},\n                                    \"catalog\": null,\n                                    \"max_attempts\": 1\n                                },\n                                \"Train XGBoost\": {\n                                    \"type\": \"stub\",\n                                    \"name\": \"Train XGBoost\",\n                                    \"next\": \"success\",\n                                    \"on_failure\": \"\",\n                                    \"executor_config\": {},\n                                    \"catalog\": null,\n                                    \"max_attempts\": 1\n                                },\n                                \"success\": {\n                                    \"type\": \"success\",\n                                    \"name\": \"success\"\n                                },\n                                \"fail\": {\n                                    \"type\": \"fail\",\n                                    \"name\": \"fail\"\n                                }\n                            }\n                        },\n                        \"RF Model\": {\n                            \"start_at\": \"Train RF\",\n                            \"name\": \"\",\n                            \"description\": \"\",\n                            \"steps\": {\n                                \"Train RF\": {\n                                    \"type\": \"stub\",\n                                    \"name\": \"Train RF\",\n                                    \"next\": \"success\",\n                                    \"on_failure\": \"\",\n                                    \"executor_config\": {},\n                                    \"catalog\": null,\n                                    \"max_attempts\": 1\n                                },\n                                \"success\": {\n                                    \"type\": \"success\",\n                                    \"name\": \"success\"\n                                },\n                                \"fail\": {\n                                    \"type\": \"fail\",\n                                    \"name\": \"fail\"\n                                }\n                            }\n                        }\n                    }\n                },\n                \"Ensemble Modelling\": {\n                    \"type\": \"stub\",\n                    \"name\": \"Ensemble Modelling\",\n                    \"next\": \"Run Inference\",\n                    \"on_failure\": \"\",\n                    \"executor_config\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1\n                },\n                \"Run Inference\": {\n                    \"type\": \"stub\",\n                    \"name\": \"Run Inference\",\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"executor_config\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre> <p>All pipelines, nested or parent, have the same structure as defined in pipeline definition.</p> <p>The parent pipeline defines a step <code>Train models</code> which is a parallel step. The branches, XGBoost and RF model, are pipelines themselves.</p>"},{"location":"concepts/parallel/#traversal","title":"Traversal","text":"<p>A branch of a parallel step is considered success only if the <code>success</code> step is reached at the end. The steps of the pipeline can fail and be handled by on failure and redirected to <code>success</code> if that is the desired behavior.</p> <p>The parallel step is considered successful only if all the branches of the step have terminated successfully.</p>"},{"location":"concepts/parallel/#parameters","title":"Parameters","text":"<p>All the tasks defined in the branches of the parallel pipeline can access to parameters and data as usual.</p> <p>Warning</p> <p>The parameters can be updated by all the tasks and the last task to execute overwrites the previous changes.</p> <p>Since the order of execution is not guaranteed, its best to avoid mutating the same parameters in the steps belonging to parallel step.</p>"},{"location":"concepts/parameters/","title":"Parameters","text":""},{"location":"concepts/parameters/#todo_concretly_show_an_example","title":"TODO: Concretly show an example!","text":"<p>In runnable, <code>parameters</code> are python data types that can be passed from one <code>task</code> to the next <code>task</code>. These parameters can be accessed by the <code>task</code> either as environment variables, arguments of the <code>python function</code> or using the API.</p>"},{"location":"concepts/parameters/#initial_parameters","title":"Initial parameters","text":"<p>The initial parameters of the pipeline can set by using a <code>yaml</code> file and presented during execution</p> <p><code>--parameters-file, -parameters</code> while using the runnable CLI</p> <p>or by using <code>parameters_file</code> with the sdk.</p> <p>They can also be set using environment variables which override the parameters defined by the file.</p> yamlenvironment variables <p>Deeply nested yaml objects are supported.</p> <pre><code>spam: \"Hello\"\neggs:\n  ham: \"Yes, please!!\"\n</code></pre> <p>Any environment variables prefixed with <code>runnable_PRM_</code> are interpreted as parameters by the <code>tasks</code>.</p> <p>The yaml formatted parameters can also be defined as:</p> <pre><code>export runnable_PRM_spam=\"hello\"\nexport runnable_PRM_eggs='{\"ham\": \"Yes, please!!\"}'\n</code></pre> <p>Parameters defined by environment variables override parameters defined by <code>yaml</code>. This can be useful to do a quick experimentation without changing code.</p>"},{"location":"concepts/parameters/#parameters_flow","title":"Parameters flow","text":"<p>Tasks can access and return parameters and the patterns are specific to the <code>command_type</code> of the task nodes. Please refer to tasks for more information.</p>"},{"location":"concepts/pipeline/","title":"Pipeline","text":"Steps <p>In runnable, a step can be a simple <code>task</code> or <code>stub</code> or complex nested pipelines like <code>parallel</code> branches, embedded <code>dags</code> or dynamic workflows.</p> <p>In this section, we use <code>stub</code> for convenience. For more in depth information about other types, please see the relevant section.</p> <p>In runnable, we use the words</p> <ul> <li><code>dag</code>, <code>workflows</code> and <code>pipeline</code> interchangeably.</li> <li><code>nodes</code>, <code>steps</code> interchangeably.</li> </ul> <p>Dag or directed acyclic graphs are a way to define your pipelines. Its a graph representation of the list of tasks you want to perform and the order of it.</p> <p></p>"},{"location":"concepts/pipeline/#example","title":"Example","text":"<p>Below is an example pipeline.</p> yamlpython <pre><code>dag:\n  description: |\n    This is a stubbed pipeline that does 3 steps in sequence.\n    All the steps are mocked and they will just pass through.\n    Use this pattern to define the skeleton of your pipeline\n    and flesh out the steps later.\n\n    You can run this pipeline by:\n    runnable execute -f examples/pipelines/traversal.yaml\n\n  start_at: step 1\n  steps:\n    step 1:\n      type: stub\n      next: step 2\n    step 2:\n      type: stub\n      next: step 3\n    step 3:\n      type: stub\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <pre><code>\"\"\"\nThis is a stubbed pipeline that does 4 steps in sequence.\nAll the steps are mocked and they will just pass through.\nUse this pattern to define the skeleton of your pipeline and\nflesh out the steps later.\n\nYou can run this pipeline by python run examples/pipelines/traversal.py\n\"\"\"\n\nfrom runnable import Pipeline, Stub\n\n\ndef main():\n    step_1 = Stub(name=\"Step 1\")\n\n    step_2 = Stub(name=\"Step 2\")\n\n    step_3 = Stub(name=\"Step 3\", terminate_with_success=True)\n\n    pipeline = Pipeline(\n        steps=[step_1, step_2, step_3],\n        add_terminal_nodes=True,\n    )\n\n    run_log = pipeline.execute()\n    print(run_log)\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p></p> <p>A closer look at the example:</p>"},{"location":"concepts/pipeline/#start_at","title":"start_at","text":"<ul> <li> start_at step is the starting node of the traversal.</li> </ul> yamlpython <p>The value should be valid key in <code>steps</code></p> <pre><code>start_at: step 1\nsteps:\n</code></pre> <p>The node should be part of <code>steps</code></p> <pre><code>main()\n</code></pre> <p>By using a <code>parallel</code> node as starting node, you can get the behavior of multi-root graph.</p> <p></p>"},{"location":"concepts/pipeline/#steps","title":"Steps","text":"<ul> <li> Apart from the terminal nodes (<code>success</code> and <code>fail</code>), the pipeline should have at least one more node.</li> </ul> Step names <p>In runnable, the names of steps should not have <code>%</code> or <code>.</code> in them.</p> <p>You can name them as descriptive as you want.</p> yamlpython <pre><code>steps:\n  step 1:\n    type: stub\n    next: step 2\n  step 2:\n    type: stub\n    next: step 3\n  step 3:\n    type: stub\n    next: success\n</code></pre> <pre><code>    step_1 = Stub(name=\"Step 1\")\n\n    step_2 = Stub(name=\"Step 2\")\n\n    step_3 = Stub(name=\"Step 3\", terminate_with_success=True)\n\n    pipeline = Pipeline(\n        steps=[step_1, step_2, step_3],\n        add_terminal_nodes=True,\n    )\n\n    run_log = pipeline.execute()\n    print(run_log)\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p></p>"},{"location":"concepts/pipeline/#linking","title":"Linking","text":"<ul> <li> All nodes except for <code>success</code> and <code>fail</code> nodes need to have a <code>next</code> step to execute upon successful execution.</li> </ul> <p>Visually, the above pipeline can be seen as:</p> Traversal <p>Start at step1.</p> <p>If it is successful, go to <code>next</code> step of the pipeline until we reach the success state.</p> <p>Any failure in execution of step would, by default, go to the fail state.</p> <pre><code>stateDiagram-v2\n    state \"Start at step 1\" as start_at\n    state \"step 2\" as step_2\n    state \"step 3\" as step_3\n    state \"Success\" as success\n    state \"Fail\" as fail\n\n\n    [*] --&gt; start_at\n    start_at --&gt; step_2 : #9989;\n    step_2 --&gt; step_3 : #9989;\n    step_3 --&gt; success : #9989;\n    start_at --&gt; fail: #10060;\n    step_2--&gt; fail: #10060;\n    step_3--&gt; fail: #10060;\n    success --&gt; [*]\n    fail --&gt; [*]</code></pre> yamlpython <pre><code>steps:\n  step 1:\n    type: stub\n    next: step 2\n  step 2:\n    type: stub\n    next: step 3\n  step 3:\n    type: stub\n    next: success\n</code></pre> <pre><code>    step_1 = Stub(name=\"Step 1\")\n\n    step_2 = Stub(name=\"Step 2\")\n\n    step_3 = Stub(name=\"Step 3\", terminate_with_success=True)\n\n    pipeline = Pipeline(\n        steps=[step_1, step_2, step_3],\n        add_terminal_nodes=True,\n    )\n\n    run_log = pipeline.execute()\n    print(run_log)\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"concepts/pipeline/#on_failure","title":"on failure","text":"<p>By default, any failure during the execution of step will traverse to <code>fail</code> node marking the execution as failed. You can override this behavior by using <code>on_failure</code></p> yamlpythontraversal <pre><code>dag:\n  description: |\n    This is a simple pipeline to demonstrate failure in a step.\n\n    The default behavior is to traverse to step type fail and mark the run as failed.\n    But you can control it by providing on_failure.\n\n    In this example: step 1 fails and moves to step 3 skipping step 2. The pipeline status\n    is considered to be success.\n\n    step 1 (FAIL) &gt;&gt; step 3 &gt;&gt; success\n\n    You can run this pipeline by runnable execute -f examples/on-failure.yaml\n  start_at: step 1\n  steps:\n    step 1:\n      type: task\n      command_type: shell\n      command: exit 1 # This will fail!\n      next: step 2\n      on_failure: step 3\n    step 2:\n      type: stub # This step will never reach\n      next: step 3\n    step 3:\n      type: stub\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <pre><code>\"\"\"\nThis is a simple pipeline to demonstrate failure in a step.\n\n    The default behavior is to traverse to step type fail and mark the run as failed.\n    But you can control it by providing on_failure.\n\n    In this example: step 1 fails and moves to step 3 skipping step 2. The pipeline status\n    is considered to be success.\n\n    step 1 (FAIL) &gt;&gt; step 3 &gt;&gt; success\n\n    You can run this example by:\n    python examples/on_failure.py\n\"\"\"\n\nfrom runnable import Pipeline, ShellTask, Stub\n\n\ndef main():\n    step_1 = ShellTask(name=\"step 1\", command=\"exit 1\")  # This will fail\n\n    step_2 = Stub(name=\"step 2\")\n\n    step_3 = Stub(name=\"step 3\", terminate_with_success=True)\n\n    step_1.on_failure = step_3.name\n\n    pipeline = Pipeline(\n        steps=[step_1, step_2, step_3],\n        add_terminal_nodes=True,\n    )\n    pipeline.execute()\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>stateDiagram-v2\n    state \"Start at step 1\" as start_at\n    state \"step 2\" as step_2\n    state \"step 3\" as step_3\n    state \"Success\" as success\n\n\n    [*] --&gt; start_at\n    start_at --&gt; step_2 : #10060;\n    start_at --&gt; step_3 : #9989;\n    step_3 --&gt; success : #9989;\n    success --&gt; [*]</code></pre> <p></p>"},{"location":"concepts/pipeline/#terminating","title":"Terminating","text":"<ul> <li> All pipelines should have one and only one Success and Fail state</li> </ul> <p>Reaching one of these states as part of traversal indicates the status of the pipeline.</p> yamlpython <p>The type determines the node to be a <code>success</code> or <code>fail</code> state.</p> <p>The name can be anything that you prefer.</p> <pre><code>success:\n  type: success\nfail:\n  type: fail\n</code></pre> <p>Setting <code>add_terminal_nodes</code> to be <code>true</code> during pipeline creation adds <code>success</code> and <code>fail</code> states with the names success and fail.</p> <pre><code>if __name__ == \"__main__\":\n    main()\n</code></pre> <p>Individual steps can link</p> <ul> <li>success state by setting <code>terminate_with_success</code> to <code>True</code></li> <li>fail state by setting <code>terminate_with_fail</code> to <code>True</code></li> </ul> <p>You can, alternatively, create a <code>success</code> and <code>fail</code> state and link them together.</p> <pre><code>from runnable import Success, Fail\n\nsuccess = Success(name=\"Custom Success\")\nfail = Fail(name=\"Custom Failure\")\n</code></pre>"},{"location":"concepts/run-log/","title":"Run Log","text":"<p>Internally, runnable uses a <code>run log</code> to keep track of the execution of the pipeline. It also stores the parameters, experiment tracking metrics and reproducibility information captured during the execution.</p> <p>It should not be confused with application logs generated during the execution of a <code>task</code> i.e the stdout and stderr when running the <code>command</code> of a task.</p>"},{"location":"concepts/run-log/#example","title":"Example","text":"pipelineRun log <p>This is the same example described in tasks.</p> <p>tl;dr a pipeline that consumes some initial parameters and passes them to the next step. Both the steps are <code>shell</code> based tasks.</p> <pre><code>dag:\n  description: |\n    This is a sample pipeline to show the parameter flow for shell types.\n\n    The step \"access initial\" just displays the initial parameters defined in examples/concepts/parameters.yaml\n    The step modify_initial updates the parameters and sets them back as environment variables.\n    The step display_again displays the updated parameters from modify_initial and updates them.\n\n    You can run this pipeline as:\n      runnable execute -f examples/concepts/task_shell_parameters.yaml  -p examples/concepts/parameters.yaml\n\n  start_at: access initial\n  steps:\n    access initial:\n      type: task\n      command_type: shell\n      command: |\n        env\n      next: modify initial\n    modify initial:\n      type: task\n      command_type: shell\n      returns:\n        - name: spam\n          kind: json\n        - name: eggs\n          kind: json\n      command: |\n        export spam='World'\n        export eggs='{\"ham\": \"No, Thank you!!\"}'\n      next: display again\n    display again:\n      type: task\n      command_type: shell\n      returns:\n        - name: spam\n          kind: json\n        - name: eggs\n          kind: json\n\n      command: |\n        env &amp;&amp; \\\n        export spam='Universe' &amp;&amp; \\\n        export eggs='{\"ham\": \"Maybe, one more..\"}'\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <pre><code>{\n  \"run_id\": \"devout-jones-0640\",\n  \"dag_hash\": \"9070f0b9c661d4ff7a23647cbe0ed2d461b9a26e\",\n  \"use_cached\": false,\n  \"tag\": \"\",\n  \"original_run_id\": \"\",\n  \"status\": \"SUCCESS\",\n  \"steps\": {\n      \"access initial\": {\n          \"name\": \"access initial\",\n          \"internal_name\": \"access initial\",\n          \"status\": \"SUCCESS\",\n          \"step_type\": \"task\",\n          \"message\": \"\",\n          \"mock\": false,\n          \"code_identities\": [\n              {\n                  \"code_identifier\": \"ca4c5fbff4148d3862a4738942d4607a9c4f0d88\",\n                  \"code_identifier_type\": \"git\",\n                  \"code_identifier_dependable\": true,\n                  \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                  \"code_identifier_message\": \"\"\n              }\n          ],\n          \"attempts\": [\n              {\n                  \"attempt_number\": 1,\n                  \"start_time\": \"2023-12-30 06:40:55.188207\",\n                  \"end_time\": \"2023-12-30 06:40:55.202317\",\n                  \"duration\": \"0:00:00.014110\",\n                  \"status\": \"SUCCESS\",\n                  \"message\": \"\",\n                  \"parameters\": {\n                      \"spam\": \"Hello\",\n                      \"eggs\": {\n                          \"ham\": \"Yes, please!!\"\n                      }\n                  }\n              }\n          ],\n          \"user_defined_metrics\": {},\n          \"branches\": {},\n          \"data_catalog\": [\n              {\n                  \"name\": \"access_initial.execution.log\",\n                  \"data_hash\": \"8a18b647052b3c85020beb2024f2a25289fe955b1421026008521b12cff4f44c\",\n                  \"catalog_relative_path\": \"devout-jones-0640/access_initial.execution.log\",\n                  \"catalog_handler_location\": \".catalog\",\n                  \"stage\": \"put\"\n              }\n          ]\n      },\n      \"modify initial\": {\n          \"name\": \"modify initial\",\n          \"internal_name\": \"modify initial\",\n          \"status\": \"SUCCESS\",\n          \"step_type\": \"task\",\n          \"message\": \"\",\n          \"mock\": false,\n          \"code_identities\": [\n              {\n                  \"code_identifier\": \"ca4c5fbff4148d3862a4738942d4607a9c4f0d88\",\n                  \"code_identifier_type\": \"git\",\n                  \"code_identifier_dependable\": true,\n                  \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                  \"code_identifier_message\": \"\"\n              }\n          ],\n          \"attempts\": [\n              {\n                  \"attempt_number\": 1,\n                  \"start_time\": \"2023-12-30 06:40:55.266858\",\n                  \"end_time\": \"2023-12-30 06:40:55.281405\",\n                  \"duration\": \"0:00:00.014547\",\n                  \"status\": \"SUCCESS\",\n                  \"message\": \"\",\n                  \"parameters\": {\n                      \"spam\": \"Hello\",\n                      \"eggs\": {\n                          \"ham\": \"Yes, please!!\"\n                      }\n                  }\n              }\n          ],\n          \"user_defined_metrics\": {},\n          \"branches\": {},\n          \"data_catalog\": [\n              {\n                  \"name\": \"modify_initial.execution.log\",\n                  \"data_hash\": \"9dea22c132992504146374f6ac7cfe2f5510da78ca3bb5cc576abcfde0a4da3c\",\n                  \"catalog_relative_path\": \"devout-jones-0640/modify_initial.execution.log\",\n                  \"catalog_handler_location\": \".catalog\",\n                  \"stage\": \"put\"\n              }\n          ]\n      },\n      \"display again\": {\n          \"name\": \"display again\",\n          \"internal_name\": \"display again\",\n          \"status\": \"SUCCESS\",\n          \"step_type\": \"task\",\n          \"message\": \"\",\n          \"mock\": false,\n          \"code_identities\": [\n              {\n                  \"code_identifier\": \"ca4c5fbff4148d3862a4738942d4607a9c4f0d88\",\n                  \"code_identifier_type\": \"git\",\n                  \"code_identifier_dependable\": true,\n                  \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                  \"code_identifier_message\": \"\"\n              }\n          ],\n          \"attempts\": [\n              {\n                  \"attempt_number\": 1,\n                  \"start_time\": \"2023-12-30 06:40:55.354662\",\n                  \"end_time\": \"2023-12-30 06:40:55.366113\",\n                  \"duration\": \"0:00:00.011451\",\n                  \"status\": \"SUCCESS\",\n                  \"message\": \"\",\n                  \"parameters\": {\n                      \"spam\": \"World\",\n                      \"eggs\": {\n                          \"ham\": \"No, Thank you!!\"\n                      }\n                  }\n              }\n          ],\n          \"user_defined_metrics\": {},\n          \"branches\": {},\n          \"data_catalog\": [\n              {\n                  \"name\": \"display_again.execution.log\",\n                  \"data_hash\": \"9126727342ebef3d3635db294708ad96b49092bf3680da8f38490ea84844c8d4\",\n                  \"catalog_relative_path\": \"devout-jones-0640/display_again.execution.log\",\n                  \"catalog_handler_location\": \".catalog\",\n                  \"stage\": \"put\"\n              }\n          ]\n      },\n      \"success\": {\n          \"name\": \"success\",\n          \"internal_name\": \"success\",\n          \"status\": \"SUCCESS\",\n          \"step_type\": \"success\",\n          \"message\": \"\",\n          \"mock\": false,\n          \"code_identities\": [\n              {\n                  \"code_identifier\": \"ca4c5fbff4148d3862a4738942d4607a9c4f0d88\",\n                  \"code_identifier_type\": \"git\",\n                  \"code_identifier_dependable\": true,\n                  \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                  \"code_identifier_message\": \"\"\n              }\n          ],\n          \"attempts\": [\n              {\n                  \"attempt_number\": 1,\n                  \"start_time\": \"2023-12-30 06:40:55.431271\",\n                  \"end_time\": \"2023-12-30 06:40:55.431327\",\n                  \"duration\": \"0:00:00.000056\",\n                  \"status\": \"SUCCESS\",\n                  \"message\": \"\",\n                  \"parameters\": {\n                      \"spam\": \"Universe\",\n                      \"eggs\": {\n                          \"ham\": \"Maybe, one more..\"\n                      }\n                  }\n              }\n          ],\n          \"user_defined_metrics\": {},\n          \"branches\": {},\n          \"data_catalog\": []\n      }\n  },\n  \"parameters\": {\n      \"spam\": \"Universe\",\n      \"eggs\": {\n          \"ham\": \"Maybe, one more..\"\n      }\n  },\n  \"run_config\": {\n      \"executor\": {\n          \"service_name\": \"local\",\n          \"service_type\": \"executor\",\n          \"enable_parallel\": false,\n          \"placeholders\": {}\n      },\n      \"run_log_store\": {\n          \"service_name\": \"buffered\",\n          \"service_type\": \"run_log_store\"\n      },\n      \"secrets_handler\": {\n          \"service_name\": \"do-nothing\",\n          \"service_type\": \"secrets\"\n      },\n      \"catalog_handler\": {\n          \"service_name\": \"file-system\",\n          \"service_type\": \"catalog\",\n          \"compute_data_folder\": \"data\"\n      },\n      \"experiment_tracker\": {\n          \"service_name\": \"do-nothing\",\n          \"service_type\": \"experiment_tracker\"\n      },\n      \"pipeline_file\": \"examples/concepts/task_shell_parameters.yaml\",\n      \"parameters_file\": \"examples/concepts/parameters.yaml\",\n      \"configuration_file\": null,\n      \"tag\": \"\",\n      \"run_id\": \"devout-jones-0640\",\n      \"variables\": {},\n      \"use_cached\": false,\n      \"original_run_id\": \"\",\n      \"dag\": {\n          \"start_at\": \"access initial\",\n          \"name\": \"\",\n          \"description\": \"This is a sample pipeline to show the parameter flow for shell\n          types.\\n\\nThe step \\\"access initial\\\" just displays the initial parameters\n          defined in examples/concepts/parameters.yaml\\nThe step modify_initial updates\n          the parameters and sets them back as environment variables.\\nThe step\n          display_again displays the updated parameters from modify_initial and updates\n          them.\\n\\n\n          You can run this pipeline as:\\n  runnable execute -f\n          examples/concepts/task_shell_parameters.yaml  -p examples/concepts/parameters.\n          yaml\\n\",\n          \"internal_branch_name\": \"\",\n          \"steps\": {\n              \"access initial\": {\n                  \"type\": \"task\",\n                  \"name\": \"access initial\",\n                  \"internal_name\": \"access initial\",\n                  \"internal_branch_name\": \"\",\n                  \"is_composite\": false\n              },\n              \"modify initial\": {\n                  \"type\": \"task\",\n                  \"name\": \"modify initial\",\n                  \"internal_name\": \"modify initial\",\n                  \"internal_branch_name\": \"\",\n                  \"is_composite\": false\n              },\n              \"display again\": {\n                  \"type\": \"task\",\n                  \"name\": \"display again\",\n                  \"internal_name\": \"display again\",\n                  \"internal_branch_name\": \"\",\n                  \"is_composite\": false\n              },\n              \"success\": {\n                  \"type\": \"success\",\n                  \"name\": \"success\",\n                  \"internal_name\": \"success\",\n                  \"internal_branch_name\": \"\",\n                  \"is_composite\": false\n              },\n              \"fail\": {\n                  \"type\": \"fail\",\n                  \"name\": \"fail\",\n                  \"internal_name\": \"fail\",\n                  \"internal_branch_name\": \"\",\n                  \"is_composite\": false\n              }\n          }\n      },\n      \"dag_hash\": \"9070f0b9c661d4ff7a23647cbe0ed2d461b9a26e\",\n      \"execution_plan\": \"chained\"\n  }\n}\n</code></pre> <p>In the above example of <code>run log</code> tab,</p> <ul> <li><code>run_id</code>: Defined in line #2, is a a unique id generated for every execution of the pipeline.</li> <li><code>use_cached</code>: in line #4, is the execution id of an older run that is being restarted in the current execution.</li> <li><code>tag</code>: A user defined label to be attached to an execution of the pipeline to contextually group executions. This label can also be used to group experiments of experiment tracking tools like mlflow.</li> <li><code>status</code>: In line #7, defines the global status of the execution. <code>SUCCESS</code>, <code>PROCESSING</code> or <code>FAILED</code> are the three possible states.</li> <li><code>run_config</code>: From line #184 to end, capture the configuration used during the execution. It details the configuration of different services (executor, catalog, secrets handler etc) and also the pipeline definition. This is the internal representation of the execution.</li> </ul> <p>Tip</p> <p>The system generated <code>run_id</code> is always appended with the time of execution. Use this to distinguish between execution id's during rapid experimentation.</p> <p>In the above example, the <code>run_id</code>, \"affable-babbage-0545\" is executed at 05:45.</p>"},{"location":"concepts/run-log/#parameters","title":"parameters","text":"<p>The final state of parameters are captured at the run log level while individual step logs show the parameters at the point of execution of the task.</p> <p>In the above example, lines 178-183 show the final parameters at the end of execution.</p>"},{"location":"concepts/run-log/#step_log","title":"Step Log","text":"<p>The step log captures the information about the execution of the steps. It is mapping indexed by the name of the step in the pipeline and is ordered chronologically by the start time of the execution of the step.</p>"},{"location":"concepts/run-log/#example_1","title":"Example","text":"<p>A snippet from the above example:</p> <pre><code>\"steps\": {\n  \"access initial\": {\n      \"name\": \"access initial\",\n      \"internal_name\": \"access initial\",\n      \"status\": \"SUCCESS\",\n      \"step_type\": \"task\",\n      \"message\": \"\",\n      \"mock\": false,\n      \"code_identities\": [\n          {\n              \"code_identifier\": \"ca4c5fbff4148d3862a4738942d4607a9c4f0d88\",\n              \"code_identifier_type\": \"git\",\n              \"code_identifier_dependable\": true,\n              \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n              \"code_identifier_message\": \"\"\n          }\n      ],\n      \"attempts\": [\n          {\n              \"attempt_number\": 1,\n              \"start_time\": \"2023-12-30 06:40:55.188207\",\n              \"end_time\": \"2023-12-30 06:40:55.202317\",\n              \"duration\": \"0:00:00.014110\",\n              \"status\": \"SUCCESS\",\n              \"message\": \"\",\n              \"parameters\": {\n                  \"spam\": \"Hello\",\n                  \"eggs\": {\n                      \"ham\": \"Yes, please!!\"\n                  }\n              }\n          }\n      ],\n      \"user_defined_metrics\": {},\n      \"branches\": {},\n      \"data_catalog\": [\n          {\n              \"name\": \"access_initial.execution.log\",\n              \"data_hash\": \"8a18b647052b3c85020beb2024f2a25289fe955b1421026008521b12cff4f44c\",\n              \"catalog_relative_path\": \"devout-jones-0640/access_initial.execution.log\",\n              \"catalog_handler_location\": \".catalog\",\n              \"stage\": \"put\"\n          }\n      ]\n  },\n  ...\n</code></pre> <ul> <li> <p>For non-nested steps, the key is the name of the step. For example, the first entry in the steps mapping is \"access initial\" which corresponds to the name of the task in the pipeline. For nested steps, the step log is also nested and shown in more detail for   parallel, map.</p> </li> <li> <p><code>status</code>: In line #5 is the status of the step with three possible states, <code>SUCCESS</code>, <code>PROCESSING</code> or <code>FAILED</code></p> </li> <li><code>step_type</code>: In line #6, is the type of step, in this case is a <code>task</code>.</li> <li><code>message</code>: in line #7, is a short description of the error if the step failed. This might not always be useful as a step can fail for many complicate reasons.</li> <li> <p><code>code_identities</code>: We capture the unique identifier of the state of the code for reproducibility purposes.</p> <ul> <li>The <code>code_identifier</code> is the git sha of the code.</li> <li><code>code_identifier_dependable</code> indicates if the current branch is clean. Unclean branches makes it hard to determine the exact state of the code.</li> <li><code>code_identifier_message</code>: Captures the names of the files which have uncommitted changes.</li> </ul> </li> </ul> <p>It is easy to extend and customize the metrics being captured here. For example, executors like <code>local-container</code>   or <code>argo</code> can add the docker container identities as part of the log.</p> <ul> <li><code>attempts</code>: In line #19-34, Is the ordered list of attempts to execute the step. It shows the start time, end time, duration of the execution and the parameters at the time of execution of the step.</li> </ul> <p>For example, at the time of executing the step <code>access initial</code>, the parameters are the   <pre><code>\"spam\": \"Hello\",\n\"eggs\": {\n    \"ham\": \"Yes, please!!\"\n}\n</code></pre>   while for the step, <code>display again</code> shows the modified parameters:   <pre><code>\"spam\": \"World\",\n\"eggs\": {\n    \"ham\": \"No, Thank you!!\"\n}\n</code></pre></p> <ul> <li> <p><code>user_defined_metrics</code>: are any experiment tracking metrics captured during the execution of the step.</p> </li> <li> <p><code>branches</code>: This only applies to parallel, map or dag steps and shows the logs captured during the execution of the branch.</p> </li> <li><code>data_catalog</code>: Captures any data flowing through the tasks by the catalog. By default, the execution logs of the task are put in the catalog for easier debugging purposes.</li> </ul> <p>For example,  the below lines from the snippet specifies one entry into the catalog which is the execution log of the task <code>access initial</code> and also the hash of the data.</p> <pre><code>\"data_catalog\": [\n    {\n        \"name\": \"access_initial.execution.log\",\n        \"data_hash\": \"8a18b647052b3c85020beb2024f2a25289fe955b1421026008521b12cff4f44c\",\n        \"catalog_relative_path\": \"devout-jones-0640/access_initial.execution.log\",\n        \"catalog_handler_location\": \".catalog\",\n        \"stage\": \"put\"\n    }\n]\n</code></pre>"},{"location":"concepts/run-log/#retrying_failures","title":"Retrying failures","text":"<p>The structure of the run log remains the same independent of the <code>executor</code> used to execute. This enables to debug failures during the execution in complex environments to be easily reproduced in local environments and fixed.</p> <p>Shortcomings</p> <p>Currently, the support is only available for</p> <ul> <li>non-nested, linear pipelines</li> <li>non-chunked run log store</li> </ul> <p>mocked executor provides better support in debugging failures.</p>"},{"location":"concepts/run-log/#example_2","title":"Example","text":"Argo configurationFaulty pipelineRun log in ArgoFixed pipeline in local environmentRun log in localDiff <p>The configuration file is assumed to be located at: <code>examples/configs/argo-config-catalog.yaml</code></p> <pre><code>executor:\n  type: \"argo\" # (1)\n  config:\n    image: $argo_docker_image # (2)\n    service_account_name: default-editor\n    persistent_volumes: # (3)\n      - name: runnable-volume\n        mount_path: /mnt\n\nrun_log_store: # (4)\n  type: file-system\n  config:\n    log_folder: /mnt/run_log_store\n\ncatalog:\n  type: file-system\n  config:\n    catalog_location: /mnt/catalog\n\nsecrets:\n  type: do-nothing\n\nexperiment_tracker:\n  type: do-nothing\n</code></pre> <p>To run the pipeline in argo, change the configuration file from <code>examples/configs/fs-catalog-run_log.yaml</code> to <code>examples/configs/argo-config-catalog.yaml</code></p> <pre><code>dag:\n  description: |\n    This is a simple pipeline that demonstrates retrying failures.\n\n    1. Setup: We setup a data folder, we ignore if it is already present\n    2. Create Content: We create a \"hello.txt\" and \"put\" the file in catalog\n    3. Retrieve Content: We \"get\" the file \"hello.txt\" from the catalog and show the contents\n    5. Cleanup: We remove the data folder. Note that this is stubbed to prevent accidental deletion.\n\n\n    You can run this pipeline by:\n       runnable execute -f examples/retry-fail.yaml -c examples/configs/fs-catalog-run_log.yaml \\\n        --run-id wrong-file-name\n  start_at: Setup\n  steps:\n    Setup:\n      type: task\n      command_type: shell\n      command: mkdir -p data # (1)\n      next: Create Content\n    Create Content:\n      type: task\n      command_type: shell\n      command: |\n        echo \"Hello from runnable\" &gt;&gt; data/hello.txt\n      next: Retrieve Content\n      catalog: # (2)\n        put:\n          - data/hello.txt\n    Retrieve Content:\n      type: task\n      command_type: shell\n      command: cat data/hello1.txt # (3)\n      catalog:\n        get:\n          - \"data/hello.txt\" # You can use wild cards following glob pattern\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <pre><code>{\n    \"run_id\": \"toFail\",\n    \"dag_hash\": \"13f7c1b29ebb07ce058305253171ceae504e1683\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"PROCESSING\",\n    \"steps\": {\n        \"Setup\": {\n            \"name\": \"Setup\",\n            \"internal_name\": \"Setup\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-05 22:11:47.213714\",\n                    \"end_time\": \"2024-02-05 22:11:47.290352\",\n                    \"duration\": \"0:00:00.076638\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"Setup.execution.log\",\n                    \"data_hash\": \"b709b710424701bd86be1cca36c5ec18f412b6dbb8d4e7729ec10e44319adbaf\",\n                    \"catalog_relative_path\": \"toFail/Setup.execution.log\",\n                    \"catalog_handler_location\": \"/mnt/catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"Create Content\": {\n            \"name\": \"Create Content\",\n            \"internal_name\": \"Create Content\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-05 22:12:14.210011\",\n                    \"end_time\": \"2024-02-05 22:12:14.225645\",\n                    \"duration\": \"0:00:00.015634\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"Create_Content.execution.log\",\n                    \"data_hash\": \"618e515729e00c7811865306b41e91d698c00577078e75b2e4bcf87ec9669d62\",\n                    \"catalog_relative_path\": \"toFail/Create_Content.execution.log\",\n                    \"catalog_handler_location\": \"/mnt/catalog\",\n                    \"stage\": \"put\"\n                },\n                {\n                    \"name\": \"data/hello.txt\",\n                    \"data_hash\": \"949a4f1afcea77b4b3f483ebe993e733122fb87b7539a3fc3d6752030be6ad44\",\n                    \"catalog_relative_path\": \"toFail/data/hello.txt\",\n                    \"catalog_handler_location\": \"/mnt/catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"Retrieve Content\": {\n            \"name\": \"Retrieve Content\",\n            \"internal_name\": \"Retrieve Content\",\n            \"status\": \"FAIL\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-05 22:12:36.514484\",\n                    \"end_time\": \"2024-02-05 22:12:36.985694\",\n                    \"duration\": \"0:00:00.471210\",\n                    \"status\": \"FAIL\",\n                    \"message\": \"Command failed\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"data/hello.txt\",\n                    \"data_hash\": \"949a4f1afcea77b4b3f483ebe993e733122fb87b7539a3fc3d6752030be6ad44\",\n                    \"catalog_relative_path\": \"data/hello.txt\",\n                    \"catalog_handler_location\": \"/mnt/catalog\",\n                    \"stage\": \"get\"\n                },\n                {\n                    \"name\": \"Retrieve_Content.execution.log\",\n                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                    \"catalog_relative_path\": \"toFail/Retrieve_Content.execution.log\",\n                    \"catalog_handler_location\": \"/mnt/catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"argo\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"overrides\": {},\n            \"image\": \"$argo_docker_image\",\n            \"expose_parameters_as_inputs\": true,\n            \"secrets_from_k8s\": [],\n            \"output_file\": \"argo-pipeline.yaml\",\n            \"name\": \"runnable-dag-\",\n            \"annotations\": {},\n            \"labels\": {},\n            \"activeDeadlineSeconds\": 172800,\n            \"nodeSelector\": null,\n            \"parallelism\": null,\n            \"retryStrategy\": {\n                \"limit\": \"0\",\n                \"retryPolicy\": \"Always\",\n                \"backoff\": {\n                    \"duration\": \"120\",\n                    \"factor\": 2,\n                    \"maxDuration\": \"3600\"\n                }\n            },\n            \"max_step_duration_in_seconds\": 7200,\n            \"tolerations\": null,\n            \"image_pull_policy\": \"\",\n            \"service_account_name\": \"default-editor\",\n            \"persistent_volumes\": [\n                {\n                    \"name\": \"runnable-volume\",\n                    \"mount_path\": \"/mnt\"\n                }\n            ],\n            \"step_timeout\": 14400\n        },\n        \"run_log_store\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"run_log_store\",\n            \"log_folder\": \"/mnt/run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\",\n            \"catalog_location\": \"/mnt/catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"examples/retry-fail.yaml\",\n        \"parameters_file\": null,\n        \"configuration_file\": \"examples/configs/argo-config-catalog.yaml\",\n        \"tag\": \"\",\n        \"run_id\": \"toFail\",\n        \"variables\": {},\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"Setup\",\n            \"name\": \"\",\n            \"description\": \"This is a simple pipeline that demonstrates retrying failures.\\n\\n1. Setup: We setup a data folder, we ignore if it is already present\\n2. Create Content: We create a \\\"hello.txt\\\" and \\\"put\\\" the file in catalog\\n3. Retrieve Content: We \\\"get\\\" the file \\\"hello.txt\\\" from the catalog and show the contents\\n5. Cleanup: We remove the data folder. Note that this is stubbed to prevent accidental deletion.\\n\\n\\nYou can run this pipeline by:\\n   runnable execute -f examples/catalog.yaml -c examples/configs/fs-catalog.yaml\\n\",\n            \"steps\": {\n                \"Setup\": {\n                    \"type\": \"task\",\n                    \"name\": \"Setup\",\n                    \"next\": \"Create Content\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"mkdir -p data\",\n                    \"node_name\": \"Setup\"\n                },\n                \"Create Content\": {\n                    \"type\": \"task\",\n                    \"name\": \"Create Content\",\n                    \"next\": \"Retrieve Content\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": {\n                        \"get\": [],\n                        \"put\": [\n                            \"data/hello.txt\"\n                        ]\n                    },\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"echo \\\"Hello from runnable\\\" &gt;&gt; data/hello.txt\\n\",\n                    \"node_name\": \"Create Content\"\n                },\n                \"Retrieve Content\": {\n                    \"type\": \"task\",\n                    \"name\": \"Retrieve Content\",\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": {\n                        \"get\": [\n                            \"data/hello.txt\"\n                        ],\n                        \"put\": []\n                    },\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"cat data/hello1.txt\",\n                    \"node_name\": \"Retrieve Content\"\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"13f7c1b29ebb07ce058305253171ceae504e1683\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre> <p>Bring the run log from K8's volumes to local machine for a retry.</p> <pre><code>dag:\n  description: |\n    This is a simple pipeline that demonstrates passing data between steps.\n\n    1. Setup: We setup a data folder, we ignore if it is already present\n    2. Create Content: We create a \"hello.txt\" and \"put\" the file in catalog\n    3. Clean up to get again: We remove the data folder. Note that this is stubbed to prevent\n      accidental deletion of your contents. You can change type to task to make really run.\n    4. Retrieve Content: We \"get\" the file \"hello.txt\" from the catalog and show the contents\n    5. Cleanup: We remove the data folder. Note that this is stubbed to prevent accidental deletion.\n\n\n    You can run this pipeline by:\n       runnable execute -f examples/retry-fixed.yaml -c examples/configs/fs-catalog-run_log.yaml \\\n       --use-cached wrong-file-name\n\n  start_at: Setup\n  steps:\n    Setup:\n      type: task # (1)\n      command_type: shell\n      command: mkdir -p data\n      next: Create Content\n    Create Content:\n      type: stub # (2)\n      command_type: shell\n      command: |\n        echo \"Hello from runnable\" &gt;&gt; data/hello.txt\n      next: Retrieve Content\n      catalog:\n        put:\n          - data/hello.txt\n    Retrieve Content:\n      type: task\n      command_type: shell\n      command: cat data/hello.txt\n      catalog:\n        get:\n          - \"data/hello.txt\" # You can use wild cards following glob pattern\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <pre><code>{\n    \"run_id\": \"polynomial-bartik-2226\",\n    \"dag_hash\": \"2beec08fd417134cd3b04599d6684469db4ad176\",\n    \"use_cached\": true,\n    \"tag\": \"\",\n    \"original_run_id\": \"toFail\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {\n        \"Setup\": {\n            \"name\": \"Setup\",\n            \"internal_name\": \"Setup\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": true,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"Create Content\": {\n            \"name\": \"Create Content\",\n            \"internal_name\": \"Create Content\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": true,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"Retrieve Content\": {\n            \"name\": \"Retrieve Content\",\n            \"internal_name\": \"Retrieve Content\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-05 22:26:05.366143\",\n                    \"end_time\": \"2024-02-05 22:26:05.383790\",\n                    \"duration\": \"0:00:00.017647\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"data/hello.txt\",\n                    \"data_hash\": \"14e0a818c551fd963f9496f5b9e780f741e3ee020456c7d8b761b902fbfa4cb4\",\n                    \"catalog_relative_path\": \"data/hello.txt\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"get\"\n                },\n                {\n                    \"name\": \"Retrieve_Content.execution.log\",\n                    \"data_hash\": \"f7911c18bf8be5131e6f61eecbeaf607758b9bf38a84b237e2aad7497ff46211\",\n                    \"catalog_relative_path\": \"polynomial-bartik-2226/Retrieve_Content.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-05 22:26:05.465249\",\n                    \"end_time\": \"2024-02-05 22:26:05.466008\",\n                    \"duration\": \"0:00:00.000759\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"overrides\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"run_log_store\",\n            \"log_folder\": \".run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\",\n            \"catalog_location\": \".catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"examples/retry-fixed.yaml\",\n        \"parameters_file\": null,\n        \"configuration_file\": \"examples/configs/fs-catalog-run_log.yaml\",\n        \"tag\": \"\",\n        \"run_id\": \"polynomial-bartik-2226\",\n        \"variables\": {\n            \"argo_docker_image\": \"harbor.csis.astrazeneca.net/mlops/runnable:latest\"\n        },\n        \"use_cached\": true,\n        \"original_run_id\": \"toFail\",\n        \"dag\": {\n            \"start_at\": \"Setup\",\n            \"name\": \"\",\n            \"description\": \"This is a simple pipeline that demonstrates passing data between steps.\\n\\n1. Setup: We setup a data folder, we ignore if it is already\npresent\\n2. Create Content: We create a \\\"hello.txt\\\" and \\\"put\\\" the file in catalog\\n3. Clean up to get again: We remove the data folder. Note that this is stubbed\nto prevent\\n  accidental deletion of your contents. You can change type to task to make really run.\\n4. Retrieve Content: We \\\"get\\\" the file \\\"hello.txt\\\" from the\ncatalog and show the contents\\n5. Cleanup: We remove the data folder. Note that this is stubbed to prevent accidental deletion.\\n\\n\\nYou can run this pipeline by:\\n\nrunnable execute -f examples/catalog.yaml -c examples/configs/fs-catalog.yaml\\n\",\n            \"steps\": {\n                \"Setup\": {\n                    \"type\": \"task\",\n                    \"name\": \"Setup\",\n                    \"next\": \"Create Content\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"mkdir -p data\",\n                    \"node_name\": \"Setup\"\n                },\n                \"Create Content\": {\n                    \"type\": \"task\",\n                    \"name\": \"Create Content\",\n                    \"next\": \"Retrieve Content\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": {\n                        \"get\": [],\n                        \"put\": [\n                            \"data/hello.txt\"\n                        ]\n                    },\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"echo \\\"Hello from runnable\\\" &gt;&gt; data/hello.txt\\n\",\n                    \"node_name\": \"Create Content\"\n                },\n                \"Retrieve Content\": {\n                    \"type\": \"task\",\n                    \"name\": \"Retrieve Content\",\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": {\n                        \"get\": [\n                            \"data/hello.txt\"\n                        ],\n                        \"put\": []\n                    },\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"cat data/hello.txt\",\n                    \"node_name\": \"Retrieve Content\"\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"2beec08fd417134cd3b04599d6684469db4ad176\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre> <pre><code>diff .run_log_store/toFail.json .run_log_store/polynomial-bartik-2226.json\n2,4c2,4\n&lt;     \"run_id\": \"toFail\",\n&lt;     \"dag_hash\": \"13f7c1b29ebb07ce058305253171ceae504e1683\",\n&lt;     \"use_cached\": false,\n---\n&gt;     \"run_id\": \"polynomial-bartik-2226\",\n&gt;     \"dag_hash\": \"2beec08fd417134cd3b04599d6684469db4ad176\",\n&gt;     \"use_cached\": true,\n6,7c6,7\n&lt;     \"original_run_id\": \"\",\n&lt;     \"status\": \"PROCESSING\",\n---\n&gt;     \"original_run_id\": \"toFail\",\n&gt;     \"status\": \"SUCCESS\",\n15c15\n&lt;             \"mock\": false,\n---\n&gt;             \"mock\": true,\n25,35c25\n&lt;             \"attempts\": [\n&lt;                 {\n&lt;                     \"attempt_number\": 1,\n&lt;                     \"start_time\": \"2024-02-05 22:11:47.213714\",\n&lt;                     \"end_time\": \"2024-02-05 22:11:47.290352\",\n&lt;                     \"duration\": \"0:00:00.076638\",\n&lt;                     \"status\": \"SUCCESS\",\n&lt;                     \"message\": \"\",\n&lt;                     \"parameters\": {}\n&lt;                 }\n&lt;             ],\n---\n&gt;             \"attempts\": [],\n38,46c28\n&lt;             \"data_catalog\": [\n&lt;                 {\n&lt;                     \"name\": \"Setup.execution.log\",\n&lt;                     \"data_hash\": \"b709b710424701bd86be1cca36c5ec18f412b6dbb8d4e7729ec10e44319adbaf\",\n&lt;                     \"catalog_relative_path\": \"toFail/Setup.execution.log\",\n&lt;                     \"catalog_handler_location\": \"/mnt/catalog\",\n&lt;                     \"stage\": \"put\"\n&lt;                 }\n&lt;             ]\n---\n&gt;             \"data_catalog\": []\n53a36,56\n&gt;             \"mock\": true,\n&gt;             \"code_identities\": [\n&gt;                 {\n&gt;                     \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n&gt;                     \"code_identifier_type\": \"git\",\n&gt;                     \"code_identifier_dependable\": true,\n&gt;                     \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n&gt;                     \"code_identifier_message\": \"\"\n&gt;                 }\n&gt;             ],\n&gt;             \"attempts\": [],\n&gt;             \"user_defined_metrics\": {},\n&gt;             \"branches\": {},\n&gt;             \"data_catalog\": []\n&gt;         },\n&gt;         \"Retrieve Content\": {\n&gt;             \"name\": \"Retrieve Content\",\n&gt;             \"internal_name\": \"Retrieve Content\",\n&gt;             \"status\": \"SUCCESS\",\n&gt;             \"step_type\": \"task\",\n&gt;             \"message\": \"\",\n67,69c70,72\n&lt;                     \"start_time\": \"2024-02-05 22:12:14.210011\",\n&lt;                     \"end_time\": \"2024-02-05 22:12:14.225645\",\n&lt;                     \"duration\": \"0:00:00.015634\",\n---\n&gt;                     \"start_time\": \"2024-02-05 22:26:05.366143\",\n&gt;                     \"end_time\": \"2024-02-05 22:26:05.383790\",\n&gt;                     \"duration\": \"0:00:00.017647\",\n79,83c82,86\n&lt;                     \"name\": \"Create_Content.execution.log\",\n&lt;                     \"data_hash\": \"618e515729e00c7811865306b41e91d698c00577078e75b2e4bcf87ec9669d62\",\n&lt;                     \"catalog_relative_path\": \"toFail/Create_Content.execution.log\",\n&lt;                     \"catalog_handler_location\": \"/mnt/catalog\",\n&lt;                     \"stage\": \"put\"\n---\n&gt;                     \"name\": \"data/hello.txt\",\n&gt;                     \"data_hash\": \"14e0a818c551fd963f9496f5b9e780f741e3ee020456c7d8b761b902fbfa4cb4\",\n&gt;                     \"catalog_relative_path\": \"data/hello.txt\",\n&gt;                     \"catalog_handler_location\": \".catalog\",\n&gt;                     \"stage\": \"get\"\n86,89c89,92\n&lt;                     \"name\": \"data/hello.txt\",\n&lt;                     \"data_hash\": \"949a4f1afcea77b4b3f483ebe993e733122fb87b7539a3fc3d6752030be6ad44\",\n&lt;                     \"catalog_relative_path\": \"toFail/data/hello.txt\",\n&lt;                     \"catalog_handler_location\": \"/mnt/catalog\",\n---\n&gt;                     \"name\": \"Retrieve_Content.execution.log\",\n&gt;                     \"data_hash\": \"f7911c18bf8be5131e6f61eecbeaf607758b9bf38a84b237e2aad7497ff46211\",\n&gt;                     \"catalog_relative_path\": \"polynomial-bartik-2226/Retrieve_Content.execution.log\",\n&gt;                     \"catalog_handler_location\": \".catalog\",\n94,98c97,101\n&lt;         \"Retrieve Content\": {\n&lt;             \"name\": \"Retrieve Content\",\n&lt;             \"internal_name\": \"Retrieve Content\",\n&lt;             \"status\": \"FAIL\",\n&lt;             \"step_type\": \"task\",\n---\n&gt;         \"success\": {\n&gt;             \"name\": \"success\",\n&gt;             \"internal_name\": \"success\",\n&gt;             \"status\": \"SUCCESS\",\n&gt;             \"step_type\": \"success\",\n113,117c116,120\n&lt;                     \"start_time\": \"2024-02-05 22:12:36.514484\",\n&lt;                     \"end_time\": \"2024-02-05 22:12:36.985694\",\n&lt;                     \"duration\": \"0:00:00.471210\",\n&lt;                     \"status\": \"FAIL\",\n&lt;                     \"message\": \"Command failed\",\n---\n&gt;                     \"start_time\": \"2024-02-05 22:26:05.465249\",\n&gt;                     \"end_time\": \"2024-02-05 22:26:05.466008\",\n&gt;                     \"duration\": \"0:00:00.000759\",\n&gt;                     \"status\": \"SUCCESS\",\n&gt;                     \"message\": \"\",\n123,138c126\n&lt;             \"data_catalog\": [\n&lt;                 {\n&lt;                     \"name\": \"data/hello.txt\",\n&lt;                     \"data_hash\": \"949a4f1afcea77b4b3f483ebe993e733122fb87b7539a3fc3d6752030be6ad44\",\n&lt;                     \"catalog_relative_path\": \"data/hello.txt\",\n&lt;                     \"catalog_handler_location\": \"/mnt/catalog\",\n&lt;                     \"stage\": \"get\"\n&lt;                 },\n&lt;                 {\n&lt;                     \"name\": \"Retrieve_Content.execution.log\",\n&lt;                     \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n&lt;                     \"catalog_relative_path\": \"toFail/Retrieve_Content.execution.log\",\n&lt;                     \"catalog_handler_location\": \"/mnt/catalog\",\n&lt;                     \"stage\": \"put\"\n&lt;                 }\n&lt;             ]\n---\n&gt;             \"data_catalog\": []\n144c132\n&lt;             \"service_name\": \"argo\",\n---\n&gt;             \"service_name\": \"local\",\n147,177c135\n&lt;             \"overrides\": {},\n&lt;             \"image\": \"$argo_docker_image\",\n&lt;             \"expose_parameters_as_inputs\": true,\n&lt;             \"secrets_from_k8s\": [],\n&lt;             \"output_file\": \"argo-pipeline.yaml\",\n&lt;             \"name\": \"runnable-dag-\",\n&lt;             \"annotations\": {},\n&lt;             \"labels\": {},\n&lt;             \"activeDeadlineSeconds\": 172800,\n&lt;             \"nodeSelector\": null,\n&lt;             \"parallelism\": null,\n&lt;             \"retryStrategy\": {\n&lt;                 \"limit\": \"0\",\n&lt;                 \"retryPolicy\": \"Always\",\n&lt;                 \"backoff\": {\n&lt;                     \"duration\": \"120\",\n&lt;                     \"factor\": 2,\n&lt;                     \"maxDuration\": \"3600\"\n&lt;                 }\n&lt;             },\n&lt;             \"max_step_duration_in_seconds\": 7200,\n&lt;             \"tolerations\": null,\n&lt;             \"image_pull_policy\": \"\",\n&lt;             \"service_account_name\": \"default-editor\",\n&lt;             \"persistent_volumes\": [\n&lt;                 {\n&lt;                     \"name\": \"runnable-volume\",\n&lt;                     \"mount_path\": \"/mnt\"\n&lt;                 }\n&lt;             ],\n&lt;             \"step_timeout\": 14400\n---\n&gt;             \"overrides\": {}\n182c140\n&lt;             \"log_folder\": \"/mnt/run_log_store\"\n---\n&gt;             \"log_folder\": \".run_log_store\"\n191c149\n&lt;             \"catalog_location\": \"/mnt/catalog\"\n---\n&gt;             \"catalog_location\": \".catalog\"\n197c155\n&lt;         \"pipeline_file\": \"examples/retry-fail.yaml\",\n---\n&gt;         \"pipeline_file\": \"examples/retry-fixed.yaml\",\n199c157\n&lt;         \"configuration_file\": \"examples/configs/argo-config-catalog.yaml\",\n---\n&gt;         \"configuration_file\": \"examples/configs/fs-catalog-run_log.yaml\",\n201,204c159,164\n&lt;         \"run_id\": \"toFail\",\n&lt;         \"variables\": {},\n&lt;         \"use_cached\": false,\n&lt;         \"original_run_id\": \"\",\n---\n&gt;         \"run_id\": \"polynomial-bartik-2226\",\n&gt;         \"variables\": {\n&gt;             \"argo_docker_image\": \"harbor.csis.astrazeneca.net/mlops/runnable:latest\"\n&gt;         },\n&gt;         \"use_cached\": true,\n&gt;         \"original_run_id\": \"toFail\",\n208c168\n&lt;             \"description\": \"This is a simple pipeline that demonstrates retrying failures.\\n\\n1. Setup: We setup a data folder, we ignore if it is already present\\n2. Create Content: We create a \\\"hello.txt\\\" and \\\"put\\\" the file in catalog\\n3. Retrieve Content: We \\\"get\\\" the file \\\"hello.txt\\\" from the catalog and show the contents\\n5. Cleanup: We remove the data folder. Note that this is stubbed to prevent accidental deletion.\\n\\n\\nYou can run this pipeline by:\\n   runnable execute -f examples/catalog.yaml -c examples/configs/fs-catalog.yaml\\n\",\n---\n&gt;             \"description\": \"This is a simple pipeline that demonstrates passing data between steps.\\n\\n1. Setup: We setup a data folder, we ignore if it is already present\\n2. Create Content: We create a \\\"hello.txt\\\" and \\\"put\\\" the file in catalog\\n3. Clean up to get again: We remove the data folder. Note that this is stubbed to prevent\\n  accidental deletion of your contents. You can change type to task to make really run.\\n4. Retrieve Content: We \\\"get\\\" the file \\\"hello.txt\\\" from the catalog and show the contents\\n5. Cleanup: We remove the data folder. Note that this is stubbed to prevent accidental deletion.\\n\\n\\nYou can run this pipeline by:\\n   runnable execute -f examples/catalog.yaml -c examples/configs/fs-catalog.yaml\\n\",\n253c213\n&lt;                     \"command\": \"cat data/hello1.txt\",\n---\n&gt;                     \"command\": \"cat data/hello.txt\",\n266c226\n&lt;         \"dag_hash\": \"13f7c1b29ebb07ce058305253171ceae504e1683\",\n---\n&gt;         \"dag_hash\": \"2beec08fd417134cd3b04599d6684469db4ad176\",\n</code></pre>"},{"location":"concepts/run-log/#api","title":"API","text":"<p>Tasks can access the <code>run log</code> during the execution of the step using the API. The run log returned by this method is a deep copy to prevent any modifications.</p> <p>Tasks can also access the <code>run_id</code> of the current execution either by using the API or by the environment variable <code>runnable_RUN_ID</code>.</p>"},{"location":"concepts/secrets/","title":"Overview","text":"<p>Opt out</p> <p>Pipelines need not use the <code>secrets</code> if the preferred tools of choice is not implemented in runnable. The default configuration of <code>do-nothing</code> is no-op by design. We kindly request to raise a feature request to make us aware of the eco-system.</p> <p>Most complex pipelines require secrets to hold sensitive information during task execution. They could be database credentials, API keys or any information that need to present at the run-time but invisible at all other times.</p> <p>runnable provides a clean API to access secrets and independent of the actual secret provider, the interface remains the same.</p> <p>A typical example would be a task requiring the database connection string to connect to a database.</p> Using the secrets API<pre><code>class CustomObject:\n\n    @property\n    def connection_object(self):\n        from runnable import get_secret\n        connection_string = get_secret(\"connection_string\")\n        # Do something with the secrets\n</code></pre> <p>Please refer to configurations for available implementations.</p>"},{"location":"concepts/secrets/#example","title":"Example","text":"dotenv formatExample configurationPipeline in python <p>The dotenv format for providing secrets. Ideally, this file should not be part of the version control but present during development phase.</p> <p>The file is assumed to be present in <code>examples/secrets.env</code> for this example.</p> <pre><code>\n</code></pre> <ol> <li>Shell scripts style are supported.</li> <li>Key value based format is also supported.</li> </ol> <p>Configuration to use the dotenv format file.</p> <pre><code>secrets:\n  type: dotenv # (1)\n  config:\n    location: examples/secrets.env # (2)\n</code></pre> <ol> <li>Use dotenv secrets manager.</li> <li>Location of the dotenv file, defaults to <code>.env</code> in project root.</li> </ol> <pre><code>\n</code></pre> <ol> <li>The key of the secret that you want to retrieve.</li> </ol>"},{"location":"concepts/stub/","title":"Stub","text":"<p>Stub nodes in runnable are just like <code>Pass</code> state in AWS Step Functions or <code>pass</code> in python code. It is a placeholder and useful when you want to debug or design your pipeline.</p> <p>Stub nodes can take arbitrary number of parameters and is always a success.</p>"},{"location":"concepts/stub/#example","title":"Example","text":"<p>Intuition</p> <p>Designing a pipeline is similar to writing a modular program. Stub nodes are handy to create a placeholder for some step that will be implemented in the future.</p> <p>During debugging, changing a node to <code>stub</code> will let you focus on the actual bug without having to execute the additional steps.</p> yamlpython <p>In the below example, all the steps are <code>stub</code> nodes. The only required field is the <code>next</code> which is needed for graph traversal. As seen in <code>step 2</code> definition, they can have arbitrary fields.</p> <pre><code>dag:\n  description: |\n    This is a simple pipeline that does 3 steps in sequence.\n\n    step 1 &gt;&gt; step 2 &gt;&gt; step 3 &gt;&gt; success\n\n    All the steps are mocked and they will just pass through.\n    Use this pattern to define the skeleton of your pipeline and flesh out the steps later.\n\n    Note that you can give any arbitrary keys to the steps (like step 2). This is handy\n    to mock steps within mature pipelines.\n\n    You can run this pipeline by:\n       runnable execute -f examples/mocking.yaml\n  start_at: step 1\n  steps:\n    step 1:\n      type: stub\n      next: step 2\n    step 2:\n      type: stub\n      what: is this thing?\n      It: does not matter!!\n      next: step 3\n    step 3:\n      type: stub\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p>In the below example, all the steps are <code>stub</code> nodes.</p> <pre><code>\"\"\"\nThis is a simple pipeline that does 3 steps in sequence.\n\n    step 1 &gt;&gt; step 2 &gt;&gt; step 3 &gt;&gt; success\n\n    All the steps are mocked and they will just pass through.\n    Use this pattern to define the skeleton of your pipeline and flesh out the steps later.\n\n    Note that you can give any arbitrary keys to the steps (like step 2). This is handy\n    to mock steps within mature pipelines.\n\n    You can run this pipeline by:\n       python examples/mocking.py\n\"\"\"\n\nfrom runnable import Pipeline, Stub\n\n\ndef main():\n    step1 = Stub(name=\"step1\")  # (1)\n    step2 = Stub(name=\"step2\", what=\"is this thing\")\n\n    step3 = Stub(name=\"step3\", terminate_with_success=True)  # (3)\n\n    pipeline = Pipeline(steps=[step1, step2, step3], add_terminal_nodes=True)  # (4)\n\n    pipeline.execute()\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>The only required field is the <code>name</code>, <code>next</code> which is needed for graph traversal.</p> <ul> <li>yaml definition needs <code>next</code> to be defined as part of the step definition.</li> <li>python SDK can define the <code>next</code> when linking the nodes as part of the pipeline.</li> </ul>"},{"location":"concepts/task/","title":"Task","text":"<p>Task nodes are the execution units of the pipeline.</p> <p>In runnable, a <code>command</code> in a task node can be python functions, Jupyter notebooks or a shell scripts. All task nodes  can take arguments, retrieve and create files/objects and return arguments, though their access patterns are different.</p> <p>In the below examples, we define a pipeline either using python SDK or yaml format but both are equivalent and all the pipelines can be expressed in either formats.</p>"},{"location":"concepts/task/#python_functions","title":"Python functions","text":"<p>Python is the default <code>command type</code> of a task node. The <code>command</code> should be the dotted path to the python function.</p> <p>Dotted path</p> <p>Assuming the below project structure:</p> <ul> <li> <p>The <code>command</code> for the <code>outer_function</code> should be <code>outer_functions.outer_function</code></p> </li> <li> <p>The <code>command</code> for <code>inner_function</code> should be <code>module_inner.inner_functions.inner_function</code></p> <pre><code>..\n\u251c\u2500\u2500 outer_functions.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 outer_function()\n\u251c\u2500\u2500 module_inner\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 inner_functions.py\n\u2502\u00a0\u00a0 |    \u251c\u2500\u2500 inner_function()\n..\n</code></pre> </li> </ul>"},{"location":"concepts/task/#example","title":"Example","text":"pythonyaml <p>Structuring</p> <p>It is best to keep the application specific functions in a different module than the pipeline definition, if you are using Python SDK.</p> <p>In this example, we combined them as one module for convenience.</p> <p>You can execute this pipeline using <code>examples/concepts/simple.py</code></p> <pre><code>\"\"\"\nA simple pipeline with a simple function that just prints \"Hello World!\".\n\nRun this pipeline by:\n    python examples/concepts/simple.py\n\"\"\"\n\nfrom runnable import Pipeline, PythonTask\n\n\ndef simple_function():\n    \"\"\"\n    A simple function that just prints \"Hello World!\".\n    \"\"\"\n    print(\"Hello World!\")\n\n\ndef main():\n    simple_task = PythonTask(\n        name=\"simple\",\n        function=simple_function,\n        terminate_with_success=True,\n    )\n\n    pipeline = Pipeline(\n        steps=[simple_task],\n        add_terminal_nodes=True,\n    )\n\n    pipeline.execute()  # (1)\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>You can execute this by runnable execute -f examples/concepts/simple.yaml</p> <pre><code>dag:\n  description: |\n    A simple pipeline with a simple function that just prints \"Hello World!\".\n\n    Run this pipeline by:\n      runnable execute -f  examples/concepts/simple.yaml\n  start_at: simple\n  steps:\n    simple:\n      type: task\n      command: \"examples.concepts.simple.simple_function\"\n      command_type: python\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre>"},{"location":"concepts/task/#closer_look","title":"Closer look","text":"<p>Lines 4-8 in the python code defines the function that we want to execute as  part of the pipeline. They are plain old python functions.</p> <p>The rest of the python code (or yaml) defines and executes a pipeline that executes a task whose <code>command</code> is to execute this function.</p>"},{"location":"concepts/task/#fields","title":"Fields","text":"<ul> <li><code>command</code> : Should refer to the function in dotted path notation.</li> <li><code>command_type</code>: Defaults to python and not needed for python task types.</li> <li>next: is required for any step of the pipeline except for success and fail steps.</li> <li>on_failure: Name of the step to execute if the step fails.</li> <li>catalog: Optional required for data access patterns from/to the central storage.</li> </ul>"},{"location":"concepts/task/#accessing_parameters","title":"Accessing parameters","text":"<p>Mutability</p> <p>Functions mutating the input parameters is idiomatic is python. However, functions as part of runnable pipeline should return the mutated parameters for downstream steps to have access to them.</p> <p>For example, unless the function <code>mutating_function</code> returns the updated parameters, runnable will not know about the change.</p> <pre><code>d = {\"name\": \"monty\"}\nprint(d)\n\"&gt;&gt;&gt; {'name': 'monty'}\"\n\ndef mutating_function(input_dict):\n    input_dict[\"name\"] = \"python\"\n\n\nmutating_function(d)\nprint(d)\n\"&gt;&gt;&gt;{'name': 'python'}\"\n</code></pre> <p>Please refer to Initial Parameters for more information about setting initial parameters.</p> <p>Lets assume that the initial parameters are:</p> <pre><code>spam: \"Hello\"\neggs:\n  ham: \"Yes, please!!\"\n</code></pre> <ul> <li> Passing parameters between steps</li> </ul> NativelyUsing the APIUsing environment variables <p>Internally, runnable stores the parameters in serialised json format.</p> <p>runnable also has python API to access parameters.</p> <p>Use get_parameter to access a parameter at the root level. You can optionally specify the <code>type</code> by using <code>cast_as</code> argument to the API. For example, line 19 would cast <code>eggs</code>parameter into <code>EggsModel</code>. Native python types do not need any explicit <code>cast_as</code> argument.</p> <p>Use set_parameter to set parameters at the root level. Multiple parameters can be set at the same time, for example, line 26 would set both the <code>spam</code> and <code>eggs</code> in a single call.</p> <p>The pydantic models would be serialised to json format using model_dump, respecting the alias.</p> <p>You can run this example by: <code>python run examples/concepts/task_api_parameters.py</code></p> <pre><code>\n</code></pre> <p>Any environment variable with <code>runnable_PRM_</code> is understood to be a parameter in runnable.</p> <p>Before the execution of the <code>command</code>, all the parameters at the root level are set as environment variables with the key prefixed by <code>runnable_PRM_</code>. Python functions that are called during the execution of the command can also access them as environment variables.</p> <p>After the execution of the <code>command</code>, the environment is \"scanned\" again to identify changes to the existing variables prefixed by <code>runnable_PRM_</code>. All updated variables are stored at the root level.</p> <p>Parameters set by environment variables over-ride the parameters defined by the initial parameters which can be handy to quickly experiment without modifying code or to dynamically adjust behavior when running in orchestrators like Argo or AWS step functions.</p> <p>You can run this example by: <code>python run examples/concepts/task_env_parameters.py</code></p> <pre><code>\n</code></pre> <p>Verbose?</p> <p>We acknowledge that using pydantic models as our Data transfer objects is verbose in comparison to using <code>dict</code>.</p> <p>The advantages of using strongly typed DTO has long term advantages of implicit validation, typing hints in editors. This choice is inspired from FastAPI's ways of working.</p>"},{"location":"concepts/task/#input_arguments_to_the_function","title":"Input arguments to the function","text":"<p>Any arguments passed into the function should be at the root level of the json object. Arguments with type annotations will be casted appropriately. Arguments with no type annotation will be sent in as <code>dict</code>.</p> <p>In the below example, in line 13 and 28, arguments <code>spam</code> and <code>eggs</code> are at the root level in the yaml representation and also are annotated in the function signature. They are sent in to the function as arguments with proper type conversion.</p> <p>Annotation</p> <p>Without annotations, runnable cannot determine the type and can cause unexpected behavior.</p> <p>This is especially true in distributed executors (eg: argo workflows).</p>"},{"location":"concepts/task/#output_arguments_of_function","title":"Output arguments of function","text":"<p>Only pydantic models are allowed to be return types of a function. There is no need for any type annotation for return type but is advised for a cleaner code.</p> <p>Output arguments are stored in json format by model_dump, respecting the alias.</p> <p>The model structure of the pydantic model would be added to the root structure. This is useful when you want to add or modify parameters at the root level. For example, line 25 would update all the initial parameters.</p> <p>To update a subset of existing parameters at the root level, you can either create a new model or use DynamicModel. For example, lines 42-45 create a dynamic model to update the <code>eggs</code> parameter.</p> <p>caution</p> <p>Returning \"eggs\" in line 42 would result in a new parameter \"ham\" at the root level  as it looses the nested structure.</p> <p>You can run this example using: <code>python run examples/concepts/task_native_parameters.py</code></p> <pre><code>\"\"\"\nAn example pipeline of accessing initial parameters and passing parameters between tasks.\n\nYou can run this pipeline by:\n    python examples/concepts/task_native_parameters.py\n\n\"\"\"\n\nfrom pydantic import BaseModel, create_model\n\n\nclass EggsModel(BaseModel):\n    ham: str\n\n\nclass EverythingModel(BaseModel):\n    spam: str\n    eggs: EggsModel\n\n\ndef modify_initial(spam: str, eggs: EggsModel):\n    \"\"\"\n    Access initial parameters by the keys.\n    Type annotation helps in casting to the right model type.\n    \"\"\"\n    print(spam)\n    \"&gt;&gt;&gt; Hello\"\n    print(eggs)\n    \"&gt;&gt;&gt; ham='Yes, please!!'\"\n\n    # Return modified parameters\n    # Use this pattern to create or modify parameters at the root level.\n    return EverythingModel(spam=\"World\", eggs=EggsModel(ham=\"No, Thank you!!\"))\n\n\ndef consume(eggs: EggsModel):\n    \"\"\"\n    Access only a subset of the parameters.\n    \"\"\"\n    # the value is set by the modify_initial function.\n    print(eggs)\n    \"&gt;&gt;&gt; ham='No, Thank you!!'\"\n\n    # runnable supports only pydantic models as return types.\n    # You can modify a subset of the parameters by creating a dynamic pydantic model.\n    # https://docs.pydantic.dev/latest/concepts/models/#dynamic-model-creation\n\n    # CAUTION: Returning \"eggs\" would result in a new parameter \"ham\" at the root level\n    # as it looses the nested structure.\n    return create_model(\n        \"DynamicModel\",\n        eggs=(EggsModel, EggsModel(ham=\"May be one more!!\")),\n    )()\n\n\ndef main():\n    from runnable import Pipeline, PythonTask\n\n    modify = PythonTask(\n        name=\"Modify\",\n        function=modify_initial,\n    )\n\n    consume_parameters = PythonTask(\n        name=\"Consume\",\n        function=consume,\n        terminate_with_success=True,\n    )\n\n    pipeline = Pipeline(\n        steps=[modify, consume_parameters],\n        add_terminal_nodes=True,\n    )\n    pipeline.execute(parameters_file=\"examples/concepts/parameters.yaml\")\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"concepts/task/#passing_data_and_execution_logs","title":"Passing data and execution logs","text":"<p>Please refer to catalog for more details and examples on passing data between tasks and the storage of execution logs.</p>"},{"location":"concepts/task/#notebook","title":"Notebook","text":"<p>Jupyter notebooks are supported as part of a task step. We internally use Ploomber engine for executing notebooks.</p> <p>The output is saved to the same location as the input notebook but with <code>_out</code> post-fixed to the name of the notebook. This is configurable by <code>notebook_output_path</code> while defining the task either via yaml or the sdk.</p> <p>The output notebook is also saved in the <code>catalog</code> for logging and ease of debugging.</p>"},{"location":"concepts/task/#example_1","title":"Example","text":"NotebookPipeline <p>The below is a simple notebook for demonstration.</p> <p>Below is just a screenshot, the original notebook can be found at <code>examples/concepts/simple_notebook.yaml</code>.</p> <p> </p> <p>The same pipeline can also be defined via the SDK.</p> <pre><code>dag:\n  description: |\n    This is a sample pipeline with one step that executes a notebook.\n\n    The step name \"notebook\" has the \"command_type\" to be notebook to\n    let runnable know to execute a notebook while the command is the\n    path to the notebook relative to the project root.\n\n    The notebook is executed in the same environment as the current\n    project, you can import any module that was installed for the project.\n\n    You can run this pipeline as:\n      runnable execute -f examples/concepts/simple_notebook.yaml\n\n  start_at: notebook\n  steps:\n    notebook:\n      type: task\n      command_type: notebook\n      returns:\n        - name: a\n        - name: b\n        - name: c\n      command: examples/concepts/simple_notebook.ipynb\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre>"},{"location":"concepts/task/#closer_look_1","title":"Closer look","text":"<p>The structure of the pipeline remains the same as with any <code>task</code>. In the pipeline definition,  <code>command_type</code> in line number 19 specifies the type of the task to be a notebook  while the <code>command</code> in line number 20 specifies the location of the notebook relative to the project root.</p> <p>The notebook executed in the same shell session, thanks to ploomber engine, so any libraries installed in the current project are readily available.</p>"},{"location":"concepts/task/#fields_1","title":"Fields","text":"<ul> <li><code>command</code> : Should be the location of the notebook relative to the project root. It should end with <code>.ipynb</code>.</li> <li><code>command_type</code>: Should be <code>notebook</code> to execute notebooks.</li> <li><code>notebook_output_path</code>: the location of the executed notebook. Defaults to the notebook name defined in <code>command</code> with <code>_out</code> post-fixed. The location should be relative to the project root and also would be stored in catalog in the same location.</li> <li>next: is required for any step of the pipeline except for success and fail steps.</li> <li>on_failure: Name of the step to execute if the step fails.</li> <li>catalog: Optional required for data access patterns from/to the central storage.</li> </ul>"},{"location":"concepts/task/#ploomber_arguments","title":"ploomber arguments","text":"<p>Please refer to ploomber arguments for available arguments. During the execution of the notebook, we set</p> <ul> <li>input_path: To refer to command</li> <li>output_path: to refer to notebook_output_path.</li> <li>parameters: To the dictionary of available parameters.</li> <li>log_output: True.</li> <li>progress_bar: False</li> </ul> <p>You can set additional arguments or override these by sending an optional dictionary <code>optional_ploomber_args</code>.</p>"},{"location":"concepts/task/#accessing_parameters_1","title":"Accessing parameters","text":"<p>Please refer to Initial Parameters for more information about setting initial parameters.</p> <p>Assume that the initial parameters are:</p> <pre><code>spam: \"Hello\"\neggs:\n  ham: \"Yes, please!!\"\n</code></pre> <ul> <li> Passing parameters between steps</li> </ul> NativelyUsing the APIUsing environment variables <p>Note</p> <p>The actual notebook is available in examples/concepts/notebook_native_parameters.ipynb. Below are some screenshots to show the detail.</p> pipeline definitionNotebook Pipeline definition<pre><code>dag:\n  description: |\n    This is a sample pipeline with one step that executes a notebook.\n\n    The step name \"notebook\" has the \"command_type\" to be notebook to\n    let runnable know to execute a notebook while the command is the\n    path to the notebook relative to the project root.\n\n    The notebook is executed in the same environment as the current\n    project, you can import any module that was installed for the project.\n\n    You can run this pipeline as:\n      runnable execute -f examples/concepts/notebook_native_parameters.yaml -p examples/concepts/parameters.yaml\n\n  start_at: notebook\n  steps:\n    notebook:\n      type: task\n      command_type: notebook\n      command: examples/concepts/notebook_native_parameters.ipynb\n      returns:\n        - name: spam\n          kind: json\n        - name: eggs\n          kind: json\n        - name: custom\n          kind: object\n      next: consume_notebook\n    consume_notebook:\n      type: task\n      command_type: notebook\n      command: examples/concepts/notebook_native_parameters_consume.ipynb\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p> </p> <p>As seen in python tasks, you can use the python API's to get and set parameters.</p> pipeline definitionNotebook <p>The below pipeline reuses the native parameters notebook to modify the initial parameters, retrieves them via the <code>get_parameter</code> API and updates the parameters by <code>set_parameter</code> API.</p> Pipeline definition<pre><code>\n</code></pre> <p>Below is just a screenshot of the notebook, the original notebook can be found at <code>examples/concepts/notebook_api_parameters.ipynb</code></p> <p> </p> <p>In the output notebook, you might see a cell with a tag <code>injected_parameters</code> at the start of the notebook, this should not interfere with the way the notebook behaves.</p> <p>As seen in python tasks, you can get/set the parameters by using environment variables. Any variable with prefix <code>runnable_PRM_</code> is identified to be a parameter.</p> pipeline definitionNotebook <p>The below pipeline reuses the native parameters notebook to modify the initial parameters, by using environment variables.</p> Pipeline definition<pre><code>\n</code></pre> <p>Below is just a screenshot of the notebook, the original notebook can be found at <code>examples/concepts/notebook_env_parameters.ipynb</code></p> <p> </p>"},{"location":"concepts/task/#input_parameters_to_the_notebook","title":"Input parameters to the notebook","text":"<p>Input parameters to the notebook are \"injected\" into the notebook by tagging the cell as \"parameters\". Please refer to Ploomber engine for more details.</p> <p>For example, the initial parameters will be passed to the notebook as shown below.</p> <p> </p> <p>The cell with the <code>parameters</code> tag will be introspected and variables defined in that cell would be replaced with the variables passed into the notebook during execution.</p> <p>Nested parameters will be sent in as a <code>dict</code>.</p>"},{"location":"concepts/task/#output_parameters_from_the_notebook","title":"Output parameters from the notebook","text":"<p>Similar to the input parameters, outputs from the notebook ca be indicated by tagging the cell. Please ensure The tagged cell should <code>print</code> the dictionary as the output and nothing else.</p> <p>The default <code>tag</code> to indicate output parameters is <code>runnable_output</code> but can be configured by <code>output_cell_tag</code> while defining the task in both SDK and yaml.</p> <p> </p>"},{"location":"concepts/task/#passing_data_and_execution_logs_1","title":"Passing data and execution logs","text":"<p>Please refer to catalog for more details and examples on passing data between tasks and the storage of execution logs.</p>"},{"location":"concepts/task/#shell","title":"Shell","text":"<p>Python functions and Jupyter notebooks provide a rich interface to the python ecosystem while shell provides a interface to non-python executables.</p> <p>We internally use Popen to execute the command.</p>"},{"location":"concepts/task/#example_2","title":"Example","text":"Pipeline definition<pre><code>dag:\n  description: |\n    This is a sample pipeline with one step that executes a shell command.\n\n    The step name \"shell\" has the \"command_type\" to be shell to\n    let runnable know to execute a shell while the command is directly\n    executed in the current environment.\n\n    You can run this pipeline as:\n      runnable execute -f examples/concepts/task_shell_simple.yaml\n\n  start_at: shell\n  steps:\n    shell:\n      type: task\n      command_type: shell\n      command: echo \"Hello world!!\"\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre>"},{"location":"concepts/task/#fields_2","title":"Fields","text":"<ul> <li><code>command</code> : Should refer to the exact command to execute. Multiple commands can be run by using the <code>&amp;&amp;</code> delimiter.</li> <li><code>command_type</code>: Should be shell.</li> <li>next: is required for any step of the pipeline except for success and fail steps.</li> <li>on_failure: Name of the step to execute if the step fails.</li> <li>catalog: Optional required for data access patterns from/to the central storage.</li> </ul>"},{"location":"concepts/task/#accessing_parameters_2","title":"Accessing parameters","text":"<p>Please refer to Initial Parameters for more information about setting initial parameters.</p> <p>Assuming the initial parameters are:</p> <pre><code>spam: \"Hello\"\neggs:\n  ham: \"Yes, please!!\"\n</code></pre> <ul> <li> Passing parameters between steps</li> </ul> <p>The only way <code>shell</code> commands can pass parameters between steps is via the <code>environment</code> variables. Any environment variable with prefix <code>runnable_PRM_</code> should be understood as a parameter inside the shell script/command. Nested parameters are set in json string format.</p> <p>To pass parameter to downstream steps, set/update environment variables with <code>runnable_PRM_</code> prefix. The execution environment is \"scanned\" for updated environment variables and stored for downstream steps.</p> <pre><code>dag:\n  description: |\n    This is a sample pipeline to show the parameter flow for shell types.\n\n    The step \"access initial\" just displays the initial parameters defined in examples/concepts/parameters.yaml\n    The step modify_initial updates the parameters and sets them back as environment variables.\n    The step display_again displays the updated parameters from modify_initial and updates them.\n\n    You can run this pipeline as:\n      runnable execute -f examples/concepts/task_shell_parameters.yaml  -p examples/concepts/parameters.yaml\n\n  start_at: access initial\n  steps:\n    access initial:\n      type: task\n      command_type: shell\n      command: |\n        env\n      next: modify initial\n    modify initial:\n      type: task\n      command_type: shell\n      returns:\n        - name: spam\n          kind: json\n        - name: eggs\n          kind: json\n      command: |\n        export spam='World'\n        export eggs='{\"ham\": \"No, Thank you!!\"}'\n      next: display again\n    display again:\n      type: task\n      command_type: shell\n      returns:\n        - name: spam\n          kind: json\n        - name: eggs\n          kind: json\n\n      command: |\n        env &amp;&amp; \\\n        export spam='Universe' &amp;&amp; \\\n        export eggs='{\"ham\": \"Maybe, one more..\"}'\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p>In the above example, the execution is specified with initial parameters by the <code>-p</code> option.</p> <p>In line 18, we just display the parameters prefixed by <code>runnable_PRM_``. The next step</code>modify_initial``` updates the parameters by setting new environment variables in line 26 and 27.</p> <p>The next step <code>display_again</code> displays the updated parameters and updates them for downstream steps in lines 33-35.</p> <p>Output</p> <p>You might notice that the output might have a few extra lines starting with <code>runnable</code>. You can ignore them as they are generated by internal mechanisms of runnable.</p>"},{"location":"concepts/task/#passing_data_and_execution_logs_2","title":"Passing data and execution logs","text":"<p>Please refer to catalog for more details and examples on passing data between tasks and the storage of execution logs.</p>"},{"location":"concepts/task/#experiment_tracking","title":"Experiment tracking","text":"<p>Please refer to experiment tracking for more details and examples on experiment tracking.</p>"},{"location":"concepts/the-big-picture/","title":"tl;dr","text":"<p>runnable revolves around the concept of pipelines or workflows and tasks that happen within them.</p> <p>A workflow is simply a series of steps that you want to execute for a desired outcome.</p> <pre><code>%%{ init: { 'flowchart': { 'curve': 'linear' } } }%%\nflowchart LR\n\n    step1:::green\n    step1([Step 1]) --&gt; step2:::green\n    step2([Step 2]) --&gt; step3:::green\n    step3([Step .. ]) --&gt; step4:::green\n    step4([Step n]) --&gt; suc([success]):::green\n\n    classDef green stroke:#0f0\n</code></pre> <p>To define a workflow, we need:</p> <ul> <li>List of steps</li> <li>a starting step</li> <li> <p>Next step</p> <ul> <li>In case of success</li> <li>In case of failure</li> </ul> </li> <li> <p>Terminating</p> </li> </ul> <p>The workflow can be defined either in <code>yaml</code> or using the <code>python sdk</code>.</p> <p>A step in the workflow can be:</p> taskstubparallelmap <p>A step in the workflow that does a logical unit work.</p> <p>The unit of work can be a python function, a shell script or a notebook.</p> <p>All the logs, i.e stderr and stdout or executed notebooks are stored in catalog for easier access and debugging.</p> <p>An abstract step that is not yet fully implemented.</p> <p>For example in python:</p> <pre><code>def do_something():\n    pass\n</code></pre> <p>A step that has a definite number of parallel workflows executing  simultaneously.</p> <p>In the below visualisation, the green lined steps happen in sequence and wait for the previous step to successfully complete.</p> <p>The branches lined in yellow run in parallel to each other but sequential within the branch.</p> <pre><code>flowchart TD\n\n    getFeatures([Get Features]):::green\n    trainStep(Train Models):::green\n    ensembleModel([Ensemble Modelling]):::green\n    inference([Run Inference]):::green\n    success([Success]):::green\n\n    prepareXG([Prepare for XGBoost]):::yellow\n    trainXG([Train XGBoost]):::yellow\n    successXG([XGBoost success]):::yellow\n    prepareXG --&gt; trainXG --&gt; successXG\n\n    trainRF([Train RF model]):::yellow\n    successRF([RF Model success]):::yellow\n    trainRF --&gt; successRF\n\n\n    getFeatures --&gt; trainStep\n    trainStep --&gt; prepareXG\n    trainStep --&gt; trainRF\n    successXG --&gt; ensembleModel\n    successRF --&gt; ensembleModel\n    ensembleModel --&gt; inference\n    inference --&gt; success\n\n\n    classDef yellow stroke:#FFFF00\n    classDef green stroke:#0f0\n\n</code></pre> <p>A step that executes a workflow over an iterable parameter.</p> <p>The step \"chunk files\" identifies the number of files to process and computes the start index of every batch of files to process for a chunk size of 10, the stride.</p> <p>\"Process Chunk\" pipelines are then triggered in parallel to process the chunk of files between <code>start index</code> and <code>start index + stride</code></p> <pre><code>flowchart TD\nchunkify([Chunk files]):::green\nsuccess([Success]):::green\n\nsubgraph one[Process Chunk]\n    process_chunk1([Process Chunk]):::yellow\n    success_chunk1([Success]):::yellow\n\n    process_chunk1 --&gt; success_chunk1\nend\n\nsubgraph two[Process Chunk]\n    process_chunk2([Process Chunk]):::yellow\n    success_chunk2([Success]):::yellow\n\n    process_chunk2 --&gt; success_chunk2\nend\n\nsubgraph three[Process Chunk]\n    process_chunk3([Process Chunk]):::yellow\n    success_chunk3([Success]):::yellow\n\n    process_chunk3 --&gt; success_chunk3\nend\n\nsubgraph four[Process Chunk]\n    process_chunk4([Process Chunk]):::yellow\n    success_chunk4([Success]):::yellow\n\n    process_chunk4 --&gt; success_chunk4\nend\n\nsubgraph five[Process Chunk]\n    process_chunk5([Process Chunk]):::yellow\n    success_chunk5([Success]):::yellow\n\n    process_chunk5 --&gt; success_chunk5\nend\n\n\n\nchunkify -- (stride=10, start_index=0)--&gt; one --&gt; success\nchunkify -- (stride=10, start_index=10)--&gt; two --&gt; success\nchunkify -- (stride=10, start_index=20)--&gt; three --&gt; success\nchunkify -- (stride=10, start_index=30)--&gt; four --&gt; success\nchunkify -- (stride=10, start_index=40)--&gt; five --&gt; success\n\nclassDef yellow stroke:#FFFF00\nclassDef green stroke:#0f0</code></pre> <p>A step type of task is the functional unit of the pipeline.</p> <p>To be useful, it can:</p> <ul> <li> <p>Access parameters</p> <ul> <li>Either defined statically at the start of the pipeline</li> <li>Or by upstream steps</li> </ul> </li> <li> <p>Publish or retrieve artifacts from/to other steps.</p> </li> </ul> <ul> <li>Have access to secrets.</li> </ul> <p>All the above functionality is possible naturally with no intrusion into code base.</p> <p>All executions of the pipeline should be:</p> <ul> <li>Reproducible for audit and data lineage purposes.</li> <li>Runnable in local environments for debugging failed runs.</li> </ul> <p>Executions of pipeline should be scalable and use the infrastructure at your disposal efficiently.</p> <p>We achieve this by adding one configuration file, rather than changing the application code.</p>"},{"location":"configurations/catalog/","title":"Catalog","text":"<p>Catalog provides a way to store and retrieve data generated by the individual steps of the dag to downstream steps of the dag. Please refer to concepts for more detailed information.</p>"},{"location":"configurations/catalog/#do-nothing","title":"do-nothing","text":"<p>A noop implementation which does nothing.</p>"},{"location":"configurations/catalog/#configuration","title":"Configuration","text":"<pre><code>catalog:\n  type: do-nothing\n</code></pre>"},{"location":"configurations/catalog/#file-system","title":"file-system","text":"<p>In this configuration, the local folder is used a catalog store. The default location is <code>.catalog</code>. Every execution of the pipeline will create a new directory by the <code>run_id</code> to store all the generated artifacts.</p>"},{"location":"configurations/catalog/#configuration_1","title":"Configuration","text":"<pre><code>catalog:\n  type: file-system\n  config:\n    catalog_location: .catalog # default value\n</code></pre>"},{"location":"configurations/catalog/#example","title":"Example","text":"ConfigurationPipelineCatalog structureRun log entry <pre><code>catalog:\n  type: file-system # (1)\n</code></pre> <ol> <li>Use local file-system as catalog, default location is <code>.catalog</code></li> </ol> <pre><code>\"\"\"\nAn example pipeline to demonstrate the use of file-system catalog.\n\nRun this pipeline by:\n    python examples/concepts/catalog_simple.py\n\n\"\"\"\n\nfrom runnable import Catalog, Pipeline, ShellTask\n\n\ndef main():\n    # Make the data folder if it does not exist\n    set_up = ShellTask(name=\"Setup\", command=\"mkdir -p data\")\n\n    # create a catalog instruction to put a file into the catalog\n    create_catalog = Catalog(put=[\"data/hello.txt\"])\n    # This task will create a file in the data folder and attaches the instruction\n    # to put the file into the catalog.\n    create = ShellTask(\n        name=\"Create Content\",\n        command='echo \"Hello from runnable\" &gt;&gt; data/hello.txt',\n        catalog=create_catalog,\n        terminate_with_success=True,\n    )\n\n    pipeline = Pipeline(\n        steps=[set_up, create],\n        add_terminal_nodes=True,\n    )\n\n    # override the default configuration to use file-system catalog.\n    pipeline.execute(configuration_file=\"examples/configs/fs-catalog.yaml\")\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>The files suffixed by <code>.execution.log</code> are stdout and stderr of the command.</p> <pre><code>.catalog\n\u2514\u2500\u2500 juicy-blackwell-0625\n    \u251c\u2500\u2500 Create_Content.execution.log\n    \u251c\u2500\u2500 Setup.execution.log\n    \u2514\u2500\u2500 data\n        \u2514\u2500\u2500 hello.txt\n\n3 directories, 3 files\n</code></pre> <p>All the execution logs of steps along with files are stored in the catalog. Please look at the highlighted lines in the run log.</p> <pre><code>{\n    \"run_id\": \"juicy-blackwell-0625\",\n    \"dag_hash\": \"\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {\n        \"Setup\": {\n            \"name\": \"Setup\",\n            \"internal_name\": \"Setup\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"39cd98770cb2fd6994d8ac08ae4c5506e5ce694a\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-04 06:25:26.014967\",\n                    \"end_time\": \"2024-02-04 06:25:26.026029\",\n                    \"duration\": \"0:00:00.011062\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"Setup.execution.log\",\n                    \"data_hash\": \"b38eb7b5290ff433276a75fdd7a3935335aedff3ab5ee8714f6ea735d9c9492c\",\n                    \"catalog_relative_path\": \"juicy-blackwell-0625/Setup.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"Create Content\": {\n            \"name\": \"Create Content\",\n            \"internal_name\": \"Create Content\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"39cd98770cb2fd6994d8ac08ae4c5506e5ce694a\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-04 06:25:26.092282\",\n                    \"end_time\": \"2024-02-04 06:25:26.100095\",\n                    \"duration\": \"0:00:00.007813\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"Create_Content.execution.log\",\n                    \"data_hash\": \"b38eb7b5290ff433276a75fdd7a3935335aedff3ab5ee8714f6ea735d9c9492c\",\n                    \"catalog_relative_path\": \"juicy-blackwell-0625/Create_Content.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                },\n                {\n                    \"name\": \"data/hello.txt\",\n                    \"data_hash\": \"50e75c30352e8ef442b2b5be37dd19533f9334faaf8c4e41f2b528df57d3c20c\",\n                    \"catalog_relative_path\": \"juicy-blackwell-0625/data/hello.txt\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"39cd98770cb2fd6994d8ac08ae4c5506e5ce694a\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-04 06:25:26.165278\",\n                    \"end_time\": \"2024-02-04 06:25:26.165355\",\n                    \"duration\": \"0:00:00.000077\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"overrides\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"buffered\",\n            \"service_type\": \"run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\",\n            \"catalog_location\": \".catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"\",\n        \"parameters_file\": \"\",\n        \"configuration_file\": \"examples/configs/fs-catalog.yaml\",\n        \"tag\": \"\",\n        \"run_id\": \"juicy-blackwell-0625\",\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"Setup\",\n            \"name\": \"\",\n            \"description\": \"\",\n            \"steps\": {\n                \"Setup\": {\n                    \"type\": \"task\",\n                    \"name\": \"Setup\",\n                    \"next\": \"Create Content\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1,\n                    \"command\": \"mkdir -p data\",\n                    \"command_type\": \"shell\",\n                    \"node_name\": \"Setup\"\n                },\n                \"Create Content\": {\n                    \"type\": \"task\",\n                    \"name\": \"Create Content\",\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": {\n                        \"get\": [],\n                        \"put\": [\n                            \"data/hello.txt\"\n                        ]\n                    },\n                    \"max_attempts\": 1,\n                    \"command\": \"echo \\\"Hello from runnable\\\" &gt;&gt; data/hello.txt\",\n                    \"command_type\": \"shell\",\n                    \"node_name\": \"Create Content\"\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre>"},{"location":"configurations/overview/","title":"Overview","text":"<p>runnable is designed to make effective collaborations between data scientists/researchers and infrastructure engineers.</p> <p>All the features described in the concepts are aimed at the research side of data science projects while configurations add scaling features to them.</p> <p>Configurations are presented during the execution:</p> <p>For <code>yaml</code> based pipeline, use the <code>--config-file, -c</code> option in the runnable CLI.</p> <p>For python SDK, use the <code>configuration_file</code> option or via environment variable <code>runnable_CONFIGURATION_FILE</code></p>"},{"location":"configurations/overview/#default_configuration","title":"Default configuration","text":"<pre><code>executor:\n  type: local # (1)\n\nrun_log_store:\n  type: buffered # (2)\n\ncatalog:\n  type: do-nothing # (3)\n\nsecrets:\n  type: do-nothing # (4)\n</code></pre> <ol> <li>Execute the pipeline in the local compute environment.</li> <li>The run log is not persisted but present in-memory and flushed at the end of execution.</li> <li>No catalog functionality, all catalog operations are effectively no-op.</li> <li>No secrets functionality, all secrets are effectively no-op.</li> <li>No experiment tracking tools, all interactions with experiment tracking tools are effectively no-op. Run log still captures the metrics, but are not passed to the experiment tracking tools.</li> </ol> <p>The default configuration for all the pipeline executions runs on the local compute, using a buffered run log store with no catalog or secrets or experiment tracking functionality.</p>"},{"location":"configurations/overview/#format","title":"Format","text":"<p>The configuration file is in yaml format and the typical structure is:</p> <pre><code>service:\n  type: service provider\n  config:\n    ...\n</code></pre> <p>where service is one of <code>executor</code>, <code>catalog</code>, <code>experiment_tracker</code>,  <code>secrets</code> or <code>run_log_store</code>.</p>"},{"location":"configurations/run-log/","title":"Run log","text":"<p>Along with tracking the progress and status of the execution of the pipeline, run log also keeps a track of parameters, experiment tracking metrics, data flowing through the pipeline and any reproducibility metrics emitted by the tasks of the pipeline.</p> <p>Please refer here for detailed information about run log.</p>"},{"location":"configurations/run-log/#buffered","title":"buffered","text":"<p>Stores all the run log in-memory. The run log is not persisted and destroyed immediately after the execution is complete.</p> <p>Parallel execution</p> <p><code>buffered</code> run log stores suffers from race conditions when two tasks need to update status concurrently.</p>"},{"location":"configurations/run-log/#configuration","title":"Configuration","text":"<pre><code>run_log_store:\n  type: buffered\n</code></pre>"},{"location":"configurations/run-log/#file-system","title":"file-system","text":"<p>Stores the run log as a <code>json</code> file in the file-system accessible by all the steps of the pipeline.</p> <p>Parallel execution</p> <p><code>file-system</code> based run log stores suffers from race conditions when two tasks need to update status concurrently. Use <code>chunked</code> version to avoid this behavior or disable parallelism.</p>"},{"location":"configurations/run-log/#configuration_1","title":"Configuration","text":"<pre><code>run_log_store:\n  type: file-system\n  config:\n    log_folder: # defaults to  \".run_log_store\"\n</code></pre>"},{"location":"configurations/run-log/#example","title":"Example","text":"Configurationsdk pipelineRun logfolder structure <p>Assumed to be present at <code>examples/configs/fs-run_log.yaml</code></p> <pre><code>run_log_store:\n  type: file-system\n</code></pre> <p>The configuration can be provided dynamically by setting the environment variable <code>runnable_CONFIGURATION_FILE</code>.</p> <p>Executing the pipeline with:</p> <p><code>runnable_CONFIGURATION_FILE=examples/configs/fs-run_log.yaml python examples/concepts/simple.py</code></p> <pre><code>\"\"\"\nA simple pipeline with a simple function that just prints \"Hello World!\".\n\nRun this pipeline by:\n    python examples/concepts/simple.py\n\"\"\"\n\nfrom runnable import Pipeline, PythonTask\n\n\ndef simple_function():\n    \"\"\"\n    A simple function that just prints \"Hello World!\".\n    \"\"\"\n    print(\"Hello World!\")\n\n\ndef main():\n    simple_task = PythonTask(\n        name=\"simple\",\n        function=simple_function,\n        terminate_with_success=True,\n    )\n\n    pipeline = Pipeline(\n        steps=[simple_task],\n        add_terminal_nodes=True,\n    )\n\n    pipeline.execute()  # (1)\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>The structure of the run log is detailed in concepts.</p> <pre><code>{\n    \"run_id\": \"blocking-shaw-0538\",\n    \"dag_hash\": \"\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {\n        \"simple\": {\n            \"name\": \"simple\",\n            \"internal_name\": \"simple\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"39cd98770cb2fd6994d8ac08ae4c5506e5ce694a\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-02 05:38:07.973392\",\n                    \"end_time\": \"2024-02-02 05:38:07.977228\",\n                    \"duration\": \"0:00:00.003836\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"simple.execution.log\",\n                    \"data_hash\": \"03ba204e50d126e4674c005e04d82e84c21366780af1f43bd54a37816b6ab340\",\n                    \"catalog_relative_path\": \"blocking-shaw-0538/simple.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"39cd98770cb2fd6994d8ac08ae4c5506e5ce694a\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-02 05:38:08.056864\",\n                    \"end_time\": \"2024-02-02 05:38:08.057359\",\n                    \"duration\": \"0:00:00.000495\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"overrides\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"run_log_store\",\n            \"log_folder\": \".run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\",\n            \"catalog_location\": \".catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"\",\n        \"parameters_file\": \"\",\n        \"configuration_file\": \"examples/configs/fs-run_log.yaml\",\n        \"tag\": \"\",\n        \"run_id\": \"blocking-shaw-0538\",\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"simple\",\n            \"name\": \"\",\n            \"description\": \"\",\n            \"steps\": {\n                \"simple\": {\n                    \"type\": \"task\",\n                    \"name\": \"simple\",\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1,\n                    \"command\": \"examples.concepts.simple.simple_function\",\n                    \"command_type\": \"python\",\n                    \"node_name\": \"simple\"\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre> <p>All the run logs are stored in .run_log_store with the filename being the <code>run_id</code>.</p> <pre><code>&gt;&gt;&gt; tree .run_log_store\n.run_log_store\n\u2514\u2500\u2500 blocking-shaw-0538.json\n\n1 directory, 1 file\n</code></pre>"},{"location":"configurations/run-log/#chunked-fs","title":"chunked-fs","text":"<p>Chunked file system is similar to the <code>file-system</code> but stores concents of the run log that have concurrency blocks in separate files.</p>"},{"location":"configurations/run-log/#configuration_2","title":"Configuration","text":"<pre><code>run_log_store:\n  type: chunked-fs\n  config:\n    log_folder: # defaults to  \".run_log_store\"\n</code></pre> Configurationsdk pipelineRun logfolder structure <p>Assumed to be present at <code>examples/configs/chunked-fs-run_log.yaml</code></p> <pre><code>run_log_store:\n  type: chunked-fs\n</code></pre> <p>The configuration can be provided dynamically by setting the environment variable <code>runnable_CONFIGURATION_FILE</code>.</p> <p>Executing the pipeline with:</p> <p><code>runnable_CONFIGURATION_FILE=examples/configs/chunked-fs-run_log.yaml python examples/concepts/simple.py</code></p> <pre><code>\"\"\"\nA simple pipeline with a simple function that just prints \"Hello World!\".\n\nRun this pipeline by:\n    python examples/concepts/simple.py\n\"\"\"\n\nfrom runnable import Pipeline, PythonTask\n\n\ndef simple_function():\n    \"\"\"\n    A simple function that just prints \"Hello World!\".\n    \"\"\"\n    print(\"Hello World!\")\n\n\ndef main():\n    simple_task = PythonTask(\n        name=\"simple\",\n        function=simple_function,\n        terminate_with_success=True,\n    )\n\n    pipeline = Pipeline(\n        steps=[simple_task],\n        add_terminal_nodes=True,\n    )\n\n    pipeline.execute()  # (1)\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>The structure of the run log is detailed in concepts.</p> RunLog.jsonStepLog-simple-1706852981689005000.json <p>Stores only the metadata of the run log. The contents of this are safe for concurrent executions.</p> <pre><code>{\n    \"run_id\": \"pleasant-lamarr-0549\",\n    \"dag_hash\": \"\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {},\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"overrides\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"chunked-fs\",\n            \"service_type\": \"run_log_store\",\n            \"log_folder\": \".run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\",\n            \"catalog_location\": \".catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"\",\n        \"parameters_file\": \"\",\n        \"configuration_file\": \"examples/configs/chunked-fs-run_log.yaml\",\n        \"tag\": \"\",\n        \"run_id\": \"pleasant-lamarr-0549\",\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"simple\",\n            \"name\": \"\",\n            \"description\": \"\",\n            \"steps\": {\n                \"simple\": {\n                    \"type\": \"task\",\n                    \"name\": \"simple\",\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1,\n                    \"command\": \"examples.concepts.simple.simple_function\",\n                    \"command_type\": \"python\",\n                    \"node_name\": \"simple\"\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre> <p>Contains only the information of the single step <code>simple</code>. The name of the file follows the pattern:</p> <p><code>StepLog-&lt;Step name&gt;-&lt;timestamp&gt;.json</code>. The timestamp allows runnable to infer the order of execution of the steps.</p> <pre><code>{\n    \"name\": \"simple\",\n    \"internal_name\": \"simple\",\n    \"status\": \"SUCCESS\",\n    \"step_type\": \"task\",\n    \"message\": \"\",\n    \"mock\": false,\n    \"code_identities\": [\n        {\n            \"code_identifier\": \"39cd98770cb2fd6994d8ac08ae4c5506e5ce694a\",\n            \"code_identifier_type\": \"git\",\n            \"code_identifier_dependable\": true,\n            \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n            \"code_identifier_message\": \"\"\n        }\n    ],\n    \"attempts\": [\n        {\n            \"attempt_number\": 1,\n            \"start_time\": \"2024-02-02 05:49:41.697142\",\n            \"end_time\": \"2024-02-02 05:49:41.702983\",\n            \"duration\": \"0:00:00.005841\",\n            \"status\": \"SUCCESS\",\n            \"message\": \"\",\n            \"parameters\": {}\n        }\n    ],\n    \"user_defined_metrics\": {},\n    \"branches\": {},\n    \"data_catalog\": [\n        {\n            \"name\": \"simple.execution.log\",\n            \"data_hash\": \"03ba204e50d126e4674c005e04d82e84c21366780af1f43bd54a37816b6ab340\",\n            \"catalog_relative_path\": \"pleasant-lamarr-0549/simple.execution.log\",\n            \"catalog_handler_location\": \".catalog\",\n            \"stage\": \"put\"\n        }\n    ]\n}\n</code></pre> <p>All the run logs are stored in .run_log_store with the directory name being the <code>run_id</code>.</p> <p>Instead of storing a single <code>json</code> file, the contents are stored in the folder by the name of the <code>`run_id</code>.</p> <pre><code>.run_log_store\n\u2514\u2500\u2500 pleasant-lamarr-0549\n    \u251c\u2500\u2500 RunLog.json\n    \u251c\u2500\u2500 StepLog-simple-1706852981689005000.json\n    \u2514\u2500\u2500 StepLog-success-1706852981779002000.json\n\n2 directories, 3 files\n</code></pre>"},{"location":"configurations/secrets/","title":"Secrets","text":"<p>runnable provides an interface to secrets managers via the API.</p> <p>Please refer to Secrets in concepts for more information.</p>"},{"location":"configurations/secrets/#do-nothing","title":"do-nothing","text":"<p>A no-op implementation of a secret manager. This is useful when you do not have need for secrets in your application.</p>"},{"location":"configurations/secrets/#configuration","title":"configuration","text":"<pre><code>secrets:\n  type: do-nothing\n</code></pre> <p>Note that this is the default configuration if nothing is specified.</p>"},{"location":"configurations/secrets/#environment_secret_manager","title":"Environment Secret Manager","text":"<p>A secrets manager to access secrets from environment variables. Many cloud based executors, especially K8's, have capabilities to send in secrets as environment variables and this secrets provider could used in those environments.</p>"},{"location":"configurations/secrets/#configuration_1","title":"Configuration","text":"<pre><code>secrets:\n  type: env-secrets-manager\n  config:\n    prefix: \"\" # default value\n    suffix: \"\" # default value\n</code></pre> <p>Use <code>suffix</code> and <code>prefix</code> the uniquely identify the secrets. The actual key while calling the secrets manager via the API, <code>get_secret(secret_key)</code> is <code>&lt;prefix&gt;&lt;secret_key&gt;&lt;suffix&gt;</code>.</p>"},{"location":"configurations/secrets/#example","title":"Example","text":"PipelineDefault ConfigurationPrefixed and Suffixed Configuration <p>Below is a simple pipeline to demonstrate the use of secrets.</p> <p>The configuration file to use can be dynamically specified via the environment variable <code>runnable_CONFIGURATION_FILE</code>.</p> <p>The example can be found in <code>examples/secrets_env.py</code></p> <pre><code>\n</code></pre> <p>We can execute the pipeline using this configuration by: <code>secret=\"secret_value\" runnable_CONFIGURATION_FILE=examples/configs/secrets-env-default.yaml python examples/secrets_env.py</code></p> <p>The configuration file is located at <code>examples/configs/secrets-env-default.yaml</code></p> <pre><code>secrets:\n  type: env-secrets-manager\n</code></pre> <p>We can execute the pipeline using this configuration by: <code>runnable_secret=\"secret_value\" runnable_CONFIGURATION_FILE=examples/configs/secrets-env-ps.yaml python examples/secrets_env.py</code></p> <p>The configuration file is located at <code>examples/configs/secrets-env-ps.yaml</code></p> <pre><code>secrets:\n  type: env-secrets-manager\n  config:\n    prefix: \"runnable_\"\n</code></pre>"},{"location":"configurations/secrets/#dotenv","title":"dotenv","text":"<p><code>.env</code> files are routinely used to provide configuration parameters and secrets during development phase. runnable can dotenv files as a secret store and can surface them to tasks.</p>"},{"location":"configurations/secrets/#configuration_2","title":"Configuration","text":"<pre><code>secrets:\n  type: dotenv\n  config:\n    location: .env # default value\n</code></pre> <p>The format of the <code>.env</code> file is <code>key=value</code> pairs. Any content after <code>#</code> is considered as a comment and will be ignored. Using <code>export</code> or <code>set</code>, case insensitive, as used for shell scripts are allowed.</p>"},{"location":"configurations/secrets/#example_1","title":"Example","text":".env fileExample configurationPipeline in python <p>Assumed to be present at <code>examples/secrets.env</code></p> <pre><code>\n</code></pre> <ol> <li>Shell scripts style are supported.</li> <li>Key value based format is also supported.</li> </ol> <p>Configuration to use the dotenv format file.</p> <p>Assumed to be present at <code>examples/configs/dotenv.yaml</code></p> <pre><code>secrets:\n  type: dotenv # (1)\n  config:\n    location: examples/secrets.env # (2)\n</code></pre> <ol> <li>Use dotenv secrets manager.</li> <li>Location of the dotenv file, defaults to <code>.env</code> in project root.</li> </ol> <p>The example is present in <code>examples/secrets.py</code></p> <pre><code>\n</code></pre> <ol> <li>The key of the secret that you want to retrieve.</li> </ol>"},{"location":"configurations/executors/argo/","title":"argo workflows","text":"<p>Argo workflows is a powerful container orchestration framework for Kubernetes and it can run on any Kubernetes environment.</p> <p>runnable will transpile pipeline definition to argo specification during the pipeline execution which you can then upload to the cluster either manually or via CICD (recommended).</p> <ul> <li> Execute the pipeline in any cloud environment.</li> <li> Massively scalable.</li> <li> Ability to provide specialized compute environments for different steps of the pipeline.</li> <li> Expects a mature cloud kubernetes environment and expertise.</li> </ul> <p>runnable provides sensible defaults to most of the configuration variables but it is highly advised to get inputs from infrastructure teams or ML engineers in defining the configuration.</p>"},{"location":"configurations/executors/argo/#configuration","title":"Configuration","text":"<p>Only <code>image</code> is the required parameter. Please refer to the note on containers on building images.</p> <pre><code>executor:\n  type: argo\n  config:\n    name:\n    annotations:\n    labels:\n    namespace:\n    image: &lt;required&gt;\n    pod_gc:\n    max_workflow_duration_in_seconds:\n    node_selector:\n    parallelism:\n    service_account_name:\n    resources:\n    retry_strategy:\n    max_step_duration_in_seconds:\n    tolerations:\n    image_pull_policy:\n    expose_parameters_as_inputs:\n    output_file:\n    secrets_from_k8s:\n    persistent_volumes:\n</code></pre>"},{"location":"configurations/executors/argo/#defaults","title":"Defaults","text":"<p>Default values</p> <p>Ensure that these default values fit your needs to avoid unexpected behavior.</p> Parameter Default Argo Field name <code>runnable-dag-</code> <code>generateName</code> annotations <code>{}</code> <code>annotations</code> of <code>metadata</code> labels <code>{}</code> <code>labels</code> pod_gc <code>OnPodCompletion</code> <code>podGC</code> service_account_name <code>None</code> <code>serviceAccountName</code> of spec secrets_from_k8s <code>[]</code> List expose_parameters_as_inputs True NA max_workflow_duration_in_seconds 86400 seconds = 1 day <code>activeDeadlineSeconds</code> of spec node_selector <code>{}</code> <code>nodeSelector</code> parallelism <code>None</code> <code>parallelism</code> of spec resources limits: 1Gi of memory and 250m of CPU <code>resources</code> of the container retry_strategy <code>None</code> <code>retryStrategy</code> of the spec max_step_duration_in_seconds 60 * 60 * 2 = 2 hours <code>activeDeadlineSeconds</code> of container tolerations <code>{}</code> <code>tolerations</code> of the container image_pull_policy <code>\"\"</code> <code>imagePullPolicy</code> of the container persistent_volumes <code>None</code> '''"},{"location":"configurations/executors/argo/#notes","title":"Notes","text":""},{"location":"configurations/executors/argo/#the_following_parameters_cannot_be_overridden_at_individual_step_level","title":"The following parameters cannot be overridden at individual step level.","text":"<ul> <li><code>name</code>: Using a name provides a logical way to organize pipelines.</li> <li><code>pod_gc</code>: Defines the pod garbage collection strategy. Setting to <code>OnPodCompletion</code> will mark the pod for garbage collection immediately after completion, either success or failure.</li> <li><code>annotations</code>: Unstructured key value pairs that can be added to K8's resources.</li> <li><code>labels</code>: Dictionary of labels to apply to all the objects of the workflow.</li> <li><code>service_account_name</code>: Name of the service account to be used to run the workflow.</li> <li><code>max_workflow_duration_in_seconds</code>: The default value is 1 day for the completion of the workflow. Kubernetes will actively try to fail the pipeline after this duration.</li> </ul> <p>Volumes</p> <p>As the persistent volumes are attached to the pod at specified path, it allows for <code>file-system</code> based catalog or run log store to work without any modifications.</p> <p>For example, <code>/mnt</code> folder can be used as the <code>parent</code> directory for file-system run log store and catalog.</p> <ul> <li><code>persistent_volumes</code>: Persistent volumes from the underlying Kubernetes cluster to be assigned to the pods. You can attach multiple persistent volumes to the pods as long as there are no clashes with mount paths.</li> </ul>"},{"location":"configurations/executors/argo/#example","title":"Example:","text":"<p>The following adds the volume <code>runnable-volume</code> to every container of the workflow at <code>/mnt</code></p> <pre><code>persistent_volumes:\n  - name: runnable-volume\n    mount_path: /mnt\n</code></pre> <ul> <li><code>secrets_from_k8s</code>: List of secrets from the Kubernetes cluster to be exposed as environment variables.</li> </ul> <p>Secrets</p> <p>As the secrets are exposed as environment variables, the application can then be configured using <code>env-secrets-manager</code> as a convenient way to access K8's secrets.</p>"},{"location":"configurations/executors/argo/#example_1","title":"Example:","text":"<p>In the example below, the secret <code>connection_string</code> from <code>postgres</code> secret of K8's is exposed as <code>connection_string</code> to the container.</p> <pre><code>secrets_from_k8s:\n  - environment_variable: connection_string\n    secret_name: postgres\n    secret_key: connection_string\n</code></pre> <ul> <li><code>expose_parameters_as_inputs</code>: Expose parameters of simple python data types (str, int, float) as inputs to the workflow. This allows for changing the parameters at runtime.</li> </ul>"},{"location":"configurations/executors/argo/#example_2","title":"Example:","text":"Initial Parameterspipelineargo workflowRun SubmissionStep Log <p>Assumed to present at <code>examples/concepts/parameters.yaml</code></p> <pre><code>spam: \"Hello\"\neggs:\n  ham: \"Yes, please!!\"\n</code></pre> <p>Execute the pipeline as: <code>runnable execute -f examples/concepts/task_shell_parameters.yaml  -p examples/concepts/parameters.yaml -c examples/configs/argo-config.yaml</code></p> <pre><code>dag:\n  description: |\n    This is a sample pipeline to show the parameter flow for shell types.\n\n    The step \"access initial\" just displays the initial parameters defined in examples/concepts/parameters.yaml\n    The step modify_initial updates the parameters and sets them back as environment variables.\n    The step display_again displays the updated parameters from modify_initial and updates them.\n\n    You can run this pipeline as:\n      runnable execute -f examples/concepts/task_shell_parameters.yaml  -p examples/concepts/parameters.yaml\n\n  start_at: access initial\n  steps:\n    access initial:\n      type: task\n      command_type: shell\n      command: |\n        env\n      next: modify initial\n    modify initial:\n      type: task\n      command_type: shell\n      returns:\n        - name: spam\n          kind: json\n        - name: eggs\n          kind: json\n      command: |\n        export spam='World'\n        export eggs='{\"ham\": \"No, Thank you!!\"}'\n      next: display again\n    display again:\n      type: task\n      command_type: shell\n      returns:\n        - name: spam\n          kind: json\n        - name: eggs\n          kind: json\n\n      command: |\n        env &amp;&amp; \\\n        export spam='Universe' &amp;&amp; \\\n        export eggs='{\"ham\": \"Maybe, one more..\"}'\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p>The initial parameter of <code>spam</code> is exposed and defaulted to <code>Hello</code> as per the parameters file. The <code>run_id</code> is also a configurable run time parameter.</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: runnable-dag-\n  annotations: {}\n  labels: {}\nspec:\n  activeDeadlineSeconds: 172800\n  entrypoint: runnable-dag\n  podGC:\n    strategy: OnPodCompletion\n  retryStrategy:\n    limit: '0'\n    retryPolicy: Always\n    backoff:\n      duration: '120'\n      factor: 2\n      maxDuration: '3600'\n  serviceAccountName: default-editor\n  templates:\n    - name: runnable-dag\n      failFast: true\n      dag:\n        tasks:\n          - name: access-initial-task-cybkoa\n            template: access-initial-task-cybkoa\n            depends: ''\n          - name: modify-initial-task-6lka8g\n            template: modify-initial-task-6lka8g\n            depends: access-initial-task-cybkoa.Succeeded\n          - name: display-again-task-6d1ofy\n            template: display-again-task-6d1ofy\n            depends: modify-initial-task-6lka8g.Succeeded\n          - name: success-success-igw6ct\n            template: success-success-igw6ct\n            depends: display-again-task-6d1ofy.Succeeded\n    - name: access-initial-task-cybkoa\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - '{{workflow.parameters.run_id}}'\n          - access%initial\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/task_shell_parameters.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n          - --parameters-file\n          - examples/concepts/parameters.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: ''\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n        env:\n          - name: runnable_PRM_spam\n            value: '{{workflow.parameters.spam}}'\n    - name: modify-initial-task-6lka8g\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - '{{workflow.parameters.run_id}}'\n          - modify%initial\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/task_shell_parameters.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n          - --parameters-file\n          - examples/concepts/parameters.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: ''\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n    - name: display-again-task-6d1ofy\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - '{{workflow.parameters.run_id}}'\n          - display%again\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/task_shell_parameters.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n          - --parameters-file\n          - examples/concepts/parameters.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: ''\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n    - name: success-success-igw6ct\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - '{{workflow.parameters.run_id}}'\n          - success\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/task_shell_parameters.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n          - --parameters-file\n          - examples/concepts/parameters.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: ''\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n  templateDefaults:\n    activeDeadlineSeconds: 7200\n    timeout: 10800s\n  arguments:\n    parameters:\n      - name: spam\n        value: Hello\n      - name: run_id\n        value: '{{workflow.uid}}'\n  volumes:\n    - name: executor-0\n      persistentVolumeClaim:\n        claimName: runnable-volume\n</code></pre> <p> argo workflows UI exposing the parameters </p> <p>The <code>step log</code> of the first step, <code>access initial</code> receives the value of the parameter <code>spam</code> as <code>No-Hello</code> from the UI submission.</p> <pre><code>{\n  \"name\": \"access initial\",\n  \"internal_name\": \"access initial\",\n  \"status\": \"SUCCESS\",\n  \"step_type\": \"task\",\n  \"message\": \"\",\n  \"mock\": false,\n  \"code_identities\": [\n      {\n          \"code_identifier\": \"39cd98770cb2fd6994d8ac08ae4c5506e5ce694a\",\n          \"code_identifier_type\": \"git\",\n          \"code_identifier_dependable\": true,\n          \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n          \"code_identifier_message\": \"\"\n      }\n  ],\n  \"attempts\": [\n      {\n          \"attempt_number\": 1,\n          \"start_time\": \"2024-02-01 14:44:06.023052\",\n          \"end_time\": \"2024-02-01 14:44:06.031187\",\n          \"duration\": \"0:00:00.008135\",\n          \"status\": \"SUCCESS\",\n          \"message\": \"\",\n          \"parameters\": {\n              \"spam\": \"No-Hello\",\n              \"eggs\": {\n                  \"ham\": \"Yes, please!!\"\n              }\n          }\n      }\n  ],\n  \"user_defined_metrics\": {},\n  \"branches\": {},\n  \"data_catalog\": []\n}\n</code></pre>"},{"location":"configurations/executors/argo/#the_following_parameters_can_be_configured_at_step_level_using_overrides","title":"The following parameters can be configured at step level using overrides:","text":"<ul> <li>parallelism: Controls the number of parallel tasks that can happen at once. By default, there is no limit either for <code>parallel</code> or <code>map</code> nodes. To control the parallelism of a <code>map</code> or <code>parallel</code>, provide an <code>override</code> in the overrides section.</li> </ul> <p>The parallelism constraint only applies to the step, any nested steps within the step have the <code>default</code> parallelism.</p>"},{"location":"configurations/executors/argo/#example_3","title":"Example:","text":"Without OverrideWith Override <p>By default, there is no limit on the number of parallel tasks that can be run.</p> ConfigurationPipelineWorkflow execution <p>The argo config is a very basic configuration.</p> <pre><code>executor:\n  type: \"argo\" # (1)\n  config:\n    image: runnable:demo # (2)\n    service_account_name: default-editor\n    persistent_volumes: # (3)\n      - name: runnable-volume\n        mount_path: /mnt\n\nrun_log_store: # (4)\n  type: file-system\n  config:\n    log_folder: /mnt/run_log_store\n\ncatalog:\n  type: do-nothing\n\nsecrets:\n  type: do-nothing\n\nexperiment_tracker:\n  type: do-nothing\n</code></pre> <p>This example is the same as detailed in map.</p> <pre><code>dag:\n  description: |\n    This pipeline demonstrates the usage of map state to dynamically\n    execute workflows in parallel.\n\n    The step \"chunk files\" identifies the total number of batches to\n    execute in parallel and sets the parameters\n     - start_index of every batch to process, chunks\n     - number of files to process per batch, stride.\n\n    The step \"iterate and execute\" iterates on \"chunks\" and the\n    parameter name per chunk is set to be \"start_index\".\n\n    Run this example by:\n      runnable execute -f examples/concepts/map.yaml\n  start_at: chunk files\n  steps:\n    chunk files:\n      type: task\n      command_type: python\n      command: \"examples.concepts.map.chunk_files\"\n      returns:\n        - name: stride\n          kind: json\n        - name: chunks\n          kind: json\n      next: iterate and execute\n    iterate and execute:\n      type: map\n      iterate_on: chunks\n      iterate_as: start_index\n      next: success\n      branch:\n        start_at: execute\n        steps:\n          execute:\n            type: task\n            command_type: python\n            command: \"examples.concepts.map.process_chunk\"\n            next: success\n          success:\n            type: success\n          fail:\n            type: fail\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p>From the <code>gant</code> chart representation of the workflow execution, we can see that all the <code>execute_task</code> tasks execute simultaneously.</p> <p> argo workflows UI exposing the parameters </p> ConfigurationPipelineWorkflow execution <p>While the global configuration has no limit on parallelism, any task using <code>sequential</code> override would run sequentially.</p> <pre><code>executor:\n  type: \"argo\" # (1)\n  config:\n    image: $argo_docker_image # (2)\n    service_account_name: default-editor\n    persistent_volumes: # (3)\n      - name: runnable-volume\n        mount_path: /mnt\n    overrides:\n      sequential:\n        parallelism: 1\n\nrun_log_store: # (4)\n  type: chunked-fs\n  config:\n    log_folder: /mnt/run_log_store\n\ncatalog:\n  type: do-nothing\n\nsecrets:\n  type: do-nothing\n\nexperiment_tracker:\n  type: do-nothing\n</code></pre> <p>The pipeline defined here is nearly the same as detailed in map with the only exception in lines 25-26 which use the <code>sequential</code> override.</p> <pre><code>dag:\n  description: |\n    This pipeline demonstrates the usage of map state to dynamically\n    execute workflows in parallel.\n\n    The step \"chunk files\" identifies the total number of batches to\n    execute in parallel and sets the parameters\n     - start_index of every batch to process, chunks\n     - number of files to process per batch, stride.\n\n    The step \"iterate and execute\" iterates on \"chunks\" and the\n    parameter name per chunk is set to be \"start_index\".\n  start_at: chunk files\n  steps:\n    chunk files:\n      type: task\n      command_type: python\n      command: \"examples.concepts.map.chunk_files\"\n      next: iterate and execute\n    iterate and execute:\n      type: map\n      iterate_on: chunks\n      iterate_as: start_index\n      next: success\n      overrides:\n        argo: sequential\n      branch:\n        start_at: execute\n        steps:\n          execute:\n            type: task\n            command_type: python\n            command: \"examples.concepts.map.process_chunk\"\n            next: success\n          success:\n            type: success\n          fail:\n            type: fail\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p>The workflow execution from the <code>gant</code> chart shows the execution of <code>execute task</code> is sequential instead of parallel as seen in the default.</p> <p> argo workflows UI exposing the parameters </p> <ul> <li> <p><code>node_selector</code> and <code>tolerations</code>: Gives you the ability to selectively choose a node to run your task. See more information about node selector and tolerations for more information.</p> </li> <li> <p>resources: Has the same structure as K8's manifest. To use a GPU, you can mention the maximum number of GPUs in <code>limits</code> section. The default value is 1Gi of memory and 250m of cpu with no GPU. To override the resources for a specific task, use <code>overrides</code> section.</p> </li> </ul> <p>Example:</p> Configurationpipeline Argo configuration with override<pre><code>executor:\ntype: argo\nconfig:\n    image: &lt;required&gt;\noverrides:\n    BiggerMachine:\n      requests:\n        memory: 4Gi\n        cpu: 4\n</code></pre> <p>In this example, the <code>run on bigger machine</code> will run on a node that can provide 4 CPU cores and 4GB memory.</p> <pre><code>dag:\n  steps:\n    run on bigger machine:\n      type: task\n      override:\n        argo: BiggerMachine\n</code></pre> <ul> <li> <p><code>max_step_duration_in_seconds</code>: Defines the maximum amount of time a task can take for completion. The default value is 2 hours and an additional 1 hour is given for <code>timeout</code>.</p> </li> <li> <p><code>retry_strategy</code>: Defines the strategy to retry in case of failure. The default retry policy is <code>Always</code>, i.e in case of failure in execution of task or any other infrastructure failures. Please see argo workflows documentation for more information. As with other parameters, this can be overridden for individual task nodes.</p> </li> <li> <p><code>image_pull_policy</code>: Defaults to not setting the field. This behavior does not pull the image for any tag other than <code>latest</code></p> </li> </ul>"},{"location":"configurations/executors/argo/#compatibility","title":"Compatibility","text":"<p>As argo workflows is a cloud based executor, not all the services are compatible with it.</p> <ul> <li> <p>Run log: All steps of the workflow need access to the run log as such <code>buffered</code> run log store would not be compatible. <code>file-system</code> based run log store is compatible by using volumes that are available for all the steps of the workflow, eg. persistent volumes.</p> </li> <li> <p>catalog: Any catalog service that is available for all the steps of the workflow is compatible. <code>file-system</code> is compatible as long as the catalog store is mounted as a volume similar to the run log store.</p> </li> <li> <p>secrets: It is possible to use <code>dotenv</code> secrets manager as long as the file is available during the execution of the task. We highly recommend <code>.env</code> files to be excluded from the code versioning tools. We recommend using <code>secrets_from_k8s</code> in the configuration.</p> </li> </ul>"},{"location":"configurations/executors/argo/#example_4","title":"Example","text":"configurationpython SDKyamlArgo workflow definitionScreenshotsRun Log <p>Assumed to be present at <code>examples/configs/argo-config.yaml</code></p> <p>The docker image is a variable and dynamically set during execution.</p> <pre><code>executor:\n  type: \"argo\" # (1)\n  config:\n    image: runnable:demo # (2)\n    service_account_name: default-editor\n    persistent_volumes: # (3)\n      - name: runnable-volume\n        mount_path: /mnt\n\nrun_log_store: # (4)\n  type: file-system\n  config:\n    log_folder: /mnt/run_log_store\n\ncatalog:\n  type: do-nothing\n\nsecrets:\n  type: do-nothing\n\nexperiment_tracker:\n  type: do-nothing\n</code></pre> <ol> <li>Use <code>argo</code> executor type to execute the pipeline.</li> <li>By default, all the tasks are executed in the docker image . Please refer to building docker images</li> <li>Mount the persistent volume <code>runnable-volume</code> to all the containers as <code>/mnt</code>.</li> <li>Store the run logs in the file-system. As all containers have access to <code>runnable-volume</code> as <code>/mnt</code>. We use that to mounted folder as run log store.</li> </ol> <p>Running the SDK defined pipelines for any container based executions happens in multi-stage process.</p> <ol> <li>Generate the <code>yaml</code> definition file by: <code>runnable_CONFIGURATION_FILE=examples/configs/argo-config.yaml python examples/concepts/simple.py</code></li> <li>Build the docker image with yaml definition in it, called runnable:latest in current example.</li> <li>Execute the pipeline via the runnable CLI, <code>runnable_VAR_argo_docker_image=runnable:latest  runnable execute -f runnable-pipeline.yaml -c examples/configs/argo-config.yaml</code></li> </ol> <pre><code>\"\"\"\nA simple pipeline with a simple function that just prints \"Hello World!\".\n\nRun this pipeline by:\n    python examples/concepts/simple.py\n\"\"\"\n\nfrom runnable import Pipeline, PythonTask\n\n\ndef simple_function():\n    \"\"\"\n    A simple function that just prints \"Hello World!\".\n    \"\"\"\n    print(\"Hello World!\")\n\n\ndef main():\n    simple_task = PythonTask(\n        name=\"simple\",\n        function=simple_function,\n        terminate_with_success=True,\n    )\n\n    pipeline = Pipeline(\n        steps=[simple_task],\n        add_terminal_nodes=True,\n    )\n\n    pipeline.execute()  # (1)\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <ol> <li>You can provide a configuration file dynamically by using the environment variable <code>runnable_CONFIGURATION_FILE</code>. Please see SDK for more details.</li> </ol> <p>For yaml based definitions, the execution order is to:</p> <ol> <li>Build the docker image with the yaml definition in it, called runnable:latest in current example.</li> <li>Execute the pipeline via the runnable CLI: <code>runnable_VAR_argo_docker_image=runnable:latest runnable execute -f examples/concepts/simple.yaml -c examples/configs/argo-config.yaml</code></li> </ol> <pre><code>dag:\n  description: |\n    A simple pipeline with a simple function that just prints \"Hello World!\".\n\n    Run this pipeline by:\n      runnable execute -f  examples/concepts/simple.yaml\n  start_at: simple\n  steps:\n    simple:\n      type: task\n      command: \"examples.concepts.simple.simple_function\"\n      command_type: python\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: runnable-dag-\n  annotations: {}\n  labels: {}\nspec:\n  activeDeadlineSeconds: 172800\n  entrypoint: runnable-dag\n  podGC:\n    strategy: OnPodCompletion\n  retryStrategy:\n    limit: \"0\"\n    retryPolicy: Always\n    backoff:\n      duration: \"120\"\n      factor: 2\n      maxDuration: \"3600\"\n  templates:\n    - name: runnable-dag\n      failFast: true\n      dag:\n        tasks:\n          - name: simple-task-6mn2ll\n            template: simple-task-6mn2ll\n            depends: \"\"\n          - name: success-success-0uvo9r\n            template: success-success-0uvo9r\n            depends: simple-task-6mn2ll.Succeeded\n    - name: simple-task-6mn2ll\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - simple\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/simple.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n    - name: success-success-0uvo9r\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - success\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/simple.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n  templateDefaults:\n    activeDeadlineSeconds: 7200\n    timeout: 10800s\n  arguments:\n    parameters:\n      - name: run_id\n        value: \"{{workflow.uid}}\"\n  volumes:\n    - name: executor-0\n      persistentVolumeClaim:\n        claimName: runnable-volume\n</code></pre> <p> argo workflows UI showing the pipeline </p> <p> argo workflows UI showing the logs </p> <p>The run log structure is the same as any other executor. Any failed executions in the workflow can be executed in <code>local</code> by providing this run log and any catalog files.</p> <pre><code>{\n  \"run_id\": \"bb96359d-74f0-4837-90e3-94aed85dbb8f\",\n  \"dag_hash\": \"d467805d7f743d459a6abce95bedbfc6c1ecab67\",\n  \"use_cached\": false,\n  \"tag\": \"\",\n  \"original_run_id\": \"\",\n  \"status\": \"SUCCESS\",\n  \"steps\": {\n      \"simple\": {\n          \"name\": \"simple\",\n          \"internal_name\": \"simple\",\n          \"status\": \"SUCCESS\",\n          \"step_type\": \"task\",\n          \"message\": \"\",\n          \"mock\": false,\n          \"code_identities\": [\n              {\n                  \"code_identifier\": \"39cd98770cb2fd6994d8ac08ae4c5506e5ce694a\",\n                  \"code_identifier_type\": \"git\",\n                  \"code_identifier_dependable\": true,\n                  \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                  \"code_identifier_message\": \"\"\n              }\n          ],\n          \"attempts\": [\n              {\n                  \"attempt_number\": 1,\n                  \"start_time\": \"2024-01-31 06:43:01.937309\",\n                  \"end_time\": \"2024-01-31 06:43:01.940862\",\n                  \"duration\": \"0:00:00.003553\",\n                  \"status\": \"SUCCESS\",\n                  \"message\": \"\",\n                  \"parameters\": {}\n              }\n          ],\n          \"user_defined_metrics\": {},\n          \"branches\": {},\n          \"data_catalog\": []\n      },\n      \"success\": {\n          \"name\": \"success\",\n          \"internal_name\": \"success\",\n          \"status\": \"SUCCESS\",\n          \"step_type\": \"success\",\n          \"message\": \"\",\n          \"mock\": false,\n          \"code_identities\": [\n              {\n                  \"code_identifier\": \"39cd98770cb2fd6994d8ac08ae4c5506e5ce694a\",\n                  \"code_identifier_type\": \"git\",\n                  \"code_identifier_dependable\": false,\n                  \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                  \"code_identifier_message\": \"\"\n              }\n          ],\n          \"attempts\": [\n              {\n                  \"attempt_number\": 1,\n                  \"start_time\": \"2024-01-31 06:43:26.537710\",\n                  \"end_time\": \"2024-01-31 06:43:26.544461\",\n                  \"duration\": \"0:00:00.006751\",\n                  \"status\": \"SUCCESS\",\n                  \"message\": \"\",\n                  \"parameters\": {}\n              }\n          ],\n          \"user_defined_metrics\": {},\n          \"branches\": {},\n          \"data_catalog\": []\n      }\n  },\n  \"parameters\": {},\n  \"run_config\": {\n      \"executor\": {\n          \"service_name\": \"argo\",\n          \"service_type\": \"executor\",\n          \"enable_parallel\": false,\n          \"overrides\": {},\n          \"image\": \"$argo_docker_image\",\n          \"expose_parameters_as_inputs\": true,\n          \"output_file\": \"argo-pipeline.yaml\",\n          \"name\": \"runnable-dag-\",\n          \"annotations\": {},\n          \"labels\": {},\n          \"namespace\": null,\n          \"activeDeadlineSeconds\": 172800,\n          \"nodeSelector\": null,\n          \"parallelism\": null,\n          \"branch_parallelism\": 0,\n          \"retryStrategy\": {\n              \"limit\": \"0\",\n              \"retryPolicy\": \"Always\",\n              \"backoff\": {\n                  \"duration\": \"120\",\n                  \"factor\": 2,\n                  \"maxDuration\": \"3600\"\n              }\n          },\n          \"max_step_duration_in_seconds\": 7200,\n          \"tolerations\": null,\n          \"image_pull_policy\": \"\",\n          \"service_account_name\": null,\n          \"secrets_from_k8s\": [],\n          \"persistent_volumes\": [\n              {\n                  \"name\": \"runnable-volume\",\n                  \"mount_path\": \"/mnt\"\n              }\n          ],\n          \"step_timeout\": 14400\n      },\n      \"run_log_store\": {\n          \"service_name\": \"file-system\",\n          \"service_type\": \"run_log_store\",\n          \"log_folder\": \"/mnt/run_log_store\"\n      },\n      \"secrets_handler\": {\n          \"service_name\": \"do-nothing\",\n          \"service_type\": \"secrets\"\n      },\n      \"catalog_handler\": {\n          \"service_name\": \"do-nothing\",\n          \"service_type\": \"catalog\"\n      },\n      \"experiment_tracker\": {\n          \"service_name\": \"do-nothing\",\n          \"service_type\": \"experiment_tracker\"\n      },\n      \"pipeline_file\": \"examples/concepts/simple.yaml\",\n      \"parameters_file\": null,\n      \"configuration_file\": \"examples/configs/argo-config.yaml\",\n      \"tag\": \"\",\n      \"run_id\": \"bb96359d-74f0-4837-90e3-94aed85dbb8f\",\n      \"variables\": {},\n      \"use_cached\": false,\n      \"original_run_id\": \"\",\n      \"dag\": {\n          \"start_at\": \"simple\",\n          \"name\": \"\",\n          \"description\": null,\n          \"steps\": {\n              \"simple\": {\n                  \"type\": \"task\",\n                  \"name\": \"simple\",\n                  \"next\": \"success\",\n                  \"on_failure\": \"\",\n                  \"overrides\": {},\n                  \"catalog\": null,\n                  \"max_attempts\": 1,\n                  \"command\": \"examples.concepts.simple.simple_function\",\n                  \"command_type\": \"python\",\n                  \"node_name\": \"simple\"\n              },\n              \"success\": {\n                  \"type\": \"success\",\n                  \"name\": \"success\"\n              },\n              \"fail\": {\n                  \"type\": \"fail\",\n                  \"name\": \"fail\"\n              }\n          }\n      },\n      \"dag_hash\": \"d467805d7f743d459a6abce95bedbfc6c1ecab67\",\n      \"execution_plan\": \"chained\"\n  }\n}\n</code></pre>"},{"location":"configurations/executors/argo/#nesting","title":"Nesting","text":"<p>runnable compiled argo workflows support deeply nested workflows.</p>"},{"location":"configurations/executors/argo/#example_5","title":"Example","text":"Nested workflowConfigurationArgo workflowIn argo UI <p>This is the same example as shown in nested.</p> <pre><code>dag:\n  description: |\n    An example of nesting pipelines within pipelines.\n\n    Run this pipeline by:\n      runnable execute -f examples/concepts/nesting.yaml\n\n  start_at: generate_list\n  steps:\n    generate_list:\n      type: task\n      command_type: shell\n      returns:\n        - name: array\n          kind: json\n      command: export array=\"[0, 1]\"\n      next: outer most map\n    outer most map:\n      type: map\n      iterate_on: array\n      iterate_as: xarg\n      next: success\n      branch:\n        start_at: nested parallel\n        steps:\n          nested parallel:\n            type: parallel\n            next: success\n            branches:\n              a:\n                start_at: inner most map\n                steps:\n                  inner most map:\n                    type: map\n                    iterate_on: array\n                    iterate_as: yarg\n                    next: success\n                    branch:\n                      start_at: executable\n                      steps:\n                        executable:\n                          type: stub\n                          next: success\n                        success:\n                          type: success\n                        fail:\n                          type: fail\n                  success:\n                    type: success\n                  fail:\n                    type: fail\n              b:\n                start_at: inner most map\n                steps:\n                  inner most map:\n                    type: map\n                    iterate_on: array\n                    iterate_as: yarg\n                    next: success\n                    branch:\n                      start_at: executable\n                      steps:\n                        executable:\n                          type: stub\n                          next: success\n                        success:\n                          type: success\n                        fail:\n                          type: fail\n                  success:\n                    type: success\n                  fail:\n                    type: fail\n          success:\n            type: success\n          fail:\n            type: fail\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p>Assumed to be present at <code>examples/configs/argo-config.yaml</code></p> <p>The docker image is a variable and dynamically set during execution.</p> <pre><code>executor:\n  type: \"argo\" # (1)\n  config:\n    image: runnable:demo # (2)\n    service_account_name: default-editor\n    persistent_volumes: # (3)\n      - name: runnable-volume\n        mount_path: /mnt\n\nrun_log_store: # (4)\n  type: file-system\n  config:\n    log_folder: /mnt/run_log_store\n\ncatalog:\n  type: do-nothing\n\nsecrets:\n  type: do-nothing\n\nexperiment_tracker:\n  type: do-nothing\n</code></pre> <ol> <li>Use <code>argo</code> executor type to execute the pipeline.</li> <li>By default, all the tasks are executed in the docker image . Please refer to building docker images</li> <li>Mount the persistent volume <code>runnable-volume</code> to all the containers as <code>/mnt</code>.</li> <li>Store the run logs in the file-system. As all containers have access to <code>runnable-volume</code> as <code>/mnt</code>. We use that to mounted folder as run log store.</li> </ol> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: runnable-dag-\n  annotations: {}\n  labels: {}\nspec:\n  activeDeadlineSeconds: 172800\n  entrypoint: runnable-dag\n  retryStrategy:\n    limit: \"0\"\n    retryPolicy: Always\n    backoff:\n      duration: \"120\"\n      factor: 2\n      maxDuration: \"3600\"\n  serviceAccountName: default-editor\n  templates:\n    - name: inner-most-map-map-yeslqe-map\n      inputs:\n        parameters:\n          - name: xarg\n          - name: yarg\n      failFast: true\n      dag:\n        tasks:\n          - name: executable-stub-blnf25\n            template: executable-stub-blnf25\n            depends: \"\"\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n                - name: yarg\n                  value: \"{{inputs.parameters.yarg}}\"\n          - name: success-success-trvgst\n            template: success-success-trvgst\n            depends: executable-stub-blnf25.Succeeded\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n                - name: yarg\n                  value: \"{{inputs.parameters.yarg}}\"\n    - name: inner-most-map-map-yeslqe\n      inputs:\n        parameters:\n          - name: xarg\n      failFast: true\n      dag:\n        tasks:\n          - name: inner-most-map-map-yeslqe-fan-out\n            template: inner-most-map-map-yeslqe-fan-out\n            depends: \"\"\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n          - name: inner-most-map-map-yeslqe-map\n            template: inner-most-map-map-yeslqe-map\n            depends: inner-most-map-map-yeslqe-fan-out.Succeeded\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n                - name: yarg\n                  value: \"{{item}}\"\n            withParam: \"{{tasks.inner-most-map-map-yeslqe-fan-out.outputs.parameters.iterate-on}}\"\n          - name: inner-most-map-map-yeslqe-fan-in\n            template: inner-most-map-map-yeslqe-fan-in\n            depends: inner-most-map-map-yeslqe-map.Succeeded || inner-most-map-map-yeslqe-map.Failed\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n    - name: nested-parallel-parallel-wje1o4-outer-most-map-map-variable-placeholder-nested-parallel-a\n      inputs:\n        parameters:\n          - name: xarg\n      failFast: true\n      dag:\n        tasks:\n          - name: inner-most-map-map-yeslqe\n            template: inner-most-map-map-yeslqe\n            depends: \"\"\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n          - name: success-success-y1yr7v\n            template: success-success-y1yr7v\n            depends: inner-most-map-map-yeslqe.Succeeded\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n    - name: inner-most-map-map-b206p5-map\n      inputs:\n        parameters:\n          - name: xarg\n          - name: yarg\n      failFast: true\n      dag:\n        tasks:\n          - name: executable-stub-8ui1yv\n            template: executable-stub-8ui1yv\n            depends: \"\"\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n                - name: yarg\n                  value: \"{{inputs.parameters.yarg}}\"\n          - name: success-success-h4j0k9\n            template: success-success-h4j0k9\n            depends: executable-stub-8ui1yv.Succeeded\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n                - name: yarg\n                  value: \"{{inputs.parameters.yarg}}\"\n    - name: inner-most-map-map-b206p5\n      inputs:\n        parameters:\n          - name: xarg\n      failFast: true\n      dag:\n        tasks:\n          - name: inner-most-map-map-b206p5-fan-out\n            template: inner-most-map-map-b206p5-fan-out\n            depends: \"\"\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n          - name: inner-most-map-map-b206p5-map\n            template: inner-most-map-map-b206p5-map\n            depends: inner-most-map-map-b206p5-fan-out.Succeeded\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n                - name: yarg\n                  value: \"{{item}}\"\n            withParam: \"{{tasks.inner-most-map-map-b206p5-fan-out.outputs.parameters.iterate-on}}\"\n          - name: inner-most-map-map-b206p5-fan-in\n            template: inner-most-map-map-b206p5-fan-in\n            depends: inner-most-map-map-b206p5-map.Succeeded || inner-most-map-map-b206p5-map.Failed\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n    - name: nested-parallel-parallel-wje1o4-outer-most-map-map-variable-placeholder-nested-parallel-b\n      inputs:\n        parameters:\n          - name: xarg\n      failFast: true\n      dag:\n        tasks:\n          - name: inner-most-map-map-b206p5\n            template: inner-most-map-map-b206p5\n            depends: \"\"\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n          - name: success-success-dvma7h\n            template: success-success-dvma7h\n            depends: inner-most-map-map-b206p5.Succeeded\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n    - name: nested-parallel-parallel-wje1o4\n      inputs:\n        parameters:\n          - name: xarg\n      failFast: true\n      dag:\n        tasks:\n          - name: nested-parallel-parallel-wje1o4-fan-out\n            template: nested-parallel-parallel-wje1o4-fan-out\n            depends: \"\"\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n          - name: nested-parallel-parallel-wje1o4-outer-most-map-map-variable-placeholder-nested-parallel-a\n            template: nested-parallel-parallel-wje1o4-outer-most-map-map-variable-placeholder-nested-parallel-a\n            depends: nested-parallel-parallel-wje1o4-fan-out.Succeeded\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n          - name: nested-parallel-parallel-wje1o4-outer-most-map-map-variable-placeholder-nested-parallel-b\n            template: nested-parallel-parallel-wje1o4-outer-most-map-map-variable-placeholder-nested-parallel-b\n            depends: nested-parallel-parallel-wje1o4-fan-out.Succeeded\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n          - name: nested-parallel-parallel-wje1o4-fan-in\n            template: nested-parallel-parallel-wje1o4-fan-in\n            depends:\n              nested-parallel-parallel-wje1o4-outer-most-map-map-variable-placeholder-nested-parallel-a.Succeeded\n              ||\n              nested-parallel-parallel-wje1o4-outer-most-map-map-variable-placeholder-nested-parallel-a.Failed\n              ||\n              nested-parallel-parallel-wje1o4-outer-most-map-map-variable-placeholder-nested-parallel-b.Succeeded\n              ||\n              nested-parallel-parallel-wje1o4-outer-most-map-map-variable-placeholder-nested-parallel-b.Failed\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n    - name: outer-most-map-map-0ukhr5-map\n      inputs:\n        parameters:\n          - name: xarg\n      failFast: true\n      dag:\n        tasks:\n          - name: nested-parallel-parallel-wje1o4\n            template: nested-parallel-parallel-wje1o4\n            depends: \"\"\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n          - name: success-success-e4lb2k\n            template: success-success-e4lb2k\n            depends: nested-parallel-parallel-wje1o4.Succeeded\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{inputs.parameters.xarg}}\"\n    - name: outer-most-map-map-0ukhr5\n      failFast: true\n      dag:\n        tasks:\n          - name: outer-most-map-map-0ukhr5-fan-out\n            template: outer-most-map-map-0ukhr5-fan-out\n            depends: \"\"\n          - name: outer-most-map-map-0ukhr5-map\n            template: outer-most-map-map-0ukhr5-map\n            depends: outer-most-map-map-0ukhr5-fan-out.Succeeded\n            arguments:\n              parameters:\n                - name: xarg\n                  value: \"{{item}}\"\n            withParam: \"{{tasks.outer-most-map-map-0ukhr5-fan-out.outputs.parameters.iterate-on}}\"\n          - name: outer-most-map-map-0ukhr5-fan-in\n            template: outer-most-map-map-0ukhr5-fan-in\n            depends: outer-most-map-map-0ukhr5-map.Succeeded || outer-most-map-map-0ukhr5-map.Failed\n    - name: runnable-dag\n      failFast: true\n      dag:\n        tasks:\n          - name: generate-list-task-s7za4e\n            template: generate-list-task-s7za4e\n            depends: \"\"\n          - name: outer-most-map-map-0ukhr5\n            template: outer-most-map-map-0ukhr5\n            depends: generate-list-task-s7za4e.Succeeded\n          - name: success-success-2v62uq\n            template: success-success-2v62uq\n            depends: outer-most-map-map-0ukhr5.Succeeded\n    - name: generate-list-task-s7za4e\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - generate_list\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/nesting.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n    - name: outer-most-map-map-0ukhr5-fan-out\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - fan\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map\n          - --mode\n          - out\n          - --file\n          - examples/concepts/nesting.yaml\n          - --log-level\n          - WARNING\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      outputs:\n        parameters:\n          - name: iterate-on\n            valueFrom:\n              path: /tmp/output.txt\n    - name: outer-most-map-map-0ukhr5-fan-in\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - fan\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map\n          - --mode\n          - in\n          - --file\n          - examples/concepts/nesting.yaml\n          - --log-level\n          - WARNING\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n    - name: nested-parallel-parallel-wje1o4-fan-out\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - fan\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map.map_variable_placeholder.nested%parallel\n          - --mode\n          - out\n          - --file\n          - examples/concepts/nesting.yaml\n          - --log-level\n          - WARNING\n          - --config-file\n          - examples/configs/argo-config.yaml\n          - --map-variable\n          - '{\"xarg\": \"{{inputs.parameters.xarg}}\"}'\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      inputs:\n        parameters:\n          - name: xarg\n    - name: nested-parallel-parallel-wje1o4-fan-in\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - fan\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map.map_variable_placeholder.nested%parallel\n          - --mode\n          - in\n          - --file\n          - examples/concepts/nesting.yaml\n          - --log-level\n          - WARNING\n          - --config-file\n          - examples/configs/argo-config.yaml\n          - --map-variable\n          - '{\"xarg\": \"{{inputs.parameters.xarg}}\"}'\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      inputs:\n        parameters:\n          - name: xarg\n    - name: inner-most-map-map-yeslqe-fan-out\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - fan\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map.map_variable_placeholder.nested%parallel.a.inner%most%map\n          - --mode\n          - out\n          - --file\n          - examples/concepts/nesting.yaml\n          - --log-level\n          - WARNING\n          - --config-file\n          - examples/configs/argo-config.yaml\n          - --map-variable\n          - '{\"xarg\": \"{{inputs.parameters.xarg}}\"}'\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      outputs:\n        parameters:\n          - name: iterate-on\n            valueFrom:\n              path: /tmp/output.txt\n      inputs:\n        parameters:\n          - name: xarg\n    - name: inner-most-map-map-yeslqe-fan-in\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - fan\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map.map_variable_placeholder.nested%parallel.a.inner%most%map\n          - --mode\n          - in\n          - --file\n          - examples/concepts/nesting.yaml\n          - --log-level\n          - WARNING\n          - --config-file\n          - examples/configs/argo-config.yaml\n          - --map-variable\n          - '{\"xarg\": \"{{inputs.parameters.xarg}}\"}'\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      inputs:\n        parameters:\n          - name: xarg\n    - name: executable-stub-blnf25\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map.map_variable_placeholder.nested%parallel.a.inner%most%map.map_variable_placeholder.executable\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/nesting.yaml\n          - --map-variable\n          - '{\"xarg\": \"{{inputs.parameters.xarg}}\", \"yarg\": \"{{inputs.parameters.yarg}}\"}'\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      inputs:\n        parameters:\n          - name: xarg\n          - name: yarg\n    - name: success-success-trvgst\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map.map_variable_placeholder.nested%parallel.a.inner%most%map.map_variable_placeholder.success\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/nesting.yaml\n          - --map-variable\n          - '{\"xarg\": \"{{inputs.parameters.xarg}}\", \"yarg\": \"{{inputs.parameters.yarg}}\"}'\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      inputs:\n        parameters:\n          - name: xarg\n          - name: yarg\n    - name: success-success-y1yr7v\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map.map_variable_placeholder.nested%parallel.a.success\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/nesting.yaml\n          - --map-variable\n          - '{\"xarg\": \"{{inputs.parameters.xarg}}\"}'\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      inputs:\n        parameters:\n          - name: xarg\n    - name: inner-most-map-map-b206p5-fan-out\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - fan\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map.map_variable_placeholder.nested%parallel.b.inner%most%map\n          - --mode\n          - out\n          - --file\n          - examples/concepts/nesting.yaml\n          - --log-level\n          - WARNING\n          - --config-file\n          - examples/configs/argo-config.yaml\n          - --map-variable\n          - '{\"xarg\": \"{{inputs.parameters.xarg}}\"}'\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      outputs:\n        parameters:\n          - name: iterate-on\n            valueFrom:\n              path: /tmp/output.txt\n      inputs:\n        parameters:\n          - name: xarg\n    - name: inner-most-map-map-b206p5-fan-in\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - fan\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map.map_variable_placeholder.nested%parallel.b.inner%most%map\n          - --mode\n          - in\n          - --file\n          - examples/concepts/nesting.yaml\n          - --log-level\n          - WARNING\n          - --config-file\n          - examples/configs/argo-config.yaml\n          - --map-variable\n          - '{\"xarg\": \"{{inputs.parameters.xarg}}\"}'\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      inputs:\n        parameters:\n          - name: xarg\n    - name: executable-stub-8ui1yv\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map.map_variable_placeholder.nested%parallel.b.inner%most%map.map_variable_placeholder.executable\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/nesting.yaml\n          - --map-variable\n          - '{\"xarg\": \"{{inputs.parameters.xarg}}\", \"yarg\": \"{{inputs.parameters.yarg}}\"}'\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      inputs:\n        parameters:\n          - name: xarg\n          - name: yarg\n    - name: success-success-h4j0k9\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map.map_variable_placeholder.nested%parallel.b.inner%most%map.map_variable_placeholder.success\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/nesting.yaml\n          - --map-variable\n          - '{\"xarg\": \"{{inputs.parameters.xarg}}\", \"yarg\": \"{{inputs.parameters.yarg}}\"}'\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      inputs:\n        parameters:\n          - name: xarg\n          - name: yarg\n    - name: success-success-dvma7h\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map.map_variable_placeholder.nested%parallel.b.success\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/nesting.yaml\n          - --map-variable\n          - '{\"xarg\": \"{{inputs.parameters.xarg}}\"}'\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      inputs:\n        parameters:\n          - name: xarg\n    - name: success-success-e4lb2k\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - outer%most%map.map_variable_placeholder.success\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/nesting.yaml\n          - --map-variable\n          - '{\"xarg\": \"{{inputs.parameters.xarg}}\"}'\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n      inputs:\n        parameters:\n          - name: xarg\n    - name: success-success-2v62uq\n      container:\n        image: harbor.csis.astrazeneca.net/mlops/runnable:latest\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - success\n          - --log-level\n          - WARNING\n          - --file\n          - examples/concepts/nesting.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n  templateDefaults:\n    activeDeadlineSeconds: 7200\n    timeout: 10800s\n  arguments:\n    parameters:\n      - name: run_id\n        value: \"{{workflow.uid}}\"\n  volumes:\n    - name: executor-0\n      persistentVolumeClaim:\n        claimName: runnable-volume\n</code></pre> <p> argo workflows UI showing the deeply nested workflows. </p>"},{"location":"configurations/executors/argo/#kubeflow","title":"Kubeflow","text":"<p>Kubeflow pipelines compiles workflows defined in SDK to Argo workflows and thereby has support for uploading argo workflows. Below is a screenshot of the map pipeline uploaded to Kubeflow.</p> <p> </p> argo workflows UI showing the map workflow definition. <p> </p> argo workflows UI showing the map workflow execution."},{"location":"configurations/executors/container-environments/","title":"container environments","text":""},{"location":"configurations/executors/container-environments/#pipeline_definition","title":"Pipeline definition","text":"<p>Executing pipelines in containers needs a <code>yaml</code> based definition of the pipeline which is referred during the task execution.</p> <p>Any execution of the pipeline defined by SDK generates the pipeline definition in<code>yaml</code> format for all executors apart from the <code>local</code> executor.</p> <p>Follow the below steps to execute the pipeline defined by SDK.</p> <ol> <li>Execute the pipeline by running the python script as you would normally do to generate <code>yaml</code> based definition.</li> <li>Optionally (but highly recommended) version your code using git.</li> <li>Build the docker image with the <code>yaml</code> file-based definition as part of the image. We recommend tagging the docker image with the short git sha to uniquely identify the docker image (1).</li> <li>Define a variable to temporarily hold the docker image name in the pipeline definition, if the docker image name is not known.</li> <li>Execute the pipeline using the runnable CLI.</li> </ol> <ol> <li>Avoid using generic tags such as <code>latest</code>.</li> </ol>"},{"location":"configurations/executors/container-environments/#dynamic_name_of_the_image","title":"Dynamic name of the image","text":"<p>All containerized executors have a circular dependency problem.</p> <ul> <li>The docker image tag is only known after the creation of the image with the <code>yaml</code> based definition.</li> <li>But the <code>yaml</code> based definition needs the docker image tag as part of the definition.</li> </ul> <p>Warning</p> <p>Not providing the required environment variable will raise an exception.</p> <p>To resolve this, runnable supports <code>variables</code> in the configuration of executors, both global and in step overrides. Variables should follow the python template strings syntax and are replaced with environment variable prefixed by <code>runnable_VAR_&lt;identifier&gt;</code>.</p> <p>Concretely, <code>$identifier</code> is replaced by <code>runnable_VAR_&lt;identifier&gt;</code>.</p>"},{"location":"configurations/executors/container-environments/#dockerfile","title":"Dockerfile","text":"<p>runnable should be installed in the docker image and available in the path. An example dockerfile is provided below.</p> <p>non-native orchestration</p> <p>Having runnable to be part of the docker image adds additional dependencies for python to be present in the docker image. In that sense, runnable is technically non-native container orchestration tool.</p> <p>Facilitating native container orchestration, without runnable as part of the docker image, results in a complicated specification of files/parameters/experiment tracking losing the value of native interfaces to these essential orchestration concepts.</p> <p>With the improvements in python packaging ecosystem, it should be possible to distribute runnable as a self-contained binary and reducing the dependency on the docker image.</p>"},{"location":"configurations/executors/container-environments/#todo_change_this_to_a_proper_example","title":"TODO: Change this to a proper example.","text":""},{"location":"configurations/executors/local-container/","title":"local-container","text":"<p>Execute all the steps of the pipeline in containers. Please refer to the note on containers on building images.</p> <ul> <li> Provides a way to test the containers and the execution of the pipeline in local environment.</li> <li> Any failure in cloud native container environments can be replicated in local environments.</li> <li> Ability to provide specialized compute environments for different steps of the pipeline.</li> <li> The scalability is still constrained by the resources in local environment.</li> </ul> <p>parallel executions</p> <p>Run logs that use a single json (eg. file-system) are not compatible with parallel executions due to race conditions to write the same file by different processes.</p> <p>Use <code>chunked</code> run log stores (eg. chunked-fs).</p>"},{"location":"configurations/executors/local-container/#configuration","title":"Configuration","text":"<pre><code>executor: local-container\nconfig:\n  docker_image: &lt;required&gt;\n  enable_parallel: false # (1)\n  auto_remove_container: true # (2)\n  run_in_local: false # (3)\n  environment: # (4)\n    ...\n  overrides: # (5)\n    ...\n</code></pre> <ol> <li>By default, all tasks are sequentially executed. Provide <code>true</code> to enable tasks within parallel or map to be executed in parallel.</li> <li>Set it to false, to debug a failed container.</li> <li>Setting it to true will behave exactly like a local executor.</li> <li>Pass any environment variables into the container.</li> <li>Please refer to step overrides for more details.</li> </ol> <p>The <code>docker_image</code> field is required and default image to execute tasks of the pipeline. Individual tasks can override the global defaults of executor by providing <code>overrides</code></p> <p>Debugging</p> <p><code>auto_remove_container</code> allows you to run the failed container independently to identify the issue that caused the failure.</p> <p><code>run_in_local</code> allows you to execute a few tasks in local environment to allow debugging and also selectively choose which step to run in container.</p>"},{"location":"configurations/executors/local-container/#example","title":"Example","text":"<p>Nearly all the examples seen in concepts can be executed using the <code>local-container</code> configuration. Below is one simple example to concretely show the patterns.</p> Configurationpython sdkyamlRun log <p>Assumed to be present at <code>examples/configs/local-container.yaml</code></p> <p>The docker image is a variable and dynamically set during execution.</p> <pre><code>executor:\n  type: \"local-container\" # (1)\n  config:\n    docker_image: runnable:latest # (2)\n    environment:\n      key: value # (3)\n\nrun_log_store: # (4)\n  type: file-system\n\ncatalog:\n  type: file-system\n\nsecrets:\n  type: do-nothing\n</code></pre> <ol> <li>Use local-container executor type to execute the pipeline.</li> <li>By default, all the tasks are executed in the docker image . Please refer to building docker images</li> <li>Pass any environment variables that are needed for the container.</li> <li>Store the run logs in the file-system. runnable will handle the access to them by mounting the file system into the container.</li> </ol> <p>Running the SDK defined pipelines for any container based executions happens in multi-stage process.</p> <ol> <li>Generate the <code>yaml</code> definition file by: <code>runnable_CONFIGURATION_FILE=examples/configs/local-container.yaml python examples/concepts/simple.py</code></li> <li>Build the docker image with yaml definition in it, called runnable:demo in current example.</li> <li>Execute the pipeline via the runnable CLI, <code>runnable_VAR_default_docker_image=runnable:demo  runnable execute -f runnable-pipeline.yaml -c examples/configs/local-container.yaml</code></li> </ol> <pre><code>\"\"\"\nA simple pipeline with a simple function that just prints \"Hello World!\".\n\nRun this pipeline by:\n    python examples/concepts/simple.py\n\"\"\"\n\nfrom runnable import Pipeline, PythonTask\n\n\ndef simple_function():\n    \"\"\"\n    A simple function that just prints \"Hello World!\".\n    \"\"\"\n    print(\"Hello World!\")\n\n\ndef main():\n    simple_task = PythonTask(\n        name=\"simple\",\n        function=simple_function,\n        terminate_with_success=True,\n    )\n\n    pipeline = Pipeline(\n        steps=[simple_task],\n        add_terminal_nodes=True,\n    )\n\n    pipeline.execute()  # (1)\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <ol> <li>You can provide a configuration file dynamically by using the environment variable <code>runnable_CONFIGURATION_FILE</code>. Please see SDK for more details.</li> </ol> <p>For yaml based definitions, the execution order is to:</p> <ol> <li>Build the docker image with the yaml definition in it, called runnable:demo in current example.</li> <li>Execute the pipeline via the runnable CLI: <code>runnable_VAR_default_docker_image=runnable:demo runnable execute -f examples/concepts/simple.yaml -c examples/configs/local-container.yaml</code></li> </ol> <pre><code>dag:\n  description: |\n    A simple pipeline with a simple function that just prints \"Hello World!\".\n\n    Run this pipeline by:\n      runnable execute -f  examples/concepts/simple.yaml\n  start_at: simple\n  steps:\n    simple:\n      type: task\n      command: \"examples.concepts.simple.simple_function\"\n      command_type: python\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p>The run log structure is the same as any other <code>local</code> executions apart from an additional code identity with the information about the docker image.</p> <pre><code>{\n  \"run_id\": \"shortest-stallman-2113\",\n  \"dag_hash\": \"d467805d7f743d459a6abce95bedbfc6c1ecab67\",\n  \"use_cached\": false,\n  \"tag\": \"\",\n  \"original_run_id\": \"\",\n  \"status\": \"SUCCESS\",\n  \"steps\": {\n      \"simple\": {\n          \"name\": \"simple\",\n          \"internal_name\": \"simple\",\n          \"status\": \"SUCCESS\",\n          \"step_type\": \"task\",\n          \"message\": \"\",\n          \"mock\": false,\n          \"code_identities\": [\n              {\n                  \"code_identifier\": \"ef142998dc315ddbd9aa10e016128c872de6e6e1\",\n                  \"code_identifier_type\": \"git\",\n                  \"code_identifier_dependable\": true,\n                  \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                  \"code_identifier_message\": \"\"\n              },\n              {\n                  \"code_identifier\": \"sha256:e5cc0936aad4d3cacb3075290729ce834dd2d9c89ea24eea609d7664f99ce50f\",\n                  \"code_identifier_type\": \"docker\",\n                  \"code_identifier_dependable\": true,\n                  \"code_identifier_url\": \"local docker host\",\n                  \"code_identifier_message\": \"\"\n              }\n          ],\n          \"attempts\": [\n              {\n                  \"attempt_number\": 1,\n                  \"start_time\": \"2024-01-22 21:13:53.676698\",\n                  \"end_time\": \"2024-01-22 21:13:53.678976\",\n                  \"duration\": \"0:00:00.002278\",\n                  \"status\": \"SUCCESS\",\n                  \"message\": \"\",\n                  \"parameters\": {}\n              }\n          ],\n          \"user_defined_metrics\": {},\n          \"branches\": {},\n          \"data_catalog\": [\n              {\n                  \"name\": \"simple.execution.log\",\n                  \"data_hash\": \"03ba204e50d126e4674c005e04d82e84c21366780af1f43bd54a37816b6ab340\",\n                  \"catalog_relative_path\": \"shortest-stallman-2113/simple.execution.log\",\n                  \"catalog_handler_location\": \"/tmp/catalog/\",\n                  \"stage\": \"put\"\n              }\n          ]\n      },\n      \"success\": {\n          \"name\": \"success\",\n          \"internal_name\": \"success\",\n          \"status\": \"SUCCESS\",\n          \"step_type\": \"success\",\n          \"message\": \"\",\n          \"mock\": false,\n          \"code_identities\": [\n              {\n                  \"code_identifier\": \"ef142998dc315ddbd9aa10e016128c872de6e6e1\",\n                  \"code_identifier_type\": \"git\",\n                  \"code_identifier_dependable\": true,\n                  \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                  \"code_identifier_message\": \"\"\n              }\n          ],\n          \"attempts\": [\n              {\n                  \"attempt_number\": 1,\n                  \"start_time\": \"2024-01-22 21:13:53.807381\",\n                  \"end_time\": \"2024-01-22 21:13:53.807834\",\n                  \"duration\": \"0:00:00.000453\",\n                  \"status\": \"SUCCESS\",\n                  \"message\": \"\",\n                  \"parameters\": {}\n              }\n          ],\n          \"user_defined_metrics\": {},\n          \"branches\": {},\n          \"data_catalog\": []\n      }\n  },\n  \"parameters\": {},\n  \"run_config\": {\n      \"executor\": {\n          \"service_name\": \"local-container\",\n          \"service_type\": \"executor\",\n          \"enable_parallel\": false,\n          \"placeholders\": {}\n      },\n      \"run_log_store\": {\n          \"service_name\": \"file-system\",\n          \"service_type\": \"run_log_store\"\n      },\n      \"secrets_handler\": {\n          \"service_name\": \"do-nothing\",\n          \"service_type\": \"secrets\"\n      },\n      \"catalog_handler\": {\n          \"service_name\": \"file-system\",\n          \"service_type\": \"catalog\"\n      },\n      \"experiment_tracker\": {\n          \"service_name\": \"do-nothing\",\n          \"service_type\": \"experiment_tracker\"\n      },\n      \"pipeline_file\": \"examples/concepts/simple.yaml\",\n      \"parameters_file\": null,\n      \"configuration_file\": \"examples/configs/local-container.yaml\",\n      \"tag\": \"\",\n      \"run_id\": \"shortest-stallman-2113\",\n      \"variables\": {\n          \"default_docker_image\": \"runnable:demo\"\n      },\n      \"use_cached\": false,\n      \"original_run_id\": \"\",\n      \"dag\": {\n          \"start_at\": \"simple\",\n          \"name\": \"\",\n          \"description\": null,\n          \"steps\": {\n              \"simple\": {\n                  \"type\": \"task\",\n                  \"name\": \"simple\",\n                  \"next\": \"success\",\n                  \"on_failure\": \"\",\n                  \"executor_config\": {},\n                  \"catalog\": null,\n                  \"max_attempts\": 1,\n                  \"command\": \"examples.concepts.simple.simple_function\",\n                  \"command_type\": \"python\",\n                  \"node_name\": \"simple\"\n              },\n              \"success\": {\n                  \"type\": \"success\",\n                  \"name\": \"success\"\n              },\n              \"fail\": {\n                  \"type\": \"fail\",\n                  \"name\": \"fail\"\n              }\n          }\n      },\n      \"dag_hash\": \"d467805d7f743d459a6abce95bedbfc6c1ecab67\",\n      \"execution_plan\": \"chained\"\n  }\n}\n</code></pre>"},{"location":"configurations/executors/local-container/#compatibility","title":"Compatibility","text":""},{"location":"configurations/executors/local-container/#step_override","title":"Step override","text":"<p>Individual steps of the pipeline can over-ride the default configuration by referring to the specific <code>override</code> defined in <code>overrides</code> section of the executor configuration.</p> <p><code>override</code> should be defined per executor and is only applicable for that specific executor.</p>"},{"location":"configurations/executors/local-container/#example_1","title":"Example","text":"Configurationpython sdkyaml <p>Assumed to be present at <code>examples/executors/local-container-override.yaml</code></p> <p>In the example below, we define the default configuration in the executor configuration. We also provide a override <code>custom_docker_image</code> which overrides some of the default configuration parameters.</p> <pre><code>executor:\n  type: \"local-container\"\n  config:\n    docker_image: $default_docker_image\n    environment:\n      key: value\n    overrides:\n      custom_docker_image:\n        docker_image: $custom_docker_image\n        environment:\n          key: not-value\n\nrun_log_store:\n  type: file-system\n\ncatalog:\n  type: file-system\n\nsecrets:\n  type: do-nothing\n\nexperiment_tracker:\n  type: do-nothing\n</code></pre> <p>As seen in the above example, running the SDK defined pipelines for any container based executions happens in multi-stage process.</p> <ol> <li>Generate the <code>yaml</code> definition file by: <code>runnable_CONFIGURATION_FILE=examples/executors/local-container-override.yaml python examples/executors/step_overrides_container.py</code></li> <li> <p>Build the docker image with yaml definition in it. In this example, we build two docker images.</p> <ul> <li>runnable:3.8 as the default_docker_image.</li> <li>runnable:3.9 as the custom_docker_image.</li> </ul> </li> </ol> <p>Both the docker images are same except for the python version.</p> <ol> <li>Execute the pipeline via the runnable CLI, <code>runnable_VAR_default_docker_image=runnable:3.8  runnable_VAR_custom_docker_image=runnable:3.9 runnable execute -f runnable-pipeline.yaml -c examples/executors/local-container-override.yaml</code></li> </ol> <p>You should see the console output of the <code>step 1</code> to be <code>3.8</code> and key to be \"value\" while the python version for <code>step 2</code> to be 3.9 and key to be \"not-value\".</p> <pre><code>\"\"\"\nAn example to demonstrate overriding global configuration for a step.\n\n    step 1 runs in the docker image specified in the executor config and uses the environment\n    value for key to be \"value\"\n\n    step 2 overrides the config and executes the command in the configuration defined\n    in overrides section of executor config.\n\n    You can run this example using two steps:\n        Generates yaml file:\n\n        runnable_CONFIGURATION_FILE=examples/executors/local-container-override.yaml \\\n        python examples/executors/step_overrides_container.py\n\n        # Create the docker image with the pipeline runnable-pipeline.yaml as part of it.\n\n        Execute the pipeline using the CLI:\n\n        runnable_VAR_default_docker_image=runnable:3.8 \\\n        runnable_VAR_custom_docker_image=runnable:3.9 \\\n        runnable execute -f runnable-pipeline.yaml -c examples/executors/local-container-override.yaml\n\n\"\"\"\n\nfrom runnable import Pipeline, Task\n\n\ndef main():\n    step1 = Task(\n        name=\"step1\",\n        command=\"python --version &amp;&amp; env | grep key\",\n        command_type=\"shell\",\n    )\n\n    step2 = Task(\n        name=\"step2\",\n        command=\"python --version &amp;&amp; env | grep key\",\n        command_type=\"shell\",\n        terminate_with_success=True,\n        overrides={\"local-container\": \"custom_docker_image\"},\n    )\n\n    pipeline = Pipeline(\n        steps=[step1, step2],\n        add_terminal_nodes=True,\n    )\n\n    pipeline.execute()\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>For yaml based definitions, the execution order is to:</p> <ol> <li> <p>Build the docker image with the yaml definition in it. In this example, we build two docker images.</p> <ul> <li>runnable:3.8 as the default_docker_image.</li> <li>runnable:3.9 as the custom_docker_image.</li> </ul> <p>Both the docker images are same except for the python version.</p> </li> <li> <p>Execute the pipeline via the runnable CLI: <code>runnable_VAR_default_docker_image=runnable:3.8 runnable_VAR_custom_docker_image=runnable:3.9 runnable execute -f examples/executors/step_overrides_container.yaml -c examples/executors/local-container-override.yaml</code></p> </li> </ol> <p>You should see the console output of the <code>step 1</code> to be <code>3.8</code> and key to be \"value\" while the python version for <code>step 2</code> to be 3.9 and key to be \"not-value\".</p> <pre><code>dag:\n  description: |\n    An example to demonstrate overriding global configuration for a step.\n\n    step 1 runs in the docker image specified in the executor config and uses the environment\n    value for key to be \"value\"\n\n    step 2 overrides the config and executes the command in the configuration defined\n    in overrides section of executor config.\n\n    You can execute the pipeline by:\n    runnable execute -f examples/executors/step_overrides_container.yaml \\\n     -c examples/executors/local-container-override.yaml\n  start_at: step 1\n  steps:\n    step 1:\n      type: task\n      command_type: shell # (2)\n      command: |\n        python --version &amp;&amp;\n        env | grep key\n      next: step 2\n    step 2:\n      type: task\n      command_type: shell\n      command: |\n        python --version &amp;&amp;\n        env | grep key\n      overrides:\n        local-container: custom_docker_image\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre>"},{"location":"configurations/executors/local/","title":"local","text":"<p>All the steps of the pipeline are executed in the local compute environment in the same shell as it was triggered.</p> <ul> <li> Provides the most comfortable environment for experimentation and development.</li> <li> The scalability is constrained by the local compute environment.</li> <li> Not possible to provide specialized compute environments for different steps of the pipeline.</li> </ul> <p>parallel executions</p> <p>Run logs that use a single json (eg. file-system) are not compatible with parallel executions due to race conditions to write the same file by different processes.</p> <p>Use <code>chunked</code> run log stores (eg. chunked-fs).</p>"},{"location":"configurations/executors/local/#configuration","title":"Configuration","text":"<pre><code>executor: local\nconfig:\n  enable_parallel: false # (1)\n</code></pre> <ol> <li>By default, all tasks are sequentially executed. Provide <code>true</code> to enable tasks within parallel or map to be executed in parallel.</li> </ol> <p>All the examples in the concepts section are executed using <code>local</code> executors.</p>"},{"location":"configurations/executors/mocked/","title":"retry","text":"<p>Mocked executors provide a way to control the behavior of <code>task</code> node types to be either pass through or execute a alternate command with modified configurations.</p> <ul> <li> Runs the pipeline only in local environment.</li> <li> Enables unit testing of the pipeline in both yaml and SDK definitions.</li> <li> Isolates specific node(s) from the execution for further analysis.</li> <li> Not meant to be used for production deployments</li> </ul>"},{"location":"configurations/executors/mocked/#options","title":"Options","text":"<pre><code>executor: mocked\nconfig:\n  patches:\n    name of the name:\n      command_configuration:\n</code></pre> <p>By default, all the <code>task</code> steps are passed through without an execution. By providing <code>patches</code>, indexed by the name of the node, gives control on the command to run and the configuration of the command.</p>"},{"location":"configurations/executors/mocked/#command_configuration_for_notebook_nodes","title":"Command configuration for notebook nodes","text":"<p><code>python</code> and <code>shell</code> based tasks have no configuration options apart from the <code>command</code>. Notebook nodes have additional configuration options detailed in concepts. Ploomber engine provides rich options in debugging failed notebooks.</p>"},{"location":"configurations/executors/mocked/#example","title":"Example","text":""},{"location":"configurations/executors/mocked/#mocking_nodes","title":"Mocking nodes","text":"<p>The following example shows the simple case of mocking all the steps of the pipeline.</p> pipeline in yamlpython sdkMocked configurationRun log <p>You can execute the mocked pipeline by: <code>runnable execute -f examples/concepts/simple.yaml -c examples/configs/mocked-config-simple.yaml</code></p> <pre><code>dag:\n  description: |\n    A simple pipeline with a simple function that just prints \"Hello World!\".\n\n    Run this pipeline by:\n      runnable execute -f  examples/concepts/simple.yaml\n  start_at: simple\n  steps:\n    simple:\n      type: task\n      command: \"examples.concepts.simple.simple_function\"\n      command_type: python\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <p>You can execute the mocked pipeline by:</p> <p><code>runnable_CONFIGURATION_FILE=examples/configs/mocked-config-simple.yaml python examples/concepts/simple.py</code></p> <pre><code>\"\"\"\nA simple pipeline with a simple function that just prints \"Hello World!\".\n\nRun this pipeline by:\n    python examples/concepts/simple.py\n\"\"\"\n\nfrom runnable import Pipeline, PythonTask\n\n\ndef simple_function():\n    \"\"\"\n    A simple function that just prints \"Hello World!\".\n    \"\"\"\n    print(\"Hello World!\")\n\n\ndef main():\n    simple_task = PythonTask(\n        name=\"simple\",\n        function=simple_function,\n        terminate_with_success=True,\n    )\n\n    pipeline = Pipeline(\n        steps=[simple_task],\n        add_terminal_nodes=True,\n    )\n\n    pipeline.execute()  # (1)\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>catalog:\n  type: file-system # (1)\n\nrun_log_store:\n  type: file-system # (1)\n\nexecutor:\n  type: mocked\n</code></pre> <p>The flag <code>mock</code> is set to be <code>true</code> for the execution of node simple which denotes that the task was mocked.</p> <pre><code>{\n    \"run_id\": \"minty-goodall-0528\",\n    \"dag_hash\": \"\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {\n        \"simple\": {\n            \"name\": \"simple\",\n            \"internal_name\": \"simple\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": true,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"d76cf865af2f8e03b6c1205403351cbe42e6cdc4\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-11 05:28:40.812597\",\n                    \"end_time\": \"2024-02-11 05:28:40.812627\",\n                    \"duration\": \"0:00:00.000030\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"d76cf865af2f8e03b6c1205403351cbe42e6cdc4\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-11 05:28:40.883909\",\n                    \"end_time\": \"2024-02-11 05:28:40.884310\",\n                    \"duration\": \"0:00:00.000401\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"mocked\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"overrides\": {},\n            \"patches\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"run_log_store\",\n            \"log_folder\": \".run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\",\n            \"catalog_location\": \".catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"\",\n        \"parameters_file\": \"\",\n        \"configuration_file\": \"examples/configs/mocked-config-simple.yaml\",\n        \"tag\": \"\",\n        \"run_id\": \"minty-goodall-0528\",\n        \"variables\": {},\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"simple\",\n            \"name\": \"\",\n            \"description\": \"\",\n            \"steps\": {\n                \"simple\": {\n                    \"type\": \"task\",\n                    \"name\": \"simple\",\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1,\n                    \"command\": \"examples.concepts.simple.simple_function\",\n                    \"command_type\": \"python\",\n                    \"node_name\": \"simple\"\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre>"},{"location":"configurations/executors/mocked/#patching_nodes_for_unit_testing","title":"Patching nodes for unit testing","text":"<p>Pipelines are themselves code and should be testable. In the below example, we take an example pipeline to test the behavior of the traversal.</p> <p>The below pipeline is designed to follow: <code>step 1 &gt;&gt; step 2 &gt;&gt; step 3</code> in case of no failures and <code>step 1 &gt;&gt; step3</code> in case of failure. The traversal is shown in concepts.</p> <p>Asserting Run log</p> <p>The run log is a simple json file that can be parsed and validated against designed behaviors. You can also create the <code>RunLog</code> object by deserializing <code>runnable.datastore.RunLog</code> from the json.</p> <p>This can be handy when validating complex pipelines.</p> pipeline in yamlpython sdkRun log with no mockingMocked configurationRun log with mocking <pre><code>dag:\n  description: |\n    This is a simple pipeline to demonstrate failure in a step.\n\n    The default behavior is to traverse to step type fail and mark the run as failed.\n    But you can control it by providing on_failure.\n\n    In this example: step 1 fails and moves to step 3 skipping step 2. The pipeline status\n    is considered to be success.\n\n    step 1 (FAIL) &gt;&gt; step 3 &gt;&gt; success\n\n    You can run this pipeline by runnable execute -f examples/on-failure.yaml\n  start_at: step 1\n  steps:\n    step 1:\n      type: task\n      command_type: shell\n      command: exit 1 # This will fail!\n      next: step 2\n      on_failure: step 3\n    step 2:\n      type: stub # This step will never reach\n      next: step 3\n    step 3:\n      type: stub\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <pre><code>\"\"\"\nThis is a simple pipeline to demonstrate failure in a step.\n\n    The default behavior is to traverse to step type fail and mark the run as failed.\n    But you can control it by providing on_failure.\n\n    In this example: step 1 fails and moves to step 3 skipping step 2. The pipeline status\n    is considered to be success.\n\n    step 1 (FAIL) &gt;&gt; step 3 &gt;&gt; success\n\n    You can run this example by:\n    python examples/on_failure.py\n\"\"\"\n\nfrom runnable import Pipeline, ShellTask, Stub\n\n\ndef main():\n    step_1 = ShellTask(name=\"step 1\", command=\"exit 1\")  # This will fail\n\n    step_2 = Stub(name=\"step 2\")\n\n    step_3 = Stub(name=\"step 3\", terminate_with_success=True)\n\n    step_1.on_failure = step_3.name\n\n    pipeline = Pipeline(\n        steps=[step_1, step_2, step_3],\n        add_terminal_nodes=True,\n    )\n    pipeline.execute()\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>The <code>run log</code> has only <code>step 1</code> and <code>step 3</code> as part of the steps (as designed)  showing the behavior of the pipeline in case of failure. The status of <code>step 1</code> is  captured as <code>FAIL</code> due to <code>exit 1</code> command in the pipeline definition.</p> <pre><code>{\n    \"run_id\": \"selfish-pasteur-0559\",\n    \"dag_hash\": \"\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {\n        \"step 1\": {\n            \"name\": \"step 1\",\n            \"internal_name\": \"step 1\",\n            \"status\": \"FAIL\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"d76cf865af2f8e03b6c1205403351cbe42e6cdc4\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-11 05:59:08.382587\",\n                    \"end_time\": \"2024-02-11 05:59:08.446642\",\n                    \"duration\": \"0:00:00.064055\",\n                    \"status\": \"FAIL\",\n                    \"message\": \"Command failed\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"step_1.execution.log\",\n                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                    \"catalog_relative_path\": \"selfish-pasteur-0559/step_1.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"step 3\": {\n            \"name\": \"step 3\",\n            \"internal_name\": \"step 3\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"stub\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"d76cf865af2f8e03b6c1205403351cbe42e6cdc4\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-11 05:59:08.516318\",\n                    \"end_time\": \"2024-02-11 05:59:08.516333\",\n                    \"duration\": \"0:00:00.000015\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"d76cf865af2f8e03b6c1205403351cbe42e6cdc4\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-11 05:59:08.580478\",\n                    \"end_time\": \"2024-02-11 05:59:08.580555\",\n                    \"duration\": \"0:00:00.000077\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"overrides\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"buffered\",\n            \"service_type\": \"run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\",\n            \"catalog_location\": \".catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"\",\n        \"parameters_file\": \"\",\n        \"configuration_file\": \"\",\n        \"tag\": \"\",\n        \"run_id\": \"selfish-pasteur-0559\",\n        \"variables\": {},\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"step 1\",\n            \"name\": \"\",\n            \"description\": \"\",\n            \"steps\": {\n                \"step 1\": {\n                    \"type\": \"task\",\n                    \"name\": \"step 1\",\n                    \"next\": \"step 2\",\n                    \"on_failure\": \"step 3\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1,\n                    \"command\": \"exit 1\",\n                    \"command_type\": \"shell\",\n                    \"node_name\": \"step 1\"\n                },\n                \"step 2\": {\n                    \"type\": \"stub\",\n                    \"name\": \"step 2\",\n                    \"next\": \"step 3\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1\n                },\n                \"step 3\": {\n                    \"type\": \"stub\",\n                    \"name\": \"step 3\",\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre> <p>We can patch the command of step 1 to be successful to test the behavior of traversal in case of no failures.</p> <p>Running the pipeline with mocked configuration:</p> <p>for yaml: <code>runnable execute -f examples/on-failure.yaml -c examples/configs/mocked-config-unittest.yaml</code></p> <p>for python: <code>runnable_CONFIGURATION_FILE=examples/configs/mocked-config-unittest.yaml python examples/on_failure.py</code></p> <pre><code>catalog:\n  type: file-system # (1)\n\nrun_log_store:\n  type: file-system # (1)\n\nexecutor:\n  type: mocked\n  config:\n    patches:\n      step 1:\n        command: exit 0\n</code></pre> <p>As seen in the <code>run log</code>, the steps have <code>step 1</code>, <code>step 2</code>, <code>step 3</code> as executed and successful steps. And the status of <code>step 1</code> is <code>SUCCESS</code>.</p> <pre><code>{\n    \"run_id\": \"syrupy-aryabhata-0552\",\n    \"dag_hash\": \"026b36dd2b3507fe586f1f85ba308f817745c465\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {\n        \"step 1\": {\n            \"name\": \"step 1\",\n            \"internal_name\": \"step 1\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"d76cf865af2f8e03b6c1205403351cbe42e6cdc4\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-11 05:52:19.421358\",\n                    \"end_time\": \"2024-02-11 05:52:19.426678\",\n                    \"duration\": \"0:00:00.005320\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"step_1.execution.log\",\n                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                    \"catalog_relative_path\": \"syrupy-aryabhata-0552/step_1.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"step 2\": {\n            \"name\": \"step 2\",\n            \"internal_name\": \"step 2\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"stub\",\n            \"message\": \"\",\n            \"mock\": true,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"d76cf865af2f8e03b6c1205403351cbe42e6cdc4\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-11 05:52:19.500544\",\n                    \"end_time\": \"2024-02-11 05:52:19.500559\",\n                    \"duration\": \"0:00:00.000015\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"step 3\": {\n            \"name\": \"step 3\",\n            \"internal_name\": \"step 3\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"stub\",\n            \"message\": \"\",\n            \"mock\": true,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"d76cf865af2f8e03b6c1205403351cbe42e6cdc4\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-11 05:52:19.577734\",\n                    \"end_time\": \"2024-02-11 05:52:19.577749\",\n                    \"duration\": \"0:00:00.000015\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"d76cf865af2f8e03b6c1205403351cbe42e6cdc4\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-11 05:52:19.649764\",\n                    \"end_time\": \"2024-02-11 05:52:19.650318\",\n                    \"duration\": \"0:00:00.000554\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"mocked\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"overrides\": {},\n            \"patches\": {\n                \"step 1\": {\n                    \"command\": \"exit 0\"\n                }\n            }\n        },\n        \"run_log_store\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"run_log_store\",\n            \"log_folder\": \".run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\",\n            \"catalog_location\": \".catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"examples/on-failure.yaml\",\n        \"parameters_file\": null,\n        \"configuration_file\": \"examples/configs/mocked-config-unittest.yaml\",\n        \"tag\": \"\",\n        \"run_id\": \"syrupy-aryabhata-0552\",\n        \"variables\": {},\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"step 1\",\n            \"name\": \"\",\n            \"description\": \"This is a simple pipeline to demonstrate failure in a step.\\n\\nThe default behavior is to traverse to step type fail and mark the run as\nfailed.\\nBut you can control it by providing on_failure.\\n\\nIn this example: step 1 fails and moves to step 3 skipping step 2. The pipeline status\\nis considered to be\nsuccess.\\n\\nstep 1 (FAIL) &gt;&gt; step 3 &gt;&gt; success\\n\\nYou can run this pipeline by runnable execute -f examples/on-failure.yaml\\n\",\n            \"steps\": {\n                \"step 1\": {\n                    \"type\": \"task\",\n                    \"name\": \"step 1\",\n                    \"next\": \"step 2\",\n                    \"on_failure\": \"step 3\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"exit 1\",\n                    \"node_name\": \"step 1\"\n                },\n                \"step 2\": {\n                    \"type\": \"stub\",\n                    \"name\": \"step 2\",\n                    \"next\": \"step 3\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1\n                },\n                \"step 3\": {\n                    \"type\": \"stub\",\n                    \"name\": \"step 3\",\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"026b36dd2b3507fe586f1f85ba308f817745c465\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre>"},{"location":"configurations/executors/mocked/#debugging_failed_executions","title":"Debugging failed executions","text":"<p>Using debuggers</p> <p>For pipelines defined by the python SDK, you can create breakpoints at the python function being executed and use debuggers.</p> <p>For <code>notebook</code> based tasks, refer to ploomber engine documentation for rich debuggers.</p> <p>Shell commands can be run in isolation by providing the parameters as environment variables and catalog artifacts present in the <code>compute_data_folder</code> location.</p> <p>To debug a failed execution, we can use the mocked executor to mock all the steps except for the failed step and providing the parameters and data exposed to the step during the failure which are captured by the <code>run log</code> and <code>catalog</code>.</p> Faulty pipelineFaulty run logmocked configurationDebugging failed executions <pre><code>dag:\n  description: |\n    This is a simple pipeline that demonstrates retrying failures.\n\n    1. Setup: We setup a data folder, we ignore if it is already present\n    2. Create Content: We create a \"hello.txt\" and \"put\" the file in catalog\n    3. Retrieve Content: We \"get\" the file \"hello.txt\" from the catalog and show the contents\n    5. Cleanup: We remove the data folder. Note that this is stubbed to prevent accidental deletion.\n\n\n    You can run this pipeline by:\n       runnable execute -f examples/retry-fail.yaml -c examples/configs/fs-catalog-run_log.yaml \\\n        --run-id wrong-file-name\n  start_at: Setup\n  steps:\n    Setup:\n      type: task\n      command_type: shell\n      command: mkdir -p data # (1)\n      next: Create Content\n    Create Content:\n      type: task\n      command_type: shell\n      command: |\n        echo \"Hello from runnable\" &gt;&gt; data/hello.txt\n      next: Retrieve Content\n      catalog: # (2)\n        put:\n          - data/hello.txt\n    Retrieve Content:\n      type: task\n      command_type: shell\n      command: cat data/hello1.txt # (3)\n      catalog:\n        get:\n          - \"data/hello.txt\" # You can use wild cards following glob pattern\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <pre><code>{\n    \"run_id\": \"wrong-file-name\",\n    \"dag_hash\": \"7b12d64874eff2072c9dd97912a17149f2c32ed2\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"FAIL\",\n    \"steps\": {\n        \"Setup\": {\n            \"name\": \"Setup\",\n            \"internal_name\": \"Setup\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"d76cf865af2f8e03b6c1205403351cbe42e6cdc4\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-11 23:03:00.417889\",\n                    \"end_time\": \"2024-02-11 23:03:00.429579\",\n                    \"duration\": \"0:00:00.011690\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"Setup.execution.log\",\n                    \"data_hash\": \"d2dd9105fa3c62c35d89182c44fbd1ec992d8d408e38f0350d582fa29ed88074\",\n                    \"catalog_relative_path\": \"wrong-file-name/Setup.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"Create Content\": {\n            \"name\": \"Create Content\",\n            \"internal_name\": \"Create Content\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"d76cf865af2f8e03b6c1205403351cbe42e6cdc4\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-11 23:03:00.507067\",\n                    \"end_time\": \"2024-02-11 23:03:00.514757\",\n                    \"duration\": \"0:00:00.007690\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"Create_Content.execution.log\",\n                    \"data_hash\": \"d2dd9105fa3c62c35d89182c44fbd1ec992d8d408e38f0350d582fa29ed88074\",\n                    \"catalog_relative_path\": \"wrong-file-name/Create_Content.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                },\n                {\n                    \"name\": \"data/hello.txt\",\n                    \"data_hash\": \"2ac8edfe4eb5d0d9392cb070664c31c45eecca78c43cb99d2d9c6f5a8c813932\",\n                    \"catalog_relative_path\": \"wrong-file-name/data/hello.txt\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"Retrieve Content\": {\n            \"name\": \"Retrieve Content\",\n            \"internal_name\": \"Retrieve Content\",\n            \"status\": \"FAIL\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"d76cf865af2f8e03b6c1205403351cbe42e6cdc4\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-11 23:03:00.595992\",\n                    \"end_time\": \"2024-02-11 23:03:00.645752\",\n                    \"duration\": \"0:00:00.049760\",\n                    \"status\": \"FAIL\",\n                    \"message\": \"Command failed\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"data/hello.txt\",\n                    \"data_hash\": \"2ac8edfe4eb5d0d9392cb070664c31c45eecca78c43cb99d2d9c6f5a8c813932\",\n                    \"catalog_relative_path\": \"data/hello.txt\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"get\"\n                },\n                {\n                    \"name\": \"Retrieve_Content.execution.log\",\n                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                    \"catalog_relative_path\": \"wrong-file-name/Retrieve_Content.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"fail\": {\n            \"name\": \"fail\",\n            \"internal_name\": \"fail\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"fail\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"d76cf865af2f8e03b6c1205403351cbe42e6cdc4\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-11 23:03:00.727316\",\n                    \"end_time\": \"2024-02-11 23:03:00.727911\",\n                    \"duration\": \"0:00:00.000595\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"overrides\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"run_log_store\",\n            \"log_folder\": \".run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\",\n            \"catalog_location\": \".catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"examples/retry-fail.yaml\",\n        \"parameters_file\": null,\n        \"configuration_file\": \"examples/configs/fs-catalog-run_log.yaml\",\n        \"tag\": \"\",\n        \"run_id\": \"wrong-file-name\",\n        \"variables\": {},\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"Setup\",\n            \"name\": \"\",\n            \"description\": \"This is a simple pipeline that demonstrates retrying failures.\\n\\n1. Setup: We setup a data folder, we ignore if it is already present\\n2. Create Content: We create a \\\"hello.txt\\\" and \\\"put\\\" the file in catalog\\n3. Retrieve Content: We \\\"get\\\" the file \\\"hello.txt\\\" from the catalog and show the contents\\n5. Cleanup: We remove the data folder. Note that this is stubbed to prevent accidental deletion.\\n\\n\\nYou can run this pipeline by:\\n   runnable execute -f examples/retry-fail.yaml -c examples/configs/fs-catalog-run_log.yaml \\\\\\n    --run-id wrong-file-name\\n\",\n            \"steps\": {\n                \"Setup\": {\n                    \"type\": \"task\",\n                    \"name\": \"Setup\",\n                    \"next\": \"Create Content\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"mkdir -p data\",\n                    \"node_name\": \"Setup\"\n                },\n                \"Create Content\": {\n                    \"type\": \"task\",\n                    \"name\": \"Create Content\",\n                    \"next\": \"Retrieve Content\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": {\n                        \"get\": [],\n                        \"put\": [\n                            \"data/hello.txt\"\n                        ]\n                    },\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"echo \\\"Hello from runnable\\\" &gt;&gt; data/hello.txt\\n\",\n                    \"node_name\": \"Create Content\"\n                },\n                \"Retrieve Content\": {\n                    \"type\": \"task\",\n                    \"name\": \"Retrieve Content\",\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": {\n                        \"get\": [\n                            \"data/hello.txt\"\n                        ],\n                        \"put\": []\n                    },\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"cat data/hello1.txt\",\n                    \"node_name\": \"Retrieve Content\"\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"7b12d64874eff2072c9dd97912a17149f2c32ed2\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre> <pre><code>catalog:\n  type: file-system # (1)\n\nrun_log_store:\n  type: file-system # (1)\n\nexecutor:\n  type: mocked\n  config:\n    patches:\n      Retrieve Content:\n        command: cat data/hello.txt\n</code></pre> <p>Copy the catalog during the failed execution to the debugging execution and retry the step. We give it a run_id <code>debug-pipeline</code></p> <p>cp .catalog/wrong-file-name debug-pipeline</p> <p>and retry with the fix:</p> <p><code>runnable execute -f examples/retry-fail.yaml -c examples/configs/mocked-config-debug.yaml --run-id debug-pipeline</code></p>"},{"location":"example/dataflow/","title":"Dataflow","text":"<p>In runnable, we distinguish between 2 types of data that steps can communicate with each other.</p> <code>Parameters</code> <p>Parameters can be thought of input and output arguments of functions. runnable supports pydantic models both as input and return types of functions.</p> <code>Files</code> <p>Data files or objects created by individual tasks of the pipeline can be passed to downstream tasks using catalog. This can be controlled either by the configuration or by python API.</p>"},{"location":"example/dataflow/#flow_of_parameters","title":"Flow of Parameters","text":"<p>The initial parameters of the pipeline can set by using a <code>yaml</code> file and presented during execution</p> <p><code>--parameters-file, -parameters</code> while using the runnable CLI</p> <p>or by using <code>parameters_file</code> with the sdk.</p> Initial ParametersPydantic model representation Defining initial parameters<pre><code># The below is assumed to be examples/parameters_initial.yaml # (2)\nsimple: 1\ninner: # (1)\n    x: 3\n    y: \"hello\"\n</code></pre> <ol> <li>You can create deeply nested parameter structures.</li> <li>You can name it as you want.</li> </ol> <p>The parameter structure can be represented as a pydantic model within your code.</p> Pydantic model representation<pre><code>from pydantic import BaseModel\n\nclass InnerModel(BaseModel): # (1)\n    x: int\n    y: str\n\nclass NestedModel(BaseModel): # (2)\n    simple: int\n    inner: InnerModel\n</code></pre> <ol> <li>Represents the <code>inner</code> nested model of parameters.</li> <li>Represents all parameters defined in initial parameters.</li> </ol>"},{"location":"example/dataflow/#accessing_parameters","title":"Accessing parameters","text":"Application native wayUsing the python APIUsing environment variables <p>No <code>import runnable</code> !!!</p> <p>A lot of design emphasis is to avoid \"import runnable\" and keep the function signature native to the application. runnable also has API's get_parameter and set_parameter if they are handy.</p> <pre><code>\"\"\"\nThe initial parameters defined in the parameters file are:\nsimple: 1\ninner:\n  x: 10\n  y: \"hello\"\n\nYou can execute this pipeline by: python examples/parameters.py\n\n\"\"\"\n\nfrom pydantic import BaseModel\n\n\nclass InnerModel(BaseModel):\n    \"\"\"\n    Captures the \"inner\" part of the parameters.\n    The model definition can be as nested as you want.\n    \"\"\"\n\n    x: int\n    y: str\n\n\nclass NestedModel(BaseModel):  # (1)\n    \"\"\"\n    Captures the whole parameter space of the application.\n    \"\"\"\n\n    simple: int\n    inner: InnerModel\n\n\ndef display(simple: int, inner: InnerModel):  # (2)\n    \"\"\"\n    The parameter \"simple\" and \"inner\" can be accessed by name.\n    runnable understands the parameter \"inner\" as a pydantic model from\n    annotation and casts it as a pydantic model.\n    \"\"\"\n    print(simple)\n    print(inner)\n\n\ndef return_parameters(simple: int, inner: InnerModel) -&gt; NestedModel:  # (3)\n    \"\"\"\n    The parameter \"simple\" and \"inner\" can be accessed by name.\n    You can redefine the parameters by returning a pydantic model.\n    \"\"\"\n    simple = 2\n    inner.x = 30\n    inner.y = \"Hello Universe!!\"\n\n    return simple, inner\n\n\n\"\"\"\nThe below code is only to provide a full working example.\n\nIn the real world, you can \"box runnable\" in pipeline definition either in\npython or yaml without cluttering your application code.\n\"\"\"\n\n\ndef main():\n    from runnable import Pipeline, PythonTask\n\n    display_task = PythonTask(name=\"display\", function=display)\n\n    return_parameters_task = PythonTask(\n        name=\"return_parameters\",\n        function=return_parameters,\n        returns=[\n            \"simple\",\n            \"inner\",\n        ],\n        terminate_with_success=True,\n    )\n\n    pipeline = Pipeline(\n        steps=[display_task, return_parameters_task],\n        add_terminal_nodes=True,\n    )\n\n    _ = pipeline.execute(parameters_file=\"examples/parameters_initial.yaml\")\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <ol> <li>Create a pydantic model to represent the parameters.</li> <li>Access those parameters by name. The annotations are used to cast to correct models.</li> <li>Return the modified parameters for downstream steps. The return type should be always a pydantic model.</li> </ol> <p>Using API</p> <p>Using the python API gives you access to the parameters without changing the signature of the functions. Also, this the preferred way to access the parameters in notebooks. (1)</p> <ol> <li>We use parameters in notebooks but they can only support simple types while the API supports rich pydantic models.</li> </ol> <pre><code>\n</code></pre> <ol> <li>To get the parameters as pydantic models, you can hint the type using <code>cast_as</code></li> <li>Downstream steps could access the modified parameters.</li> </ol> <p>Using Env</p> <p>Tasks of type shell use this mechanism to access parameters.</p> <p>There are richer ways to pass parameters in runnable if you are using only python in your application. This mechanism helps when you have non-python code as part of your application.</p> Using shell to access parameters<pre><code>dag:\n  description: |\n    This is a simple pipeline that demonstrates how to use\n    environment variables to access parameters.\n\n    All parameters are prefixed by runnable_PRM_ in json serialized form.\n    To set a parameter, you need to set the environment variable with the prefix\n\n    You can run this example:\n    runnable execute -f examples/parameters_env.yaml -p examples/parameters_initial.yaml\n\n  start_at: display\n  steps:\n    display:\n      type: task\n      command_type: shell\n      command: |\n        env | grep simple\n        env | grep inner\n      # prints simple=1\n      # prints inner={\"x\": 10, \"y\": \"hello world!!\"}\n      next: update params\n    update params:\n      type: task\n      command_type: shell\n      next: display again\n      command: |\n        export simple=10 &amp;&amp;\n        export inner='{\"x\": 100, \"y\": \"hello universe!!\"}'\n      returns: # collect simple and inner from environment\n        - name: simple\n          kind: json\n        - name: inner\n          kind: json\n    display again:\n      type: task\n      command_type: shell\n      command: |\n        env | grep simple\n        env | grep inner\n      # prints simple=1\n      # prints inner={\"x\": 100, \"y\": \"hello universe!!\"}\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <ol> <li>Show all the parameters prefixed by runnable_PRM_</li> <li>Set new values of the parameters as environment variables prefixed by runnable_PRM_</li> <li>Consume the parameters like you would using python.</li> </ol>"},{"location":"example/dataflow/#flow_of_files","title":"Flow of Files","text":"<p>runnable stores all the artifacts/files/logs generated by <code>task</code> nodes in a central storage called catalog. The catalog is indexed by the <code>run_id</code> of the pipeline and is unique for every execution of the pipeline.</p> <p>Any <code>task</code> of the pipeline can interact with the <code>catalog</code> to get and put artifacts/files as part of the execution.</p> <p>Conceptually, the flow is:</p> <pre><code>flowchart LR\n    subgraph Task\n        direction LR\n        get(\"get\n        &amp;#x1F4C1 data folder\")\n        exe(Execute code)\n        put(\"put\n        &amp;#x1F4C1 data folder\")\n    end\n\n    subgraph Catalog\n    direction BT\n        Data[&amp;#x1F4C1 run id]\n    end\nData --&gt; get\nput --&gt; Data\nget --&gt; exe\nexe --&gt; put</code></pre> <p>The <code>catalog</code> for an execution has the same structure as the <code>root</code> of the project. You can access content as if you are accessing files relative to the project root.</p> Example Configurationpipeline in yamlpython sdkpython API <pre><code>catalog:\n  type: file-system # (1)\n</code></pre> <ol> <li>Use local file system as a central catalog, defaults to <code>.catalog</code></li> <li>By default, runnable uses <code>data</code> folder as the directory containing the user data.</li> </ol> <p>Python functions</p> <p>We have used shell for these operations for convenience but you can use python functions to create content and retrieve content.</p> <p>For example, the below functions can be used in steps Create Content and Retrieve Content. <pre><code>def create_content():\n    with open(\"data/hello.txt\") as f:\n        f.write(\"hello from runnable\")\n\ndef retrieve_content():\n    with open(\"data/hello.txt\") as f:\n      print(f.read())\n</code></pre></p> <pre><code>dag:\n  description: |\n    This is a simple pipeline that demonstrates passing data between steps.\n\n    1. Setup: We setup a data folder, we ignore if it is already present\n    2. Create Content: We create a \"hello.txt\" and \"put\" the file in catalog\n    3. Clean up to get again: We remove the data folder. Note that this is stubbed to prevent\n      accidental deletion of your contents. You can change type to task to make really run.\n    4. Retrieve Content: We \"get\" the file \"hello.txt\" from the catalog and show the contents\n    5. Cleanup: We remove the data folder. Note that this is stubbed to prevent accidental deletion.\n\n\n    You can run this pipeline by:\n       runnable execute -f examples/catalog.yaml -c examples/configs/fs-catalog.yaml\n  start_at: Setup\n  steps:\n    Setup:\n      type: task\n      command_type: shell\n      command: mkdir -p data # (1)\n      next: Create Content\n    Create Content:\n      type: task\n      command_type: shell\n      command: |\n        echo \"Hello from runnable\" &gt;&gt; data/hello.txt\n      next: Clean up to get again\n      catalog: # (2)\n        put:\n          - data/hello.txt\n    Clean up to get again:\n      type: stub # (3)\n      command_type: shell\n      command: rm -rf data\n      next: Retrieve Content\n    Retrieve Content:\n      type: task\n      command_type: shell\n      command: cat data/hello.txt # (4)\n      catalog:\n        get:\n          - \"data/hello.txt\" # You can use wild cards following glob pattern\n      next: Clean up\n    Clean up:\n      type: stub # (6)\n      command_type: shell\n      command: rm -rf data\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <ol> <li>Make a <code>data</code> folder if it does not already exist.</li> <li>As the <code>compute_data_folder</code> is defined to <code>.</code>, all paths should be relative to <code>.</code>. Put the file <code>hello.txt</code> in <code>data</code> folder into the catalog.</li> <li>We have intentionally made this <code>stub</code> node to prevent accidentally deleting your content. Please make it a <code>task</code> to actually delete the <code>data</code> folder.</li> <li>Should print \"Hello from runnable\" as the content of the <code>hello.txt</code>.</li> <li>Override the default <code>.</code> as <code>compute_data_folder</code> to <code>data</code>. All interactions should then be relative to <code>data</code> folder.</li> <li>Same as above, make it a <code>task</code> to actually delete the <code>data</code> folder</li> </ol> <p>Python functions</p> <p>We have used shell for these operations for convenience but you can use python functions to create content and retrieve content.</p> <p>For example, the below functions can be used in steps create and retrieve. <pre><code>def create_content():\n    with open(\"data/hello.txt\") as f:\n        f.write(\"hello from runnable\")\n\ndef retrieve_content():\n    with open(\"data/hello.txt\") as f:\n      print(f.read())\n</code></pre></p> <pre><code>\"\"\"\nExample pipeline to demonstrate passing data files between tasks.\n\nYou can run this pipeline by:\n    python run examples/catalog.py\n\"\"\"\n\nfrom runnable import Catalog, Pipeline, ShellTask, Stub\n\n\ndef main():\n    # Make the data folder if it does not exist\n    set_up = ShellTask(\n        name=\"Setup\",\n        command=\"mkdir -p data\",\n    )\n\n    # create a catalog instruction to put a file into the catalog\n    create_catalog = Catalog(put=[\"data/hello.txt\"])\n    # This task will create a file in the data folder and attaches the instruction\n    # to put the file into the catalog.\n    create = ShellTask(\n        name=\"Create Content\",\n        command='echo \"Hello from runnable\" &gt;&gt; data/hello.txt',\n        catalog=create_catalog,\n    )\n\n    # We remove the data folder to ensure that the data folder is cleaned up.\n    # This is to show that the retrieve step just does not read from existing data\n    # This step is stubbed to prevent any accidental deletion, make it a ShellTask\n    first_clean = Stub(\n        name=\"Clean up to get again\",\n        command=\"rm -rf data\",\n    )\n\n    # We create a catalog instruction to retrieve a file from the catalog\n    # Here we use \"compute_folder_name\" to point to the directory of interest.\n    # You can alteratively ignore compute_folder_name and get \"data/hello.txt\"\n    # You can use wild card following glob patterns to retrieve multiple files.\n    get_catalog = Catalog(get=[\"data/hello.txt\"])\n    # This task will retrieve the file from the catalog and attach the instruction\n    # to retrieve the file from the catalog before execution.\n    retrieve = ShellTask(\n        name=\"Retrieve Content\",\n        command=\"cat data/hello.txt\",\n        catalog=get_catalog,\n    )\n\n    # We clean up. Note that this step is stubbed to prevent any accidental deletion,\n    # Make it a ShellTask to actually clean up.\n    clean_up = Stub(\n        name=\"Clean up\",\n        command=\"rm -rf data\",\n        terminate_with_success=True,\n    )\n\n    pipeline = Pipeline(\n        steps=[set_up, create, first_clean, retrieve, clean_up],\n        add_terminal_nodes=True,\n    )\n\n    # override the default configuration to use file-system catalog.\n    pipeline.execute(configuration_file=\"examples/configs/fs-catalog.yaml\")\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>\n</code></pre>"},{"location":"example/example/","title":"Example","text":"<p>runnable revolves around the concept of pipelines or workflows. Pipelines defined in runnable are translated into other workflow engine definitions like Argo workflows or AWS step functions.</p>"},{"location":"example/example/#example_pipeline_definition","title":"Example Pipeline definition","text":"<p>A contrived example of data science workflow without any implementation.</p> <p>Simple pipeline</p> <p>In this extremely reduced example, we acquire data from different sources, clean it and shape it for analysis. Features are then engineered from the clean data to run data science modelling.</p> <pre><code>%%{ init: { 'flowchart': { 'curve': 'linear' } } }%%\nflowchart TD\n\n    step1:::green\n    step1([Acquire data]) --&gt; step2:::green\n    step2([Prepare data]) --&gt; step3:::green\n    step3([Extract features]) --&gt; step4:::green\n    step4([Model]) --&gt; suc([success]):::green\n\n    classDef green stroke:#0f0\n</code></pre> <p>This pipeline can be represented in runnable as below:</p> yamlpythonRun log <pre><code>dag:\n  description: |\n    This is a stubbed pipeline that does 4 steps in sequence.\n    All the steps are mocked and they will just pass through.\n    Use this pattern to define the skeleton of your pipeline and flesh out the steps later.\n\n    You can run this pipeline by runnable execute -f examples/contrived.yaml\n\n  start_at: Acquire data\n  steps:\n    Acquire data:\n      type: stub # (1)\n      next: Prepare data # (2)\n    Prepare data:\n      type: stub\n      next: Extract features\n    Extract features:\n      type: stub\n      next: Model\n    Model:\n      type: stub\n      next: success\n    success: # (3)\n      type: success\n    fail: # (4)\n      type: fail\n</code></pre> <ol> <li><code>stub</code> nodes are mock nodes and always succeed.</li> <li>Execute the <code>next</code> node if it succeeds.</li> <li>This marks the pipeline to be be successfully completed.</li> <li>Any failure in the execution of the node will, by default, reach this step.</li> </ol> <pre><code>\"\"\"\nThis is a stubbed pipeline that does 4 steps in sequence.\nAll the steps are mocked and they will just pass through.\nUse this pattern to define the skeleton of your pipeline and flesh out the steps later.\n\nYou can run this pipeline by python run examples/contrived.py\n\"\"\"\n\nfrom runnable import Pipeline, Stub\n\n\ndef main():\n    acquire_data = Stub(name=\"Acquire Data\", next=\"Prepare Data\")  # (1)\n\n    prepare_data = Stub(name=\"Prepare Data\")\n\n    extract_features = Stub(name=\"Extract Features\")\n\n    modelling = Stub(name=\"Model\", terminate_with_success=True)  # (2)\n\n    pipeline = Pipeline(\n        steps=[acquire_data, prepare_data, extract_features, modelling],\n        add_terminal_nodes=True,\n    )  # (4)\n\n    run_log = pipeline.execute()  # (5)\n    print(run_log)\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <ol> <li>You can specify dependencies by using the <code>next</code> while creating the node or defer it for later.</li> <li><code>terminate_with_success</code> indicates the pipeline to be successfully complete.</li> <li>Alternative ways to define dependencies, <code>&gt;&gt;</code>, <code>&lt;&lt;</code>, <code>depends_on</code>. Choose the style that you prefer.</li> <li><code>add_terminal_nodes</code> adds success and fail states to the pipeline.</li> <li>A very rich run log that captures different properties of the run for maximum reproducibility.</li> </ol> <p>Please see Run log for more detailed information about the structure.</p> <pre><code>{\n    \"run_id\": \"vain-hopper-0731\", // (1)\n    \"dag_hash\": \"\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\", / (2)\n    \"steps\": {\n        \"Acquire Data\": {\n            \"name\": \"Acquire Data\", // (3)\n            \"internal_name\": \"Acquire Data\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"stub\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"399b0d42f4f28aaeeb2e062bb0b938d50ff1595c\", // (4)\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2023-11-16 07:31:39.929797\",\n                    \"end_time\": \"2023-11-16 07:31:39.929815\",\n                    \"duration\": \"0:00:00.000018\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {}, // (5)\n            \"branches\": {},\n            \"data_catalog\": [] // (6)\n        },\n        \"Prepare Data\": {\n            \"name\": \"Prepare Data\",\n            \"internal_name\": \"Prepare Data\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"stub\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"399b0d42f4f28aaeeb2e062bb0b938d50ff1595c\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2023-11-16 07:31:39.993807\",\n                    \"end_time\": \"2023-11-16 07:31:39.993828\",\n                    \"duration\": \"0:00:00.000021\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"Extract Features\": {\n            \"name\": \"Extract Features\",\n            \"internal_name\": \"Extract Features\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"stub\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"399b0d42f4f28aaeeb2e062bb0b938d50ff1595c\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2023-11-16 07:31:40.056403\",\n                    \"end_time\": \"2023-11-16 07:31:40.056420\",\n                    \"duration\": \"0:00:00.000017\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"Model\": {\n            \"name\": \"Model\",\n            \"internal_name\": \"Model\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"stub\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"399b0d42f4f28aaeeb2e062bb0b938d50ff1595c\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2023-11-16 07:31:40.118268\",\n                    \"end_time\": \"2023-11-16 07:31:40.118285\",\n                    \"duration\": \"0:00:00.000017\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"399b0d42f4f28aaeeb2e062bb0b938d50ff1595c\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2023-11-16 07:31:40.176718\",\n                    \"end_time\": \"2023-11-16 07:31:40.176774\",\n                    \"duration\": \"0:00:00.000056\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": { // (7)\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"placeholders\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"buffered\",\n            \"service_type\": \"run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\",\n            \"compute_data_folder\": \"data\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"\",\n        \"parameters_file\": \"\",\n        \"configuration_file\": \"\",\n        \"tag\": \"\",\n        \"run_id\": \"vain-hopper-0731\",\n        \"variables\": {},\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": { // (8)\n            \"start_at\": \"Acquire Data\",\n            \"name\": \"\",\n            \"description\": \"\",\n            \"max_time\": 86400,\n            \"internal_branch_name\": \"\",\n            \"steps\": {\n                \"Acquire Data\": {\n                    \"type\": \"stub\",\n                    \"name\": \"Acquire Data\",\n                    \"internal_name\": \"Acquire Data\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                },\n                \"Prepare Data\": {\n                    \"type\": \"stub\",\n                    \"name\": \"Prepare Data\",\n                    \"internal_name\": \"Prepare Data\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                },\n                \"Extract Features\": {\n                    \"type\": \"stub\",\n                    \"name\": \"Extract Features\",\n                    \"internal_name\": \"Extract Features\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                },\n                \"Model\": {\n                    \"type\": \"stub\",\n                    \"name\": \"Model\",\n                    \"internal_name\": \"Model\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\",\n                    \"internal_name\": \"success\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\",\n                    \"internal_name\": \"fail\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                }\n            }\n        },\n        \"dag_hash\": \"\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre> <ol> <li>Unique execution id or run id for every run of the pipeline.</li> <li>The status of the execution, one of success, fail or processing.</li> <li>Steps as defined in the pipeline configuration.</li> <li>git hash of the code that was used to run the pipeline.</li> <li>Optional user defined metrics during the step execution. These are also made available to the experiment tracking    tool, if they are configured.</li> <li>Data files that are <code>get</code> or <code>put</code> into a central storage during execution of the step.</li> <li>The configuration used to run the pipeline.</li> <li>The pipeline definition.</li> </ol> <p>Independent of the platform it is run on,</p> <ul> <li> <p> The pipeline definition remains the same from an author point of view. The data scientists are always part of the process and contribute to the development even in production environments.</p> </li> <li> <p> The run log remains the same except for the execution configuration enabling users to debug the pipeline execution in lower environments for failed executions or to validate the expectation of the execution.</p> </li> </ul>"},{"location":"example/example/#example_configuration","title":"Example configuration","text":"<p>To run the pipeline in different environments, we just provide the required configuration.</p> Default ConfigurationArgo ConfigurationTranspiled Workflow <pre><code>executor:\n  type: local # (1)\n\nrun_log_store:\n  type: buffered # (2)\n\ncatalog:\n  type: do-nothing # (3)\n\nsecrets:\n  type: do-nothing # (4)\n</code></pre> <ol> <li>Run the pipeline in local environment.</li> <li>Use the buffer as run log, this will not persist the run log to disk.</li> <li>Do not move any files to central storage.</li> <li>Do not use any secrets manager.</li> <li>Do not integrate with any experiment tracking tools</li> </ol> <p>To render the pipeline in argo specification, mention the configuration during execution.</p> <p>yaml:</p> <p><code>runnable execute -f examples/contrived.yaml -c examples/configs/argo-config.yaml</code></p> <p>python:</p> <p>Please refer to containerised environments for more information.</p> <p>runnable_CONFIGURATION_FILE=examples/configs/argo-config.yaml python examples/contrived.py &amp;&amp; runnable execute -f runnable-pipeline.yaml -c examples/configs/argo-config.yaml</p> Argo Configuration<pre><code>executor:\n  type: \"argo\" # (1)\n  config:\n    image: runnable:demo # (2)\n    service_account_name: default-editor\n    persistent_volumes: # (3)\n      - name: runnable-volume\n        mount_path: /mnt\n\nrun_log_store: # (4)\n  type: file-system\n  config:\n    log_folder: /mnt/run_log_store\n\ncatalog:\n  type: do-nothing\n\nsecrets:\n  type: do-nothing\n\nexperiment_tracker:\n  type: do-nothing\n</code></pre> <ol> <li>Use argo workflows as the execution engine to run the pipeline.</li> <li>Run this docker image for every step of the pipeline. Please refer to containerised environments for more details.</li> <li>Mount the volume from Kubernetes persistent volumes (runnable-volume) to /mnt directory.</li> <li>Resource constraints for the container runtime.</li> <li>Since every step runs in a container, the run log should be persisted. Here we are using the file-system as our run log store.</li> <li>Kubernetes PVC is mounted to every container as <code>/mnt</code>, use that to surface the run log to every step.</li> </ol> <p>The below is the same workflow definition in argo specification.</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: runnable-dag-\n  annotations: {}\n  labels: {}\nspec:\n  activeDeadlineSeconds: 172800\n  entrypoint: runnable-dag\n  podGC:\n    strategy: OnPodCompletion\n  retryStrategy:\n    limit: \"0\"\n    retryPolicy: Always\n    backoff:\n      duration: \"120\"\n      factor: 2\n      maxDuration: \"3600\"\n  serviceAccountName: default-editor\n  templates:\n    - name: runnable-dag\n      failFast: true\n      dag:\n        tasks:\n          - name: Acquire-data-stub-zl7utt\n            template: Acquire-data-stub-zl7utt\n            depends: \"\"\n          - name: Prepare-data-stub-jkn77g\n            template: Prepare-data-stub-jkn77g\n            depends: Acquire-data-stub-zl7utt.Succeeded\n          - name: Extract-features-stub-jdonf3\n            template: Extract-features-stub-jdonf3\n            depends: Prepare-data-stub-jkn77g.Succeeded\n          - name: Model-stub-42qnma\n            template: Model-stub-42qnma\n            depends: Extract-features-stub-jdonf3.Succeeded\n          - name: success-success-mk4nqv\n            template: success-success-mk4nqv\n            depends: Model-stub-42qnma.Succeeded\n    - name: Acquire-data-stub-zl7utt\n      container:\n        image: runnable:demo\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - Acquire%data\n          - --log-level\n          - WARNING\n          - --file\n          - examples/contrived.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n    - name: Prepare-data-stub-jkn77g\n      container:\n        image: runnable:demo\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - Prepare%data\n          - --log-level\n          - WARNING\n          - --file\n          - examples/contrived.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n    - name: Extract-features-stub-jdonf3\n      container:\n        image: runnable:demo\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - Extract%features\n          - --log-level\n          - WARNING\n          - --file\n          - examples/contrived.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n    - name: Model-stub-42qnma\n      container:\n        image: runnable:demo\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - Model\n          - --log-level\n          - WARNING\n          - --file\n          - examples/contrived.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n    - name: success-success-mk4nqv\n      container:\n        image: runnable:demo\n        command:\n          - runnable\n          - execute_single_node\n          - \"{{workflow.parameters.run_id}}\"\n          - success\n          - --log-level\n          - WARNING\n          - --file\n          - examples/contrived.yaml\n          - --config-file\n          - examples/configs/argo-config.yaml\n        volumeMounts:\n          - name: executor-0\n            mountPath: /mnt\n        imagePullPolicy: \"\"\n        resources:\n          limits:\n            memory: 1Gi\n            cpu: 250m\n          requests:\n            memory: 1Gi\n            cpu: 250m\n  templateDefaults:\n    activeDeadlineSeconds: 7200\n    timeout: 10800s\n  arguments:\n    parameters:\n      - name: run_id\n        value: \"{{workflow.uid}}\"\n  volumes:\n    - name: executor-0\n      persistentVolumeClaim:\n        claimName: runnable-volume\n</code></pre>"},{"location":"example/experiment-tracking/","title":"Experiment tracking","text":"<p>Metrics in data science projects summarize important information about the execution and performance of the experiment.</p> <p>runnable captures this information as part of the run log and also provides an interface to experiment tracking tools like mlflow or Weights and Biases.</p>"},{"location":"example/experiment-tracking/#example","title":"Example","text":"pythonyamlconfigurationRun logmlflow <ol> <li>Nested metrics are possible as pydantic models.</li> <li>Using mlflow as experiment tracking tool.</li> </ol> <p>Assumed to be present in <code>examples/configs/mlflow-config.yaml</code></p> <pre><code>\n</code></pre> <p>The captured metrics as part of the run log are highlighted.</p> <pre><code>{\n    \"run_id\": \"clean-ride-1048\",\n    \"dag_hash\": \"\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {\n        \"Emit Metrics\": {\n            \"name\": \"Emit Metrics\",\n            \"internal_name\": \"Emit Metrics\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"0b62e4c661a4b4a2187afdf44a7c64520374202d\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-10 10:48:10.089266\",\n                    \"end_time\": \"2024-01-10 10:48:10.092541\",\n                    \"duration\": \"0:00:00.003275\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {\n                \"spam\": \"hello\",\n                \"eggs\": {\n                    \"ham\": \"world\"\n                },\n                \"answer\": 42.0,\n                \"is_it_true\": false\n            },\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"Emit_Metrics.execution.log\",\n                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                    \"catalog_relative_path\": \"clean-ride-1048/Emit_Metrics.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"0b62e4c661a4b4a2187afdf44a7c64520374202d\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-01-10 10:48:10.585832\",\n                    \"end_time\": \"2024-01-10 10:48:10.585937\",\n                    \"duration\": \"0:00:00.000105\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"placeholders\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"buffered\",\n            \"service_type\": \"run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"mlflow\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"\",\n        \"parameters_file\": \"\",\n        \"configuration_file\": \"examples/configs/mlflow-config.yaml\",\n        \"tag\": \"\",\n        \"run_id\": \"clean-ride-1048\",\n        \"variables\": {},\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"Emit Metrics\",\n            \"name\": \"\",\n            \"description\": \"\",\n            \"internal_branch_name\": \"\",\n            \"steps\": {\n                \"Emit Metrics\": {\n                    \"type\": \"task\",\n                    \"name\": \"Emit Metrics\",\n                    \"internal_name\": \"Emit Metrics\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\",\n                    \"internal_name\": \"success\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\",\n                    \"internal_name\": \"fail\",\n                    \"internal_branch_name\": \"\",\n                    \"is_composite\": false\n                }\n            }\n        },\n        \"dag_hash\": \"\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre> <p>The metrics are also sent to mlflow.</p> <p> mlflow UI for the execution. The run_id remains the same as the run_id of runnable </p>"},{"location":"example/reproducibility/","title":"Reproducibility","text":"<p>runnable stores a variety of information about the current execution in run log. The run log is internally used for keeping track of the execution (status of different steps, parameters, etc) but also has rich information for reproducing the state at the time of pipeline execution.</p> <p>The following are \"invisibly\" captured as part of the run log:</p> <ul> <li>Code: The <code>git</code> commit hash of the code used to run a pipeline is stored as part of the run log against every step.</li> <li>Data hash: The data hash of the file passing through the catalog is stored as part of the run log. Since the catalog itself is indexed against the execution id, it is easy to recreate the exact state of the data used in the pipeline execution.</li> <li>Configuration: The configuration of the pipeline (dag definition, execution configuration) is also stored as part of the run log.</li> </ul> <p>Invisible?</p> <p>Reproducibility should not be a \"nice to have\" but is a must in data science projects. We believe that it should not be left to the data scientist to be conscious of it but should be done without any active intervention.</p> <p>Below we show an example pipeline and the different layers of the run log.</p> Example pipelineGeneral run log attributesLogs captured against a stepCaptured configuration <p>Example</p> <p>This example pipeline is the same as the data flow pipeline showcasing flow of files. The create content step creates writes a new file which is stored in the catalog and the retrieve content gets it from the catalog.</p> simple data passing pipeline<pre><code>\n</code></pre> <p>Info</p> <p>This section of the run log is about the over all status of the execution. It has information about the run_id, the execution status, re-run indicators and the final state of the parameters.</p> <pre><code>{\n    \"run_id\": \"greedy-yonath-1608\", // (1)\n    \"dag_hash\": \"\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"SUCCESS\",\n    ...\n    \"parameters\": {}, // (2)\n}\n</code></pre> <ol> <li>The unique run_id of the execution.</li> <li>The parameters at the end of the pipeline.</li> </ol> <p>Info</p> <p>The information stored against an execution of a step. We capture the git commit id's, data hashes, parameters at the point of execution. The execution logs are also stored in the catalog against the run id.</p> <pre><code>\"create_content\": { // (1)\n    \"name\": \"create_content\",\n    \"internal_name\": \"create_content\",\n    \"status\": \"SUCCESS\", // (2)\n    \"step_type\": \"task\",\n    \"message\": \"\",\n    \"mock\": false,\n    \"code_identities\": [\n        {\n            \"code_identifier\": \"ff60e7fa379c38adaa03755977057cd10acc4baa\",  // (3)\n            \"code_identifier_type\": \"git\",\n            \"code_identifier_dependable\": true, // (4)\n            \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n            \"code_identifier_message\": \"\"\n        }\n    ],\n    \"attempts\": [\n        {\n            \"attempt_number\": 1,\n            \"start_time\": \"2023-12-15 16:08:51.869129\",\n            \"end_time\": \"2023-12-15 16:08:51.878428\",\n            \"duration\": \"0:00:00.009299\",\n            \"status\": \"SUCCESS\",\n            \"message\": \"\",\n            \"parameters\": {} // (5)\n        }\n    ],\n    \"user_defined_metrics\": {},\n    \"branches\": {},\n    \"data_catalog\": [\n        {\n            \"name\": \"data/hello.txt\",  // (6)\n            \"data_hash\": \"c2e6b3d23c045731bf40a036aa6f558c9448da247e0cbb4ee3fcf10d3660ef18\", // (7)\n            \"catalog_relative_path\": \"greedy-yonath-1608/data/hello.txt\",\n            \"catalog_handler_location\": \".catalog\",\n            \"stage\": \"put\"\n        },\n        {\n            \"name\": \"create_content\",  // (8)\n            \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n            \"catalog_relative_path\": \"greedy-yonath-1608/create_content\",\n            \"catalog_handler_location\": \".catalog\",\n            \"stage\": \"put\"\n        }\n    ]\n},\n</code></pre> <ol> <li>The name of step.</li> <li>The status of the execution of the step.</li> <li>The git sha of the code at the point of execution of the pipeline.</li> <li>is True if the branch is clean, false otherwise.</li> <li>The parameters at the point of execution of the step.</li> <li>The name of the file that was \"put\" in the catalog by the step.</li> <li>The hash of the dataset put in the catalog.</li> <li>The execution logs of the step put in the catalog.</li> </ol> <p>Info</p> <p>The information about the configuration used to run the pipeline. It includes the configuration of the different <code>services</code> used, the pipeline definition and state of variables used at the time of execution of the pipeline.</p> <pre><code>\"run_config\": {\n    \"executor\": { // (1)\n        \"service_name\": \"local\",\n        \"service_type\": \"executor\",\n        \"enable_parallel\": false,\n        \"placeholders\": {}\n    },\n    \"run_log_store\": { // (2)\n        \"service_name\": \"buffered\",\n        \"service_type\": \"run_log_store\"\n    },\n    \"secrets_handler\": { // (3)\n        \"service_name\": \"do-nothing\",\n        \"service_type\": \"secrets\"\n    },\n    \"catalog_handler\": { // (4)\n        \"service_name\": \"file-system\",\n        \"service_type\": \"catalog\",\n        \"compute_data_folder\": \".\"\n    },\n    \"experiment_tracker\": { // (5)\n        \"service_name\": \"do-nothing\",\n        \"service_type\": \"experiment_tracker\"\n    },\n    \"pipeline_file\": \"\",    //  (6\n    \"parameters_file\": \"\", // (7)\n    \"configuration_file\": \"examples/configs/fs-catalog.yaml\", // (8)\n    \"tag\": \"\",\n    \"run_id\": \"greedy-yonath-1608\",\n    \"variables\": {},\n    \"use_cached\": false,\n    \"original_run_id\": \"\",\n    \"dag\": { // (9)\n        \"start_at\": \"create_content\",\n        \"name\": \"\",\n        \"description\": \"\",\n        \"max_time\": 86400,\n        \"internal_branch_name\": \"\",\n        \"steps\": {\n            \"create_content\": {\n                \"type\": \"task\",\n                \"name\": \"create_content\",\n                \"internal_name\": \"create_content\",\n                \"internal_branch_name\": \"\",\n                \"is_composite\": false\n            },\n            \"retrieve_content\": {\n                \"type\": \"task\",\n                \"name\": \"retrieve_content\",\n                \"internal_name\": \"retrieve_content\",\n                \"internal_branch_name\": \"\",\n                \"is_composite\": false\n            },\n            \"success\": {\n                \"type\": \"success\",\n                \"name\": \"success\",\n                \"internal_name\": \"success\",\n                \"internal_branch_name\": \"\",\n                \"is_composite\": false\n            },\n            \"fail\": {\n                \"type\": \"fail\",\n                \"name\": \"fail\",\n                \"internal_name\": \"fail\",\n                \"internal_branch_name\": \"\",\n                \"is_composite\": false\n            }\n        }\n    },\n    \"dag_hash\": \"\",\n    \"execution_plan\": \"chained\"\n}\n</code></pre> <ol> <li>The configuration of the <code>executor</code></li> <li>The configuration of <code>run log store</code>. The location where these logs are stored.</li> <li>The configuration of the secrets manager.</li> <li>The configuration of the catalog manager.</li> <li>The configuration of experiment tracker.</li> <li>The pipeline definition file, empty in this case as we use the SDK.</li> <li>The initial parameters file used for the execution.</li> <li>The configuration file used for the execution.</li> <li>The definition of the DAG being executed.</li> </ol> <p>This structure of the run log is the same independent of where the pipeline was executed. This enables you to reproduce a failed execution in complex environments on local environments for easier debugging.</p>"},{"location":"example/retry-after-failure/","title":"Retry after failure","text":"<p>runnable allows you to debug and recover from a failure during the execution of pipeline. The pipeline can be restarted in any suitable environment for debugging.</p> <p>Example</p> <p>A pipeline that is transpiled to argo workflows can be re-run on your local compute for debugging purposes. The only caveat is that, your local compute should have access to run log of the failed execution (1), generated catalog artifacts (2) from the the failed execution.</p> <ol> <li>Access to the run log can be as simple as copy the json file to your local compute.</li> <li>Generated catalog artifacts can be sourced from <code>file-system</code> which is your local folder.</li> </ol> <p>Below is an example of retrying a pipeline that failed.</p> Failed pipelineFailed run logFixed pipelineFixed Run log <p>Note</p> <p>You can run this pipeline on your local machine by</p> <p><code>runnable execute -f examples/retry-fail.yaml -c examples/configs/fs-catalog-run_log.yaml --run-id wrong-file-name</code></p> <p>Note that we have specified the <code>run_id</code> to be something we can use later. The execution logs of the steps in the catalog will show the reason of the failure.</p> Pipeline that fails<pre><code>dag:\n  description: |\n    This is a simple pipeline that demonstrates retrying failures.\n\n    1. Setup: We setup a data folder, we ignore if it is already present\n    2. Create Content: We create a \"hello.txt\" and \"put\" the file in catalog\n    3. Retrieve Content: We \"get\" the file \"hello.txt\" from the catalog and show the contents\n    5. Cleanup: We remove the data folder. Note that this is stubbed to prevent accidental deletion.\n\n\n    You can run this pipeline by:\n       runnable execute -f examples/retry-fail.yaml -c examples/configs/fs-catalog-run_log.yaml \\\n        --run-id wrong-file-name\n  start_at: Setup\n  steps:\n    Setup:\n      type: task\n      command_type: shell\n      command: mkdir -p data # (1)\n      next: Create Content\n    Create Content:\n      type: task\n      command_type: shell\n      command: |\n        echo \"Hello from runnable\" &gt;&gt; data/hello.txt\n      next: Retrieve Content\n      catalog: # (2)\n        put:\n          - data/hello.txt\n    Retrieve Content:\n      type: task\n      command_type: shell\n      command: cat data/hello1.txt # (3)\n      catalog:\n        get:\n          - \"data/hello.txt\" # You can use wild cards following glob pattern\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <ol> <li>We make a data folder to store content.</li> <li>Puts a file in the data folder and catalogs it for downstream steps.</li> <li>It will fail here as there is no file called <code>hello1.txt</code> in the data folder.</li> <li>Get the file, <code>hello.txt</code> generated from previous steps into data folder.</li> </ol> <p>Please note the overall status of the pipeline in line #7 to be <code>FAIL</code>. The step log of the failed step is also marked with status <code>FAIL</code>.</p> <pre><code>{\n    \"run_id\": \"wrong-file-name\",\n    \"dag_hash\": \"13f7c1b29ebb07ce058305253171ceae504e1683\",\n    \"use_cached\": false,\n    \"tag\": \"\",\n    \"original_run_id\": \"\",\n    \"status\": \"FAIL\",\n    \"steps\": {\n        \"Setup\": {\n            \"name\": \"Setup\",\n            \"internal_name\": \"Setup\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-07 06:08:45.330918\",\n                    \"end_time\": \"2024-02-07 06:08:45.348227\",\n                    \"duration\": \"0:00:00.017309\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"Setup.execution.log\",\n                    \"data_hash\": \"e1f8eaa5d49d88fae21fd8a34ff9774bcd4136bdbc3aa613f88a986261bac694\",\n                    \"catalog_relative_path\": \"wrong-file-name/Setup.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"Create Content\": {\n            \"name\": \"Create Content\",\n            \"internal_name\": \"Create Content\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-07 06:08:45.422420\",\n                    \"end_time\": \"2024-02-07 06:08:45.438199\",\n                    \"duration\": \"0:00:00.015779\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"Create_Content.execution.log\",\n                    \"data_hash\": \"e1f8eaa5d49d88fae21fd8a34ff9774bcd4136bdbc3aa613f88a986261bac694\",\n                    \"catalog_relative_path\": \"wrong-file-name/Create_Content.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                },\n                {\n                    \"name\": \"data/hello.txt\",\n                    \"data_hash\": \"108ecead366a67c2bb17e223032e12629bcc21b4ab0fff77cf48a5b784f208c7\",\n                    \"catalog_relative_path\": \"wrong-file-name/data/hello.txt\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"Retrieve Content\": {\n            \"name\": \"Retrieve Content\",\n            \"internal_name\": \"Retrieve Content\",\n            \"status\": \"FAIL\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-07 06:08:45.525924\",\n                    \"end_time\": \"2024-02-07 06:08:45.605381\",\n                    \"duration\": \"0:00:00.079457\",\n                    \"status\": \"FAIL\",\n                    \"message\": \"Command failed\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"data/hello.txt\",\n                    \"data_hash\": \"108ecead366a67c2bb17e223032e12629bcc21b4ab0fff77cf48a5b784f208c7\",\n                    \"catalog_relative_path\": \"data/hello.txt\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"get\"\n                },\n                {\n                    \"name\": \"Retrieve_Content.execution.log\",\n                    \"data_hash\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n                    \"catalog_relative_path\": \"wrong-file-name/Retrieve_Content.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"fail\": {\n            \"name\": \"fail\",\n            \"internal_name\": \"fail\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"fail\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-07 06:08:45.701371\",\n                    \"end_time\": \"2024-02-07 06:08:45.701954\",\n                    \"duration\": \"0:00:00.000583\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"overrides\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"run_log_store\",\n            \"log_folder\": \".run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\",\n            \"catalog_location\": \".catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"examples/retry-fail.yaml\",\n        \"parameters_file\": null,\n        \"configuration_file\": \"examples/configs/fs-catalog-run_log.yaml\",\n        \"tag\": \"\",\n        \"run_id\": \"wrong-file-name\",\n        \"variables\": {\n            \"argo_docker_image\": \"harbor.csis.astrazeneca.net/mlops/runnable:latest\"\n        },\n        \"use_cached\": false,\n        \"original_run_id\": \"\",\n        \"dag\": {\n            \"start_at\": \"Setup\",\n            \"name\": \"\",\n            \"description\": \"This is a simple pipeline that demonstrates retrying failures.\\n\\n1. Setup: We setup a data folder, we ignore if it is already present\\n2. Create Content: We create a \\\"hello.txt\\\" and \\\"put\\\" the file in catalog\\n3. Retrieve Content: We \\\"get\\\" the file \\\"hello.txt\\\" from the catalog and show the contents\\n5. Cleanup: We remove the data folder. Note that this is stubbed to prevent accidental deletion.\\n\\n\\nYou can run this pipeline by:\\n   runnable execute -f examples/catalog.yaml -c examples/configs/fs-catalog.yaml\\n\",\n            \"steps\": {\n                \"Setup\": {\n                    \"type\": \"task\",\n                    \"name\": \"Setup\",\n                    \"next\": \"Create Content\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"mkdir -p data\",\n                    \"node_name\": \"Setup\"\n                },\n                \"Create Content\": {\n                    \"type\": \"task\",\n                    \"name\": \"Create Content\",\n                    \"next\": \"Retrieve Content\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": {\n                        \"get\": [],\n                        \"put\": [\n                            \"data/hello.txt\"\n                        ]\n                    },\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"echo \\\"Hello from runnable\\\" &gt;&gt; data/hello.txt\\n\",\n                    \"node_name\": \"Create Content\"\n                },\n                \"Retrieve Content\": {\n                    \"type\": \"task\",\n                    \"name\": \"Retrieve Content\",\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": {\n                        \"get\": [\n                            \"data/hello.txt\"\n                        ],\n                        \"put\": []\n                    },\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"cat data/hello1.txt\",\n                    \"node_name\": \"Retrieve Content\"\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"13f7c1b29ebb07ce058305253171ceae504e1683\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre> <p>Note</p> <p>You can run this pipeline on your local machine by</p> <p><code>runnable execute -f examples/retry-fixed.yaml -c examples/configs/fs-catalog-run_log.yaml --use-cached wrong-file-name</code></p> <p>Note that we have specified the run_id of the failed execution to be <code>use-cached</code> for the new execution.</p> Pipeline that restarts<pre><code>dag:\n  description: |\n    This is a simple pipeline that demonstrates passing data between steps.\n\n    1. Setup: We setup a data folder, we ignore if it is already present\n    2. Create Content: We create a \"hello.txt\" and \"put\" the file in catalog\n    3. Clean up to get again: We remove the data folder. Note that this is stubbed to prevent\n      accidental deletion of your contents. You can change type to task to make really run.\n    4. Retrieve Content: We \"get\" the file \"hello.txt\" from the catalog and show the contents\n    5. Cleanup: We remove the data folder. Note that this is stubbed to prevent accidental deletion.\n\n\n    You can run this pipeline by:\n       runnable execute -f examples/retry-fixed.yaml -c examples/configs/fs-catalog-run_log.yaml \\\n       --use-cached wrong-file-name\n\n  start_at: Setup\n  steps:\n    Setup:\n      type: task # (1)\n      command_type: shell\n      command: mkdir -p data\n      next: Create Content\n    Create Content:\n      type: stub # (2)\n      command_type: shell\n      command: |\n        echo \"Hello from runnable\" &gt;&gt; data/hello.txt\n      next: Retrieve Content\n      catalog:\n        put:\n          - data/hello.txt\n    Retrieve Content:\n      type: task\n      command_type: shell\n      command: cat data/hello.txt\n      catalog:\n        get:\n          - \"data/hello.txt\" # You can use wild cards following glob pattern\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <ol> <li>Though this step is identical to the failed pipeline, this step does not execute in retry.</li> <li>We mark this step to be stub to demonstrate a re-run using cached does not execute the successful task.</li> </ol> <p>The retry pipeline is executed with success state.</p> <p>Note the execution of step <code>Setup</code> has been marked as <code>mock: true</code>, this step has not been executed but passed through.</p> <p>The step <code>Create Content</code> has been modified to <code>stub</code> to prevent execution in the fixed pipeline.</p> <pre><code>{\n    \"run_id\": \"naive-wilson-0625\",\n    \"dag_hash\": \"148de99f96565bb1b276db2baf23eba682615c76\",\n    \"use_cached\": true,\n    \"tag\": \"\",\n    \"original_run_id\": \"wrong-file-name\",\n    \"status\": \"SUCCESS\",\n    \"steps\": {\n        \"Setup\": {\n            \"name\": \"Setup\",\n            \"internal_name\": \"Setup\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"stub\",\n            \"message\": \"\",\n            \"mock\": true,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"Create Content\": {\n            \"name\": \"Create Content\",\n            \"internal_name\": \"Create Content\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"stub\",\n            \"message\": \"\",\n            \"mock\": true,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        },\n        \"Retrieve Content\": {\n            \"name\": \"Retrieve Content\",\n            \"internal_name\": \"Retrieve Content\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"task\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-07 06:25:13.506657\",\n                    \"end_time\": \"2024-02-07 06:25:13.527603\",\n                    \"duration\": \"0:00:00.020946\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": [\n                {\n                    \"name\": \"data/hello.txt\",\n                    \"data_hash\": \"108ecead366a67c2bb17e223032e12629bcc21b4ab0fff77cf48a5b784f208c7\",\n                    \"catalog_relative_path\": \"data/hello.txt\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"get\"\n                },\n                {\n                    \"name\": \"Retrieve_Content.execution.log\",\n                    \"data_hash\": \"bd8e06cb7432666dc3b1b0db8034966c034397863c7ff629c98ffd13966681d7\",\n                    \"catalog_relative_path\": \"naive-wilson-0625/Retrieve_Content.execution.log\",\n                    \"catalog_handler_location\": \".catalog\",\n                    \"stage\": \"put\"\n                }\n            ]\n        },\n        \"success\": {\n            \"name\": \"success\",\n            \"internal_name\": \"success\",\n            \"status\": \"SUCCESS\",\n            \"step_type\": \"success\",\n            \"message\": \"\",\n            \"mock\": false,\n            \"code_identities\": [\n                {\n                    \"code_identifier\": \"f94e49a4fcecebac4d5eecbb5b691561b08e45c0\",\n                    \"code_identifier_type\": \"git\",\n                    \"code_identifier_dependable\": true,\n                    \"code_identifier_url\": \"https://github.com/AstraZeneca/runnable-core.git\",\n                    \"code_identifier_message\": \"\"\n                }\n            ],\n            \"attempts\": [\n                {\n                    \"attempt_number\": 1,\n                    \"start_time\": \"2024-02-07 06:25:13.597125\",\n                    \"end_time\": \"2024-02-07 06:25:13.597694\",\n                    \"duration\": \"0:00:00.000569\",\n                    \"status\": \"SUCCESS\",\n                    \"message\": \"\",\n                    \"parameters\": {}\n                }\n            ],\n            \"user_defined_metrics\": {},\n            \"branches\": {},\n            \"data_catalog\": []\n        }\n    },\n    \"parameters\": {},\n    \"run_config\": {\n        \"executor\": {\n            \"service_name\": \"local\",\n            \"service_type\": \"executor\",\n            \"enable_parallel\": false,\n            \"overrides\": {}\n        },\n        \"run_log_store\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"run_log_store\",\n            \"log_folder\": \".run_log_store\"\n        },\n        \"secrets_handler\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"secrets\"\n        },\n        \"catalog_handler\": {\n            \"service_name\": \"file-system\",\n            \"service_type\": \"catalog\",\n            \"catalog_location\": \".catalog\"\n        },\n        \"experiment_tracker\": {\n            \"service_name\": \"do-nothing\",\n            \"service_type\": \"experiment_tracker\"\n        },\n        \"pipeline_file\": \"examples/retry-fixed.yaml\",\n        \"parameters_file\": null,\n        \"configuration_file\": \"examples/configs/fs-catalog-run_log.yaml\",\n        \"tag\": \"\",\n        \"run_id\": \"naive-wilson-0625\",\n        \"variables\": {\n            \"argo_docker_image\": \"harbor.csis.astrazeneca.net/mlops/runnable:latest\"\n        },\n        \"use_cached\": true,\n        \"original_run_id\": \"wrong-file-name\",\n        \"dag\": {\n            \"start_at\": \"Setup\",\n            \"name\": \"\",\n            \"description\": \"This is a simple pipeline that demonstrates passing data between steps.\\n\\n1. Setup: We setup a data folder, we ignore if it is already\npresent\\n2. Create Content: We create a \\\"hello.txt\\\" and \\\"put\\\" the file in catalog\\n3. Clean up to get again: We remove the data folder. Note that this is stubbed\nto prevent\\n  accidental deletion of your contents. You can change type to task to make really run.\\n4. Retrieve Content: We \\\"get\\\" the file \\\"hello.txt\\\" from the\ncatalog and show the contents\\n5. Cleanup: We remove the data folder. Note that this is stubbed to prevent accidental deletion.\\n\\n\\nYou can run this pipeline by:\\n\nrunnable execute -f examples/catalog.yaml -c examples/configs/fs-catalog.yaml\\n\",\n            \"steps\": {\n                \"Setup\": {\n                    \"type\": \"stub\",\n                    \"name\": \"Setup\",\n                    \"next\": \"Create Content\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": null,\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"mkdir -p data\"\n                },\n                \"Create Content\": {\n                    \"type\": \"stub\",\n                    \"name\": \"Create Content\",\n                    \"next\": \"Retrieve Content\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": {\n                        \"get\": [],\n                        \"put\": [\n                            \"data/hello.txt\"\n                        ]\n                    },\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"echo \\\"Hello from runnable\\\" &gt;&gt; data/hello.txt\\n\"\n                },\n                \"Retrieve Content\": {\n                    \"type\": \"task\",\n                    \"name\": \"Retrieve Content\",\n                    \"next\": \"success\",\n                    \"on_failure\": \"\",\n                    \"overrides\": {},\n                    \"catalog\": {\n                        \"get\": [\n                            \"data/hello.txt\"\n                        ],\n                        \"put\": []\n                    },\n                    \"max_attempts\": 1,\n                    \"command_type\": \"shell\",\n                    \"command\": \"cat data/hello.txt\",\n                    \"node_name\": \"Retrieve Content\"\n                },\n                \"success\": {\n                    \"type\": \"success\",\n                    \"name\": \"success\"\n                },\n                \"fail\": {\n                    \"type\": \"fail\",\n                    \"name\": \"fail\"\n                }\n            }\n        },\n        \"dag_hash\": \"148de99f96565bb1b276db2baf23eba682615c76\",\n        \"execution_plan\": \"chained\"\n    }\n}\n</code></pre> <p>runnable also supports <code>mocked</code> executor which can patch and mock tasks to isolate and focus on the failed task. Since python functions and notebooks are run in the same shell, it is possible to use python debugger and ploomber debugger to debug failed tasks.</p>"},{"location":"example/secrets/","title":"Secrets","text":"<p>Secrets are required assets as the complexity of the application increases. runnable provides a python API to get secrets from various sources.</p> <p>from runnable import get_secret</p> <p>Secrets is the only interface that you are required to \"import runnable\" in your python application.</p> <p>Native python and Jupyter notebooks can use this API. We currently do not support shell tasks with secrets from this interface. (1)</p> <ol> <li>Using environment variables to access secrets is one pattern works in all environments.</li> </ol> dotenv formatExample configurationPipeline in python <p>The dotenv format for providing secrets. Ideally, this file should not be part of the version control but present during development phase.</p> <p>The file is assumed to be present in <code>examples/secrets.env</code> for this example.</p> <pre><code>\n</code></pre> <ol> <li>Shell scripts style are supported.</li> <li>Key value based format is also supported.</li> </ol> <p>Configuration to use the dotenv format file.</p> <pre><code>secrets:\n  type: dotenv # (1)\n  config:\n    location: examples/secrets.env # (2)\n</code></pre> <ol> <li>Use dotenv secrets manager.</li> <li>Location of the dotenv file, defaults to <code>.env</code> in project root.</li> </ol> <pre><code>\n</code></pre> <ol> <li>The key of the secret that you want to retrieve.</li> </ol>"},{"location":"example/steps/","title":"Steps","text":"<p>runnable provides a rich definition of of step types.</p> <ul> <li>stub: A mock step which is handy during designing and debugging pipelines.</li> <li>task: To execute python functions, jupyter notebooks, shell scripts.</li> <li>parallel: To execute many tasks in parallel.</li> <li>map: To execute the same task over a list of parameters. (1)</li> </ul> <ol> <li>Similar to <code>map</code> state in AWS step functions or <code>loops</code> in Argo workflows.</li> </ol>"},{"location":"example/steps/#stub","title":"stub","text":"<p>Used as a mock node or a placeholder before the actual implementation (1).</p> <ol> <li> Equivalent to <code>pass</code> or <code>...</code> in python.</li> </ol> yamlpython <pre><code>dag:\n  description: |\n    This is a simple pipeline that does 3 steps in sequence.\n\n    step 1 &gt;&gt; step 2 &gt;&gt; step 3 &gt;&gt; success\n\n    All the steps are mocked and they will just pass through.\n    Use this pattern to define the skeleton of your pipeline and flesh out the steps later.\n\n    Note that you can give any arbitrary keys to the steps (like step 2). This is handy\n    to mock steps within mature pipelines.\n\n    You can run this pipeline by:\n       runnable execute -f examples/mocking.yaml\n  start_at: step 1\n  steps:\n    step 1:\n      type: stub\n      next: step 2\n    step 2:\n      type: stub\n      what: is this thing?\n      It: does not matter!!\n      next: step 3\n    step 3:\n      type: stub\n      next: success\n    success:\n      type: success\n    fail:\n      type: fail\n</code></pre> <pre><code>\"\"\"\nThis is a simple pipeline that does 3 steps in sequence.\n\n    step 1 &gt;&gt; step 2 &gt;&gt; step 3 &gt;&gt; success\n\n    All the steps are mocked and they will just pass through.\n    Use this pattern to define the skeleton of your pipeline and flesh out the steps later.\n\n    Note that you can give any arbitrary keys to the steps (like step 2). This is handy\n    to mock steps within mature pipelines.\n\n    You can run this pipeline by:\n       python examples/mocking.py\n\"\"\"\n\nfrom runnable import Pipeline, Stub\n\n\ndef main():\n    step1 = Stub(name=\"step1\")  # (1)\n    step2 = Stub(name=\"step2\", what=\"is this thing\")\n\n    step3 = Stub(name=\"step3\", terminate_with_success=True)  # (3)\n\n    pipeline = Pipeline(steps=[step1, step2, step3], add_terminal_nodes=True)  # (4)\n\n    pipeline.execute()\n\n    return pipeline\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <ol> <li>The name of the node can be as descriptive as you want. Only <code>.</code> or <code>%</code> are not allowed.</li> <li>Stub nodes can take arbitrary parameters; useful to temporarily mock a node. You can define the dependency on step1 using <code>depends_on</code></li> <li><code>terminate_with_success</code> indicates that the dag is completed successfully. You can also use <code>terminate_with_failure</code> to indicate the dag failed.</li> <li>Add <code>success</code> and <code>fail</code> nodes to the dag.</li> </ol>"},{"location":"example/steps/#task","title":"task","text":"<p>Used to execute a single unit of work. You can use python, shell, notebook as command types.</p> <p>Execution logs</p> <p>You can view the execution logs of the tasks in the catalog without digging through the logs from the underlying executor.</p> Example functionsyamlpython <p>The below content is assumed to be <code>examples/functions.py</code></p> <pre><code>from pydantic import BaseModel\n\n\nclass InnerModel(BaseModel):\n    \"\"\"\n    A pydantic model representing a group of related parameters.\n    \"\"\"\n\n    foo: int\n    bar: str\n\n\nclass NestedModel(BaseModel):\n    \"\"\"\n    A pydantic model representing the parameters of the whole pipeline.\n    \"\"\"\n\n    x: int\n    y: InnerModel\n\n\ndef return_parameter() -&gt; NestedModel:\n    \"\"\"\n    A example python task that does something interesting and returns\n    a parameter to be used in downstream steps.\n\n    The annotation of the return type of the function is not mandatory\n    but it is a good practice.\n\n    Returns:\n        NestedModel: The parameters that should be used in downstream steps.\n    \"\"\"\n    # Return type of a function should be a pydantic model\n    return 1, InnerModel(foo=10, bar=\"hello world\")\n\n\ndef display_parameter(x: int, y: InnerModel):\n    \"\"\"\n    An example python task that does something interesting with\n    input parameters.\n\n    Annotating the arguments of the function is important for\n    runnable to understand the type of parameters you want.\n\n    Without annotations, runnable would inject a python dictionary.\n\n    Input args can be a pydantic model or the individual attributes\n    of the non-nested model\n    \"\"\"\n    print(x)\n    # &gt;&gt;&gt; prints 1\n    print(y)\n    # &gt;&gt;&gt; prints InnerModel(foo=10, bar=\"hello world\")\n\n\n\"\"\"\nWithout any framework, the \"driver\" code would be the\nmain function.\n\"\"\"\n\n\ndef main():\n    my_param = return_parameter()\n    display_parameter(my_param.x, my_param.y)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>dag:\n  description: |\n    This is a simple pipeline that does 3 steps\n    in sequence.\n\n    In this example:\n      1. First step: returns a \"parameter\" x\n      as a Pydantic model\n      2. Second step: Consumes that parameter\n      and prints it\n\n    You can run this pipeline by:\n    runnable execute -f examples/python-tasks.yaml\n  start_at: step 1 # (1)\n  steps:\n    step 1: # (2)\n      type: task\n      command: examples.functions.return_parameter # (3)\n      returns:\n        - name: x\n          kind: json\n        - name: y\n          kind: json\n      next: step 2 # (4)\n    step 2:\n      type: task\n      command_type: python\n      command: examples.functions.display_parameter\n      next: success # (5)\n    success:\n      type: success # (6)\n    fail:\n      type: fail\n</code></pre> <ol> <li>Note that the <code>command</code> is the path to the python function.</li> <li><code>python</code> is default command type, you can use <code>shell</code>, <code>notebook</code> too.</li> </ol> <pre><code>\n</code></pre> <ol> <li>Note that the command is the path to the function.</li> <li>There are many ways to define dependencies within nodes, step1 &gt;&gt; step2, step1 &lt;&lt; step2 or during the definition of step1, we can define a next step.</li> <li><code>terminate_with_success</code> indicates that the dag is completed successfully. You can also use <code>terminate_with_failure</code> to indicate the dag failed.</li> <li>Add <code>success</code> and <code>fail</code> nodes to the dag.</li> </ol>"}]}